<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.3.1"><meta name=author content="Max Woolf"><meta name=description content="Given that a SF police arrest occurs at a specified time and place, what is the reason for that arrest?"><link rel=alternate hreflang=en-us href=https://minimaxir.com/2017/02/predicting-arrests/><meta name=theme-color content=#2962ff><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.6.0/css/all.css integrity=sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400italic,700|Source+Code+Pro:400,400italic,700&display=swap"><link rel=stylesheet href=/css/academic.min.d60353c45a1511432f9bc3071cf07140.css><link rel=stylesheet href=/css/academic.b011cb496b1db375ea969a485c505836.css><link rel=manifest href=/site.webmanifest><link rel=icon type=image/png href=/img/icon.png><link rel=apple-touch-icon type=image/png href=/img/icon-192.png><link rel=canonical href=https://minimaxir.com/2017/02/predicting-arrests/><meta property=twitter:card content=summary_large_image><meta property=twitter:site content=@minimaxir><meta property=twitter:creator content=@minimaxir><meta property=article:author content=https://www.facebook.com/max.woolf><meta property=og:site_name content="Max Woolf's Blog"><meta property=og:url content=https://minimaxir.com/2017/02/predicting-arrests/><meta property=og:type content=article><meta property=og:title content="Predicting And Mapping Arrest Types in San Francisco with LightGBM, R, ggplot2"><meta property=og:description content="Given that a SF police arrest occurs at a specified time and place, what is the reason for that arrest?"><meta property=og:image content=https://minimaxir.com/2017/02/predicting-arrests/featured.png><meta property=twitter:image content=https://minimaxir.com/2017/02/predicting-arrests/featured.png><meta property=og:locale content=en-us><meta property=article:published_time content=2017-02-08T06:30:00-07:00><meta property=article:modified_time content=2017-02-08T06:30:00-07:00><title>Predicting And Mapping Arrest Types in San Francisco with LightGBM, R, ggplot2 | Max Woolf&#39;s Blog</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id=navbar-main><div class=container><a class=navbar-brand href=/>Max Woolf&#39;s Blog</a>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="collapse navbar-collapse" id=navbar><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/about/><span>About</span></a></li><li class=nav-item><a class=nav-link href=/post/><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/portfolio/><span>Portfolio</span></a></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=https://www.patreon.com/minimaxir target=_blank rel=noopener><span><i class="fab fa-patreon"></i>Patreon</span></a></li><li class=nav-item><a class=nav-link href=https://github.com/minimaxir target=_blank rel=noopener><span><i class="fab fa-github-alt"></i>GitHub</span></a></li><li class=nav-item><a class="nav-link js-dark-toggle" href=#><i class="fas fa-moon" aria-hidden=true></i></a></li></ul></div></div></nav><article class=article itemscope itemtype=http://schema.org/Article><div class="article-container pt-3"><h1 itemprop=name>Predicting And Mapping Arrest Types in San Francisco with LightGBM, R, ggplot2</h1><meta content="2017-02-08 06:30:00 -0700 -0700" itemprop=datePublished><meta content="2017-02-08 06:30:00 -0700 -0700" itemprop=dateModified><div class=article-metadata><span class=article-date><time>February 8, 2017</time></span>
<span class=middot-divider></span><span class=article-reading-time>10 min read</span>
<span class=middot-divider></span><span class=article-categories><i class="fas fa-folder"></i><a href=/categories/data-science/>Data Science</a></span><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://minimaxir.com/2017/02/predicting-arrests/&amp;text=Predicting%20And%20Mapping%20Arrest%20Types%20in%20San%20Francisco%20with%20LightGBM,%20R,%20ggplot2" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://minimaxir.com/2017/02/predicting-arrests/&amp;t=Predicting%20And%20Mapping%20Arrest%20Types%20in%20San%20Francisco%20with%20LightGBM,%20R,%20ggplot2" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook-f"></i></a></li><li><a href="mailto:?subject=Predicting%20And%20Mapping%20Arrest%20Types%20in%20San%20Francisco%20with%20LightGBM,%20R,%20ggplot2&amp;body=https://minimaxir.com/2017/02/predicting-arrests/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://minimaxir.com/2017/02/predicting-arrests/&amp;title=Predicting%20And%20Mapping%20Arrest%20Types%20in%20San%20Francisco%20with%20LightGBM,%20R,%20ggplot2" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://reddit.com/submit?url=https://minimaxir.com/2017/02/predicting-arrests/&amp;title=Predicting%20And%20Mapping%20Arrest%20Types%20in%20San%20Francisco%20with%20LightGBM,%20R,%20ggplot2" target=_blank rel=noopener class=share-btn-reddit><i class="fab fa-reddit-alien"></i></a></li></ul></div></div></div><div class=article-container><div class=article-style itemprop=articleBody><p>The new hotness in the world of data science is <a href=https://en.wikipedia.org/wiki/Artificial_neural_network target=_blank>neural networks</a>, which form the basis of <a href=https://en.wikipedia.org/wiki/Deep_learning target=_blank>deep learning</a>. But while everyone is obsessing about neural networks and how deep learning is <em>magic</em> and can solve <em>any</em> problem if you just <a href=https://www.reddit.com/r/ProgrammerHumor/comments/5si1f0/machine_learning_approaches/ target=_blank>stack enough layers</a>, there have been many recent developments in the relatively nonmagical world of machine learning with <em>boring</em> CPUs.</p><p>Years before neural networks were the Swiss army knife of data science, there were <a href=https://en.wikipedia.org/wiki/Gradient_boosting target=_blank>gradient-boosted machines</a>/<a href=https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting target=_blank>gradient-boosted trees</a>. GBMs/GBTs are machine learning methods which are effective on many types of data, and do not require the <a href=http://r-statistics.co/Assumptions-of-Linear-Regression.html target=_blank>traditional model assumptions</a> of linear/logistic regression models. Wikipedia has a good article on the advantages of <a href=https://en.wikipedia.org/wiki/Decision_tree_learning target=_blank>decision tree learning</a>, and visual diagrams of the architecture:</p><p><img src=/img/predicting-arrests/CART_tree_titanic_survivors.png alt></p><p>GBMs, as <a href=http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html target=_blank>implemented</a> in the Python package <a href=http://scikit-learn.org/stable/ target=_blank>scikit-learn</a>, are extremely popular in <a href=https://www.kaggle.com target=_blank>Kaggle</a> machine learning competitions. But scikit-learn is relatively old, and new technologies have emerged which implement GBMs/GBTs on large datasets with massive parallelization and and in-memory computation. A popular big data machine learning library, <a href=http://www.h2o.ai target=_blank>H2O</a>, has a <a href=http://docs.h2o.ai/h2o-tutorials/latest-stable/tutorials/gbm-randomforest/index.html target=_blank>famous GBM implementation</a> which, <a href=https://github.com/szilard/benchm-ml target=_blank>per benchmarks</a>, is over 10x faster than scikit-learn and is optimized for datasets with millions of records. But even <em>faster</em> than H2O is <a href=https://github.com/dmlc/xgboost target=_blank>xgboost</a>, which can hit a 5x-10x speed-ups relative to H2O, depending on the dataset size.</p><p>Enter <a href=https://github.com/Microsoft/LightGBM target=_blank>LightGBM</a>, a new (October 2016) open-source machine learning framework by <a href=https://www.microsoft.com/en-us/ target=_blank>Microsoft</a> which, per <a href=https://github.com/Microsoft/LightGBM/issues/211 target=_blank>benchmarks</a> on release, was up to <em>4x faster</em> than xgboost! (xgboost very recently implemented a <a href=https://github.com/dmlc/xgboost/issues/1950 target=_blank>technique</a> also used in LightGBM, which reduced the relative speedup to just ~2x). As a result, LightGBM allows for very efficient model building on large datasets without requiring cloud computing or nVidia CUDA GPUs.</p><p>A year ago, I <a href=http://minimaxir.com/2015/12/sf-arrests/ target=_blank>wrote an analysis</a> of the types of police arrests in San Francisco, using data from the <a href=https://data.sfgov.org target=_blank>SF OpenData</a> initiative, with a <a href=http://minimaxir.com/2015/12/sf-arrest-maps/ target=_blank>followup article</a> analyzing the locations of these arrests. Months later, the same source dataset was used <a href=https://www.kaggle.com/c/sf-crime target=_blank>for a Kaggle competition</a>. Why not give the dataset another look and test LightGBM out?</p><h2 id=playing-with-the-data>Playing With The Data</h2><p><em>(You can view the R code used to process the data and generate the data visualizations in <a href=http://minimaxir.com/notebooks/predicting-arrests/ target=_blank>this R Notebook</a>)</em></p><p>The <a href=https://data.sfgov.org/Public-Safety/SFPD-Incidents-from-1-January-2003/tmnf-yvry target=_blank>SFPD Incidents</a> dataset includes crime incidents in San Francisco from 1/1/2003 to 1/17/2017 (at time of analysis). Filtering the dataset only on incidents which resulted in arrests (since most incidents are trivial) leaves a dataset of 634,299 arrests total. The dataset also includes information on the type of crime, the location where the arrest occurred, and the date/time. There are 39 different types of arrests in the <strong>Category</strong> column such as Assault, Burglary, and Prostitution, which serves as the response variable.</p><p><img src=/img/predicting-arrests/data.png alt></p><p>Meanwhile, we can engineer features from the location and date/time.
Performing an exploratory data analysis of both is helpful to determine at a glance which features may be relevant (fortunately, I did that a year ago).</p><p><img src=/img/sf-arrests/sf-arrest-when-4.png alt></p><p>The location is given as latitude/longitude coordinates, so we can select a longitude <strong>X</strong> and latitude <strong>Y</strong> as features. Date/Time can be deconstructed further. We can extract the <strong>hour</strong> in which a given arrest occurred as a feature (hour can take 24 different values from 0 — 23). Likewise, we can extract the <strong>month</strong> in a similar manner (12 values, from 1 — 12). The <strong>year</strong> the crime occurred can be extracted without special encoding. (2003 — 2017). It is always helpful to include a year feature in predictive models to help account for change over time. The <strong>DayOfWeek</strong> is important, but encoding it as a numeric value is tricker; we logically encode each day of the week from 1 — 7, but which day should be #1? Making Monday #1 and Sunday #7 is the most logical, since a decision tree rule that sets a threshold on DayOfWeek values &gt; 5 will translate logically to a weekend.</p><p><img src=/img/predicting-arrests/predict_matrix.png alt></p><p>That&rsquo;s six features total. There are more features which could be helpful, but let&rsquo;s check a baseline model as a start.</p><h2 id=modeling>Modeling</h2><p>Specifically, the model will predict the answer the question: <em>given that a San Francisco police arrest occurs at a specified time and place, what is the reason for that arrest?</em></p><p>For this post, I will use the <a href=https://github.com/Microsoft/LightGBM/tree/master/R-package target=_blank>R package</a> for LightGBM (which was beta-released in January 2017; it&rsquo;s <em>extremely</em> cutting edge!) We split the dataset 70%/30% into a training set of 444,011 arrests and a test set of 190,288 arrests (due to the large amount of different category labels, the split must be <a href=https://en.wikipedia.org/wiki/Stratified_sampling target=_blank>stratified</a> to ensure the training and test sets have a balanced distribution of labels; in R, this can be implemented with the <code>caret</code> package and <code>createDataPartition</code>).</p><p>LightGBM trains the model on the training set and evaluates it on the test set to minimize the <a href=https://www.kaggle.com/c/sf-crime#evaluation target=_blank>multiclass logarithmic loss</a> of the model. For now, I use the <a href=https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.md target=_blank>default parameters</a> of LightGBM, except to massively increase the number of iterations of the training algorithm, and to stop training the model early if the model stops improving. After about 4 minutes on my laptop (which is very fast for a dataset of this size!), the model returns a multilogloss of <strong>1.98</strong>.</p><p>That number sounds arbitrary. Is it good or bad? Let&rsquo;s compare it to the multilogloss from the <a href=https://www.kaggle.com/c/sf-crime/leaderboard target=_blank>top models</a> from the Kaggle version of the dataset, where a lower score is better:</p><p><img src=/img/predicting-arrests/kaggle.png alt></p><p>&hellip;okay, 1.98 <em>is</em> a good score, and without spending much time adding features to the model and <a href=https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters-tuning.md target=_blank>tuning parameters</a>! To be fair, my methodology would not necessarily result in the same score on the Kaggle dataset, but it confirms that the LightGBM model is in the top tier of models available for this problem and dataset context. And it didn&rsquo;t <a href=https://www.kaggle.com/smerity/sf-crime/fighting-crime-with-keras/output target=_blank>require any neural networks</a> either!</p><p>There are areas for improvement in feature engineering which <a href=https://www.kaggle.com/c/sf-crime/kernels target=_blank>other entries</a> in the Kaggle competition implemented, such as a <a href=https://en.wikipedia.org/wiki/Dummy_variable_(statistics) target=_blank>dummy variable</a> indicating whether the offense occurred at an intersection and which SF police station was involved in the arrest. We could also encode features such as hour and DayOfWeek as categorical features (LightGBM conveniently allows this without requiring <a href=https://en.wikipedia.org/wiki/One-hot target=_blank>one-hot encoding</a> the features) instead of numeric, but in my brief testing, it made the model <em>worse</em>, interestingly.</p><h2 id=analyzing-the-lightgbm-model>Analyzing the LightGBM Model</h2><p>Another perk of not using a neural network for statistical model building is the ability to learn more about the importance of features in a model, as opposed to it being a <a href=https://en.wikipedia.org/wiki/Black_box target=_blank>black box</a>. In the case of gradient boosting, we can calculate the proportional contribution of each feature to the total <a href=https://en.wikipedia.org/wiki/Information_gain_in_decision_trees target=_blank>information gain</a> of the model, which will help identify the most important features, and potentially unhelpful features:</p><p><img src=/img/predicting-arrests/imp.png alt></p><p>Unsurprisingly, location features are the most important, with both location-based features establishing 70% of the total Gain in the model. But no feature is completely insignificant, which is a good thing.</p><p>Back to the multilogloss of 1.98. What does that mean in the real world? What is the <em>accuracy</em> of the model? We run each of the 190,288 arrests in the test set against the model, which returns 39 probability values for each record: one for each possible category of arrest. The category with the highest probability becomes the <strong>predicted</strong> type of arrest.</p><p><img src=/img/predicting-arrests/predicted_results.png alt></p><p>The accuracy of the model on the test set, which is the proportion of predictions where the predicted category value matches the <strong>actual</strong> category value, is <strong>39.7%</strong>, with a 95% confidence interval for the true accuracy between 39.5% and 39.9%. That seems low! However, there is catch-all &ldquo;Other Offenses&rdquo; category for an arrest; if you predicted a &ldquo;Other Offenses&rdquo; label for all the test-set values, you would get an accuracy of <em>31.1%</em>, which serves as the No Information Rate (since it would be the highest accuracy approach if there was no information at all). A 8.6 percentage point improvement is still an improvement though; many industries would <em>love</em> an 8.6 percentage point increase in accuracy, but for this context obviously it&rsquo;s not enough to usher in a <a href=https://en.wikipedia.org/wiki/Minority_Report_(film) target=_blank>Minority Report</a>/<a href=https://en.wikipedia.org/wiki/Person_of_Interest_(TV_series) target=_blank>Person of Interest</a> future.</p><p>We can visualize the classifications on the test set by the model using a <a href=https://en.wikipedia.org/wiki/Confusion_matrix target=_blank>confusion matrix</a>; <code>caret</code> has a simple <code>confusionMatrix()</code> function, and ggplot2 has a <code>geom_tile()</code> to map out the relationships, even with 39 classes. We can also annotate the tiles where actual label = predicted label by drawing a <code>geom_point()</code> on top. Putting it all together:</p><p><img src=/img/predicting-arrests/confusionMatrix.png alt></p><p>There is, indeed, a large amount of confusion. Many of the labels are mispredicted as Other Offenses. Specifically, the model frequently confuses the combinations of Assault, Drug/Narcotics, Larceny/Theft, and Warrants, suggesting that they also may be catch-alls.</p><p>In theory, the predicted probabilities from the model between similar types of crime should also be similar, which may be causing these mispredictions. We can calculate the <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient target=_blank>Pearson correlations</a> between the predicted probabilities, and use <a href=https://en.wikipedia.org/wiki/Hierarchical_clustering target=_blank>hierarchical clustering</a> to <a href=http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization target=_blank>arrange and plot the correlations</a> and their labels in a logical order. The majority of the correlations between labels are between 0 and +/- 0.5 (weak to moderate), but their arrangement tells a different story:</p><p><img src=/img/predicting-arrests/correlationMatrix.png alt></p><p>From top to bottom, you can see that there is a grouping of more blue-collar, physical crimes types (Assault, Vandalism), then a grouping of less-physical, white-collar crime types (Bribery, Extortion), and then a smaller grouping of seedier crime types (Liquor Laws, Prostitution).</p><p>The visualization doesn&rsquo;t necessarily provide more information about the confusion matrix and the mispredictions, but <em>it looks cool</em>, which is enough.</p><h2 id=mapping-the-predicted-types-of-arrests>Mapping the Predicted Types of Arrests</h2><p>Kaggle competitions emphasize model creation, but don&rsquo;t discuss how to implement and execute models in practice. Since we can predict the type of crime based on the given location and date/time of an arrest, we can map boundaries of the mostly likely type of offense. Using <code>ggmap</code> to get a map of San Francisco, splitting San Francisco into tens of thousands of points, and predicting the most-likely type of arrest at the location with a given date/time.</p><p>Let&rsquo;s say we want to predict the types of crime in the future, on April 15th, 2017, during 8 PM. We construct a dataset of those points and the same date/time features used to generate the model originally. Then run those fabricated points through the model again to get new predicted labels (Additionally, we need to remove &ldquo;Other Offenses&rdquo; predicted labels since they cloud up the map). Plotting each point as a <code>geom_tile</code> will interpolate regions around the city. Putting it all together:</p><p><img src=/img/predicting-arrests/crime-2017-04-15-20.png alt></p><p>Not too shabby. But that&rsquo;s not all; we can <em>animate</em> this map over a day by incrementing the hour, generating a map for each hour (while keeping the colors corresponding to the arrest type consistent), and then <a href=https://github.com/minimaxir/frames-to-gif-osx target=_blank>stitching the maps together</a> into a GIF. Let&rsquo;s do March 14th, 2017 (<a href=https://en.wikipedia.org/wiki/Pi_Day target=_blank>Pi Day</a> can be dangerous!) starting at 6 AM:</p><p><img src=/img/predicting-arrests/map_ani.gif alt></p><p>Wow!</p><h2 id=conclusion>Conclusion</h2><p>I deliberately avoided using the term &ldquo;machine learning&rdquo; in the headline of this post because it has been overused to the point of clickbait. Indeed, neural networks/deep learning excel at processing higher-dimensional data such as text, image, and voice data, but in cases where dataset features are <a href="https://news.ycombinator.com/item?id=13563892" target=_blank>simple and known</a>, neural networks are not necessarily the most <em>pragmatic</em> option. CPU/RAM machine learning libraries like LightGBM are still worthwhile, despite the religious fervor for deep learning.</p><p>And there&rsquo;s still a lot of work that can be done with the SF Crime Incidents dataset. The model only predicts the type of crime given an arrest occurred; it does not predict <em>if</em> an arrest will occur at a given time and place, which would make a fun project for the future!</p><hr><p><em>You can view all the R and ggplot2 code used to visualize the San Francisco crime data in <a href=http://minimaxir.com/notebooks/predicting-arrests/ target=_blank>this R Notebook</a>. You can also view the images/data used for this post in <a href=https://github.com/minimaxir/sf-arrests-predict target=_blank>this GitHub repository</a></em>.</p><p><em>You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!</em></p><div class="alert alert-note"><div>If you liked this blog post, I have set up a <a href=https://www.patreon.com/minimaxir target=_blank>Patreon</a> to fund my machine learning/deep learning/software/hardware needs for my future crazy yet cool projects, and any monetary contributions to the Patreon are appreciated and will be put to good creative use.</div></div></div><div class=article-tags><a class="badge badge-light" href=/tags/r/>R</a>
<a class="badge badge-light" href=/tags/ggplot2/>ggplot2</a></div><div class="media author-card" itemscope itemtype=http://schema.org/Person><img class="portrait mr-3" src="https://s.gravatar.com/avatar/28f09e3deff62333b3f32f19d3971d46?s=200')" itemprop=image alt=Avatar><div class=media-body><h5 class=card-title itemprop=name><a href=https://minimaxir.com/>Max Woolf</a></h5><h6 class=card-subtitle>Data Scientist at BuzzFeed</h6><p class=card-text itemprop=description>Ex-Apple. Carnegie Mellon graduate. Plotter of pretty charts. Former TechCrunch comment troll.</p><ul class=network-icon aria-hidden=true><li><a itemprop=sameAs href=https://twitter.com/minimaxir target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a itemprop=sameAs href=https://linkedin.com/in/minimaxir target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a itemprop=sameAs href=https:/youtube.com/minimaxir target=_blank rel=noopener><i class="fab fa-youtube"></i></a></li><li><a itemprop=sameAs href=https:/twitch.tv/minimaxir target=_blank rel=noopener><i class="fab fa-twitch"></i></a></li><li><a itemprop=sameAs href=mailto:max@minimaxir.com><i class="fas fa-envelope"></i></a></li></ul></div></div><div class=article-widget><div class=hr-light></div><h3>Related</h3><ul><li><a href=/2017/01/amazon-spark/>Playing with 80 Million Amazon Product Review Ratings Using Apache Spark</a></li><li><a href=/2016/11/first-comment/>What Percent of the Top-Voted Comments in Reddit Threads Were Also 1st Comment?</a></li><li><a href=/2016/07/stack-overflow/>Visualizing How Developers Rate Their Own Programming Skills</a></li><li><a href=/2016/06/reddit-related-subreddits/>Methods for Finding Related Reddit Subreddits with Simple Set Theory</a></li><li><a href=/2016/05/reddit-graph/>How to Create a Network Graph Visualization of Reddit Subreddits</a></li></ul></div><div class=article-widget><div class=post-nav><div class=post-nav-item><div class=meta-nav>Next</div><a href=/2017/04/char-embeddings/ rel=next>Pretrained Character Embeddings for Deep Learning and Automatic Text Generation</a></div><div class=post-nav-item><div class=meta-nav>Previous</div><a href=/2017/01/amazon-spark/ rel=prev>Playing with 80 Million Amazon Product Review Ratings Using Apache Spark</a></div></div></div><section id=comments><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"minimaxir"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin=anonymous></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js></script><script>hljs.initHighlightingOnLoad();</script><script src=/js/academic.min.bc1d5e4f014b8d38d75521ad1ae2ab18.js></script><div class=container><footer class=site-footer><p class=powered-by>Copyright Max Woolf &copy; 2019 &middot;
Powered by the
<a href=https://sourcethemes.com/academic/ target=_blank rel=noopener>Academic theme</a> for
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>.
<span class=float-right aria-hidden=true><a href=# id=back_to_top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&times;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div></body></html>