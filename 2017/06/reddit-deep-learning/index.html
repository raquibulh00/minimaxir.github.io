<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.3.1"><meta name=author content="Max Woolf"><meta name=description content="Thanks to Keras, performing deep learning on a very large number of Reddit submissions is actually pretty easy. Performing it *well* is a different story."><link rel=alternate hreflang=en-us href=https://minimaxir.com/2017/06/reddit-deep-learning/><meta name=theme-color content=#2962ff><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.6.0/css/all.css integrity=sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400italic,700|Source+Code+Pro:400,400italic,700&display=swap"><link rel=stylesheet href=/css/academic.min.4cdedb6ca5fc8a13caf3e26423bf7037.css><link rel=stylesheet href=/css/academic.59da4f61e2de6d8a5935b902fe667ab3.css><link rel=manifest href=/site.webmanifest><link rel=icon type=image/png href=/img/icon.png><link rel=apple-touch-icon type=image/png href=/img/icon-192.png><link rel=canonical href=https://minimaxir.com/2017/06/reddit-deep-learning/><meta property=twitter:card content=summary_large_image><meta property=twitter:site content=@minimaxir><meta property=twitter:creator content=@minimaxir><meta property=article:author content=https://www.facebook.com/max.woolf><meta property=og:site_name content="Max Woolf's Blog"><meta property=og:url content=https://minimaxir.com/2017/06/reddit-deep-learning/><meta property=og:type content=article><meta property=og:title content="Predicting the Success of a Reddit Submission with Deep Learning and Keras"><meta property=og:description content="Thanks to Keras, performing deep learning on a very large number of Reddit submissions is actually pretty easy. Performing it *well* is a different story."><meta property=og:image content=https://minimaxir.com/2017/06/reddit-deep-learning/featured.png><meta property=twitter:image content=https://minimaxir.com/2017/06/reddit-deep-learning/featured.png><meta property=og:locale content=en-us><meta property=article:published_time content=2017-06-26T09:00:00-07:00><meta property=article:modified_time content=2017-06-26T09:00:00-07:00><title>Predicting the Success of a Reddit Submission with Deep Learning and Keras | Max Woolf&#39;s Blog</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id=navbar-main><div class=container><a class=navbar-brand href=/>Max Woolf&#39;s Blog</a>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="collapse navbar-collapse" id=navbar><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/about/><span>About</span></a></li><li class=nav-item><a class=nav-link href=/post/><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/portfolio/><span>Portfolio</span></a></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=https://www.patreon.com/minimaxir target=_blank rel=noopener><span><i class="fab fa-patreon mr-1"></i>Patreon</span></a></li><li class=nav-item><a class=nav-link href=https://github.com/minimaxir target=_blank rel=noopener><span><i class="fab fa-github-alt mr-1"></i>GitHub</span></a></li><li class=nav-item><a class="nav-link js-dark-toggle" href=#><i class="fas fa-moon" aria-hidden=true></i></a></li></ul></div></div></nav><article class=article itemscope itemtype=http://schema.org/Article><div class="article-container pt-3"><h1 itemprop=name>Predicting the Success of a Reddit Submission with Deep Learning and Keras</h1><meta content="2017-06-26 09:00:00 -0700 PDT" itemprop=datePublished><meta content="2017-06-26 09:00:00 -0700 PDT" itemprop=dateModified><div class=article-metadata><span class=article-date><time>June 26, 2017</time></span>
<span class=middot-divider></span><span class=article-reading-time>9 min read</span>
<span class=middot-divider></span><span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/categories/ai/>AI</a></span><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://minimaxir.com/2017/06/reddit-deep-learning/&amp;text=Predicting%20the%20Success%20of%20a%20Reddit%20Submission%20with%20Deep%20Learning%20and%20Keras" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://minimaxir.com/2017/06/reddit-deep-learning/&amp;t=Predicting%20the%20Success%20of%20a%20Reddit%20Submission%20with%20Deep%20Learning%20and%20Keras" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook-f"></i></a></li><li><a href="mailto:?subject=Predicting%20the%20Success%20of%20a%20Reddit%20Submission%20with%20Deep%20Learning%20and%20Keras&amp;body=https://minimaxir.com/2017/06/reddit-deep-learning/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://minimaxir.com/2017/06/reddit-deep-learning/&amp;title=Predicting%20the%20Success%20of%20a%20Reddit%20Submission%20with%20Deep%20Learning%20and%20Keras" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://reddit.com/submit?url=https://minimaxir.com/2017/06/reddit-deep-learning/&amp;title=Predicting%20the%20Success%20of%20a%20Reddit%20Submission%20with%20Deep%20Learning%20and%20Keras" target=_blank rel=noopener class=share-btn-reddit><i class="fab fa-reddit-alien"></i></a></li></ul></div></div></div><div class=article-container><div class=article-style itemprop=articleBody><p>I&rsquo;ve been trying to figure out what makes a <a href=https://www.reddit.com target=_blank>Reddit</a> submission &ldquo;good&rdquo; for years. If we assume the number of upvotes on a submission is a fair proxy for submission quality, optimizing a statistical model for Reddit data with submission score as a response variable might lead to interesting (and profitable) insights when transferred into other domains, such as Facebook Likes and Twitter Favorites.</p><p><img src=/img/reddit-deep-learning/reddit-example.png alt></p><p>An important part of a Reddit submission is the submission <strong>title</strong>. Like news headlines, a catchy title will make a user <a href=http://minimaxir.com/2015/10/reddit-topwords/ target=_blank>more inclined</a> to engage with a submission and potentially upvote.</p><p><img src=/img/reddit-topwords/mean-054-Fitness.png alt></p><p>Additionally, the <strong>time when the submission is made</strong> is <a href=http://minimaxir.com/2015/10/reddit-bigquery/ target=_blank>important</a>; submitting when user activity is the highest tends to lead to better results if you are trying to maximize exposure.</p><p><img src=/img/reddit-bigquery/reddit-bigquery-2.png alt></p><p>The actual <strong>content</strong> of the Reddit submission such as images/links to a website is likewise important, but good content is relatively difficult to optimize.</p><p>Can the magic of deep learning reconcile these concepts and create a model which can predict if a submission is a good submission? Thanks to <a href=https://github.com/fchollet/keras target=_blank>Keras</a>, performing deep learning on a very large number of Reddit submissions is actually pretty easy. Performing it <em>well</em> is a different story.</p><h2 id=getting-the-data-feature-engineering>Getting the Data + Feature Engineering</h2><p>It&rsquo;s difficult to retrieve the content of millions of Reddit submissions at scale (ethically), so let&rsquo;s initially start by building a model using submissions on <a href=https://www.reddit.com/r/AskReddit/ target=_blank>/r/AskReddit</a>: Reddit&rsquo;s largest subreddit which receives 8,000+ submissions each day. /r/AskReddit is a self-post only subreddit with no external links, allowing us to focus on only the submission title and timing.</p><p><a href=http://minimaxir.com/2015/10/reddit-bigquery/ target=_blank>As always</a>, we can collect large amounts of Reddit data from the public Reddit dataset on <a href=https://cloud.google.com/bigquery/ target=_blank>BigQuery</a>. The submission <code>title</code> is available by default. The raw timestamp of the submission is also present, allowing us to extract the <code>hour</code> of submission (adjusted to Eastern Standard Time) and <code>dayofweek</code>, as used in the heatmap above. But why stop there? Since /r/AskReddit receives hundreds of submissions <em>every hour</em> on average, we should look at the <code>minute</code> level to see if there are any deeper trends (e.g. there are only 30 slots available on the first page of /new and since there is so much submission activity, it might be more advantageous to submit during off-peak times). Lastly, to account for potential changes in behavior as the year progresses, we should add a <code>dayofyear</code> feature, where January 1st = 1, January 2nd = 2, etc which can also account for variance due to atypical days like holidays.</p><p>Instead of predicting the raw number on upvotes of the Reddit submission (as the distribution of submission scores is heavily skewed), we should predict <strong>whether or not the submission is good</strong>, shaping the problem as a <a href=https://en.wikipedia.org/wiki/Logistic_regression target=_blank>logistic regression</a>. In this case, let&rsquo;s define a &ldquo;good submission&rdquo; as one whose score is equal to or above the <strong>50th percentile (median) of all submissions</strong> in /r/AskReddit. Unfortunately, the median score ends up being <strong>2 points</strong>; although &ldquo;one upvote&rdquo; might be a low threshold for a &ldquo;good&rdquo; submission, it splits the dataset into 64% bad submissions, 36% good submissions, and setting the percentile threshold higher will result in a very unbalanced dataset for model training (a score of 2+ also implies that the submission did not get downvoted to death, which is useful).</p><p>Gathering all <strong>976,538 /r/AskReddit submissions</strong> from January 2017 to April 2017 should be enough data for this project. Here&rsquo;s the final BigQuery:</p><pre><code class=language-sql>#standardSQL 
SELECT id, title,
  CAST(FORMAT_TIMESTAMP('%H', TIMESTAMP_SECONDS(created_utc), 'America/New_York') AS INT64) AS hour,
  CAST(FORMAT_TIMESTAMP('%M', TIMESTAMP_SECONDS(created_utc), 'America/New_York') AS INT64) AS minute,
  CAST(FORMAT_TIMESTAMP('%w', TIMESTAMP_SECONDS(created_utc), 'America/New_York') AS INT64) AS dayofweek,
  CAST(FORMAT_TIMESTAMP('%j', TIMESTAMP_SECONDS(created_utc), 'America/New_York') AS INT64) AS dayofyear,
  IF(PERCENT_RANK() OVER (ORDER BY score ASC) &gt;= 0.50, 1, 0) as is_top_submission
  FROM `fh-bigquery.reddit_posts.*`
  WHERE (_TABLE_SUFFIX BETWEEN '2017_01' AND '2017_04')
  AND subreddit = 'AskReddit'
</code></pre><p><img src=/img/reddit-deep-learning/bigquery.png alt></p><h2 id=model-architecture>Model Architecture</h2><p><em>If you want to see the detailed data transformations and Keras code examples/outputs for this post, you can view <a href=https://github.com/minimaxir/predict-reddit-submission-success/blob/master/predict_askreddit_submission_success_timing.ipynb target=_blank>this Jupyter Notebook</a>.</em></p><p>Text processing is a good use case for deep learning, as it can identify relationships between words where older methods like <a href=https://en.wikipedia.org/wiki/Tfâ€“idf target=_blank>tf-idf</a> can&rsquo;t. Keras, a high level deep-learning framework on top of lower frameworks like <a href=https://www.tensorflow.org target=_blank>TensorFlow</a>, can easily convert a list of texts to a <a href=https://keras.io/preprocessing/sequence/ target=_blank>padded sequence</a> of <a href=https://keras.io/preprocessing/text/ target=_blank>index tokens</a> that can interact with deep learning models, along with many other benefits. Data scientists often use <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network target=_blank>recurrent neural networks</a> that can &ldquo;learn&rdquo; for classifying text. However <a href=https://github.com/facebookresearch/fastText target=_blank>fasttext</a>, a newer algorithm from researchers at Facebook, can perform classification tasks at an <a href=http://minimaxir.com/2017/06/keras-cntk/ target=_blank>order of magnitude faster</a> training time than RNNs, with similar predictive performance.</p><p>fasttext works by <a href=https://arxiv.org/abs/1607.01759 target=_blank>averaging word vectors</a>. In this Reddit model architecture inspired by the <a href=https://github.com/fchollet/keras/blob/master/examples/imdb_fasttext.py target=_blank>official Keras fasttext example</a>, each word in a Reddit submission title (up to 20) is mapped to a 50-dimensional vector from an Embeddings layer of up to 40,000 words. The Embeddings layer is <a href=https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html target=_blank>initialized</a> with <a href=https://nlp.stanford.edu/projects/glove/ target=_blank>GloVe word embeddings</a> pre-trained on billions of words to give the model a good start. All the word vectors for a given Reddit submission title are averaged together, and then a Dense fully-connected layer outputs a probability the given text is a good submission. The gradients then backpropagate and improve the word embeddings for future batches during training.</p><p>Keras has a <a href=https://keras.io/visualization/ target=_blank>convenient utility</a> to visualize deep learning models:</p><p><img src=/img/reddit-deep-learning/model_shapes-1.png alt></p><p>However, the first output above is the <em>auxiliary output</em> for <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics) target=_blank>regularizing</a> the word embeddings; we still have to incorporate the submission timing data into the model.</p><p>Each of the four timing features (hour, minute, day of week, day of year) receives its own Embeddings layer, outputting a 64D vector. This allows the features to learn latent characteristics which may be missed using traditional <a href=http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html target=_blank>one-hot encoding</a> for categorical data in machine learning problems.</p><p><img src=/img/reddit-deep-learning/model_shapes-2.png alt></p><p>The 50D word average vector is concatenated with the four vectors above, resulting in a 306D vector. This combined vector is connected to another fully-connected layer which can account for hidden interactions between all five input features (plus <a href=https://keras.io/layers/normalization/ target=_blank>batch normalization</a>, which improves training speed for Dense layers). Then the model outputs a final probability prediction: the <em>main output</em>.</p><p><img src=/img/reddit-deep-learning/model_shapes-3.png alt></p><p>The final model:</p><p><img src=/img/reddit-deep-learning/model.png alt></p><p>All of this sounds difficult to implement, but Keras&rsquo;s <a href=https://keras.io/getting-started/functional-api-guide/ target=_blank>functional API</a> ensures that adding each layer and linking them together can be done in a single line of code each.</p><h2 id=training-results>Training Results</h2><p>Because the model uses no recurrent layers, it trains fast enough on a CPU despite the large dataset size.</p><p>We split the full dataset into 80%/20% training/test datasets, training the model on the former and testing the model against the latter. Keras trains a model with a simple <code>fit</code> command and trains for 20 epochs, where one epoch represents an entire pass of the training set.</p><p><img src=/img/reddit-deep-learning/fit.png alt></p><p>There&rsquo;s a lot happening in the console output due to the architecture, but the main metrics of interest are the <code>main_out_acc</code>, the accuracy of the training set through the main output, and <code>val_main_out_acc</code>, the accuracy of the test set. Ideally, the accuracy of both should increase as training progresses. However, the test accuracy <em>must</em> be better than the 64% baseline (if we just say all /r/AskReddit submissions are bad), otherwise this model is unhelpful.</p><p>Keras&rsquo;s <a href=https://keras.io/callbacks/#csvlogger target=_blank>CSVLogger</a> trivially logs all these metrics to a CSV file. Plotting the results of the 20 epochs:</p><p><img src=/img/reddit-deep-learning/predict-reddit-1.png alt></p><p>The test accuracy does indeed beat the 64% baseline; however, test accuracy <em>decreases</em> as training progresses. This is a sign of <a href=https://en.wikipedia.org/wiki/Overfitting target=_blank>overfitting</a>, possibly due to the potential disparity between texts in the training and test sets. In deep learning, you can account for overfitting by adding <a href=https://keras.io/layers/core/#dropout target=_blank>Dropout</a> to relevant layers, but in my testing it did not help.</p><h2 id=using-the-model-to-optimize-reddit-submissions>Using The Model To Optimize Reddit Submissions</h2><p>At the least, we now have a model that understands the latent characteristics of an /r/AskReddit submission. But how do you apply the model <em>in practical, real-world situations</em>?</p><p>Let&rsquo;s take a random /r/AskReddit submission: <a href=https://www.reddit.com/r/AskReddit/comments/5odcpd/which_movies_plot_would_drastically_change_if_you/ target=_blank>Which movie&rsquo;s plot would drastically change if you removed a letter from its title?</a>, submitted Monday, January 16th at 3:46 PM EST and receiving 4 upvotes (a &ldquo;good&rdquo; submission in context of this model). Plugging those input variables into the trained model results in a <strong>0.669</strong> probability of it being considered a good submission, which is consistent with the true results.</p><p>But what if we made <em>minor, iterative changes</em> to the title while keeping the time submitted unchanged? Can we improve this probability?</p><p>&ldquo;Drastically&rdquo; is a silly adjective; removing it and using the title <strong>Which movie&rsquo;s plot would change if you removed a letter from its title?</strong> results in a greater probability of <strong>0.682</strong>.</p><p>&ldquo;Removed&rdquo; is <a href=http://www.ef.edu/english-resources/english-grammar/conditional/ target=_blank>grammatically incorrect</a>; fixing the issue and using the title <strong>Which movie&rsquo;s plot would change if you remove a letter from its title?</strong> results in a greater probability of <strong>0.692</strong>.</p><p>&ldquo;Which&rdquo; is also <a href=https://www.englishclub.com/vocabulary/wh-question-words.htm target=_blank>grammatically incorrect</a>; fixing the issue and using the title <strong>What movie&rsquo;s plot would change if you remove a letter from its title?</strong> results in a greater probability of <strong>0.732</strong>.</p><p>Although adjectives are sometimes redundant, they can add an intriguing emphasis; adding a &ldquo;single&rdquo; and using the title <strong>What movie&rsquo;s plot would change if you remove a single letter from its title?</strong> results in a greater probability of <strong>0.753</strong>.</p><p>Not bad for a little workshopping!</p><p>Now that we have an improved title, we can find an optimal time to make the submission through brute force by calculating the probabilities for all combinations of hour, minute, and day of week (and offsetting the day of year appropriately). After doing so, I discovered that making the submission on the previous Sunday at 10:55 PM EST results in the maximum probability possible of being a good submission at <strong>0.841</strong> (the other top submission times are at various other minutes during that hour; the best time on a different day is the following Tuesday at 4:05 AM EST with a probability of <strong>0.823</strong>).</p><p>In all, this model of Reddit submission success prediction is a proof of concept; there are many, <em>many</em> optimizations that can be done on the feature engineering side and on the data collection side (especially if we want to model subreddits other than /r/AskReddit). Predicting which submissions go viral instead of just predicting which submissions receive atleast one upvote is another, more advanced problem entirely.</p><p>Thanks to the high-level abstractions and utility functions of Keras, I was able to prototype the initial model in an afternoon instead of the weeks/months required for academic papers and software applications in this area. At the least, this little experiment serves as an example of applying Keras to a real-world dataset, and the tradeoffs that result when deep learning can&rsquo;t magically solve everything. But that doesn&rsquo;t mean my experiments on the Reddit data were unproductive; on the contrary, I now have a few new clever ideas how to fix some of the issues discovered, which I hope to implement soon.</p><p>Again, I strongly recommend reading the data transformations and Keras code examples in <a href=https://github.com/minimaxir/predict-reddit-submission-success/blob/master/predict_askreddit_submission_success_timing.ipynb target=_blank>this Jupyter Notebook</a> for more information into the methodology, as building modern deep learning models is more intuitive and less arcane than what thought pieces on Medium imply.</p><hr><p><em>You can view the R and ggplot2 code used to visualize the model data in <a href=http://minimaxir.com/notebooks/predict-reddit-submission-success/ target=_blank>this R Notebook</a>, including 2D projections of the Embedding layers not in this article. You can also view the images/data used for this post in <a href=https://github.com/minimaxir/predict-reddit-submission-success target=_blank>this GitHub repository</a>.</em></p><p><em>You are free to use the data visualizations/model architectures from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!</em></p><div class="alert alert-note"><div>If you liked this blog post, I have set up a <a href=https://www.patreon.com/minimaxir target=_blank>Patreon</a> to fund my machine learning/deep learning/software/hardware needs for my future crazy yet cool projects, and any monetary contributions to the Patreon are appreciated and will be put to good creative use.</div></div></div><div class=article-tags><a class="badge badge-light" href=/tags/python/>Python</a>
<a class="badge badge-light" href=/tags/tensorflow/>TensorFlow</a>
<a class="badge badge-light" href=/tags/keras/>Keras</a></div><div class="media author-card" itemscope itemtype=http://schema.org/Person><img class="portrait mr-3" src="https://s.gravatar.com/avatar/28f09e3deff62333b3f32f19d3971d46?s=200')" itemprop=image alt=Avatar><div class=media-body><h5 class=card-title itemprop=name><a href=https://minimaxir.com/>Max Woolf</a></h5><h6 class=card-subtitle>Data Scientist at BuzzFeed</h6><p class=card-text itemprop=description>Ex-Apple. Carnegie Mellon graduate. Plotter of pretty charts. Former TechCrunch comment troll.</p><ul class=network-icon aria-hidden=true><li><a itemprop=sameAs href=https://twitter.com/minimaxir target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a itemprop=sameAs href=https://linkedin.com/in/minimaxir target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a itemprop=sameAs href=https://youtube.com/minimaxir target=_blank rel=noopener><i class="fab fa-youtube"></i></a></li><li><a itemprop=sameAs href=https://twitch.tv/minimaxir target=_blank rel=noopener><i class="fab fa-twitch"></i></a></li><li><a itemprop=sameAs href=mailto:max@minimaxir.com><i class="fas fa-envelope"></i></a></li></ul></div></div><div class=article-widget><div class=hr-light></div><h3>Related</h3><ul><li><a href=/2017/06/r-notebooks/>Advantages of Using R Notebooks For Data Analysis Instead of Jupyter Notebooks</a></li><li><a href=/2016/05/wordclouds/>Creating Stylish, High-Quality Word Clouds Using Python and Font Awesome Icons</a></li><li><a href=/2015/07/facebook-scraper/>How to Scrape Data From Facebook Page Posts for Statistical Analysis</a></li></ul></div><div class=article-widget><div class=post-nav><div class=post-nav-item><div class=meta-nav>Next</div><a href=/2017/07/cpu-or-gpu/ rel=next>Benchmarking TensorFlow on Cloud CPUs: Cheaper Deep Learning than Cloud GPUs</a></div><div class=post-nav-item><div class=meta-nav>Previous</div><a href=/2017/06/imgur-decline/ rel=prev>The Decline of Imgur on Reddit and the Rise of Reddit&#39;s Native Image Hosting</a></div></div></div><section id=comments><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"minimaxir"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin=anonymous></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js></script><script>hljs.initHighlightingOnLoad();</script><script src=/js/academic.min.fa2e27444bc8d51f81714869209e3287.js></script><div class=container><footer class=site-footer><p class=powered-by>Copyright Max Woolf &copy; 2020 &middot;
Powered by the
<a href=https://sourcethemes.com/academic/ target=_blank rel=noopener>Academic theme</a> for
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>.
<span class=float-right aria-hidden=true><a href=# id=back_to_top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&times;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div></body></html>