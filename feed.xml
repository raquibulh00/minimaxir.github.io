<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>minimaxir | Max Woolf's Blog</title>
    <description>A blog by Max Woolf about startups, technology, and blogging. It's so meta, even this acronym.</description>
    <link>http://minimaxir.com/</link>
    <atom:link href="http://minimaxir.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 08 Apr 2017 15:45:59 -0700</pubDate>
    <lastBuildDate>Sat, 08 Apr 2017 15:45:59 -0700</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>Pretrained Character Embeddings for Deep Learning and Automatic Text Generation</title>
        <description>&lt;p&gt;Deep learning is the biggest, &lt;a href=&quot;http://approximatelycorrect.com/2017/03/28/the-ai-misinformation-epidemic/&quot;&gt;often misapplied&lt;/a&gt; buzzword nowadays for getting pageviews on blogs. As a result, there have been a lot of shenanigans lately with deep learning thought pieces and how deep learning can solve &lt;em&gt;anything&lt;/em&gt; and make childhood sci-fi dreams come true.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m not a fan of &lt;a href=&quot;http://tvtropes.org/pmwiki/pmwiki.php/Main/ClarkesThirdLaw&quot;&gt;Clarke&amp;rsquo;s Third Law&lt;/a&gt;, so I spent some time checking out deep learning myself. As it turns out, with modern deep learning tools like &lt;a href=&quot;https://github.com/fchollet/keras&quot;&gt;Keras&lt;/a&gt;, a higher-level framework on top of the popular &lt;a href=&quot;https://www.tensorflow.org&quot;&gt;TensorFlow&lt;/a&gt; framework, deep learning is &lt;strong&gt;easy to learn and understand&lt;/strong&gt;. Yes, easy. And it &lt;em&gt;definitely&lt;/em&gt; does not require a PhD, or even a Computer Science undergraduate degree, to implement models or make decisions based on the output.&lt;/p&gt;

&lt;p&gt;However, let&amp;rsquo;s try something more expansive than the stereotypical deep learning tutorials.&lt;/p&gt;

&lt;h2&gt;Characters Welcome&lt;/h2&gt;

&lt;p&gt;Word embeddings have been a popular machine learning trick nowadays. By using an algorithm such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Word2vec&quot;&gt;Word2vec&lt;/a&gt;, you can obtain a numeric representation of a word, and use those values to create numeric representations of higher-level representations like sentences/paragraphs/documents/etc.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/word-vectors.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;However, generating word vectors for datasets can be computationally expensive (see &lt;a href=&quot;http://minimaxir.com/2016/08/clickbait-cluster/&quot;&gt;my earlier post&lt;/a&gt; which uses Apache Spark/Word2vec to create sentence vectors at scale quickly). The academic way to work around this is to use pretrained word embeddings, such as &lt;a href=&quot;https://nlp.stanford.edu/projects/glove/&quot;&gt;the GloVe vectors&lt;/a&gt; collected by researchers at Stanford NLP. However, GloVe vectors are huge; the largest one (840 billion tokens at 300D) is 5.65 GB on disk and may hit issues when loaded into memory on less-powerful computers.&lt;/p&gt;

&lt;p&gt;Why not work &lt;em&gt;backwards&lt;/em&gt; and calculate &lt;em&gt;character&lt;/em&gt; embeddings? Then you could calculate a relatively few amount of vectors which would easily fit into memory, and use those to derive word vectors, which can then be used to derive the sentence/paragraph/document/etc vectors. But training character embeddings traditionally is significantly more computationally expensive since there are 5-6x the amount of tokens, and I don&amp;rsquo;t have access to the supercomputing power of Stanford researchers.&lt;/p&gt;

&lt;p&gt;Why not use the &lt;em&gt;existing&lt;/em&gt; pretrained word embeddings to extrapolate the corresponding character embeddings within the word? Think &amp;ldquo;&lt;a href=&quot;https://en.wikipedia.org/wiki/Bag-of-words_model&quot;&gt;bag-of-words&lt;/a&gt;,&amp;rdquo; except &amp;ldquo;bag-of-characters.&amp;rdquo; For example, from the embeddings from the word &amp;ldquo;the&amp;rdquo;, we can infer the embeddings for &amp;ldquo;t&amp;rdquo;, &amp;ldquo;h,&amp;rdquo; and &amp;ldquo;e&amp;rdquo; from the parent word, and average the t/h/e vectors from &lt;em&gt;all&lt;/em&gt; words/tokens in the dataset corpus. (For this post, I will only look at the 840B/300D dataset since that is the only one with capital letters, which are rather important. If you want to use a dataset with smaller dimensionality, apply &lt;a href=&quot;https://en.wikipedia.org/wiki/Principal_component_analysis&quot;&gt;PCA&lt;/a&gt; on the final results)&lt;/p&gt;

&lt;p&gt;I wrote a &lt;a href=&quot;https://github.com/minimaxir/char-embeddings/blob/master/create_embeddings.py&quot;&gt;simple Python script&lt;/a&gt; that takes in the specified pretrained word embeddings and does just that, &lt;a href=&quot;https://github.com/minimaxir/char-embeddings/blob/master/glove.840B.300d-char.txt&quot;&gt;outputting the character embeddings&lt;/a&gt; in the same format. (for simplicity, only ASCII characters are included; the &lt;a href=&quot;https://en.wikipedia.org/wiki/Extended_ASCII&quot;&gt;extended ASCII characters&lt;/a&gt; are  intentionally omitted due to compatibility reasons. Additionally, by construction, space and newline characters are not represented in the derived dataset.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/char-embeddings.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;You may be thinking that I&amp;rsquo;m cheating. So let&amp;rsquo;s set a point-of-reference. Colin Morris &lt;a href=&quot;http://colinmorris.github.io/blog/1b-words-char-embeddings&quot;&gt;found&lt;/a&gt; that when 16D character embeddings from a model used in Google&amp;rsquo;s &lt;a href=&quot;https://arxiv.org/abs/1312.3005&quot;&gt;One Billion Word Benchmark&lt;/a&gt; are projected into a 2D space via t-SNE, patterns emerge: digits are close, lowercase and uppercase letters are often paired, and punctuation marks are loosely paired.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/tsne_embeddings.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s do that for my derived character embeddings, but with &lt;a href=&quot;https://www.r-project.org&quot;&gt;R&lt;/a&gt; and &lt;a href=&quot;http://docs.ggplot2.org/current/&quot;&gt;ggplot2&lt;/a&gt;. t-SNE is &lt;a href=&quot;http://distill.pub/2016/misread-tsne/&quot;&gt;difficult to use&lt;/a&gt; for high-dimensional vectors as combinations of parameters can result in wildly different output, so let&amp;rsquo;s try a couple projections. Here&amp;rsquo;s what happens when my pretrained projections are preprojected from 300D to 16D via &lt;a href=&quot;http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/&quot;&gt;PCA whitening&lt;/a&gt;, and setting perplexity (number of optimal neighbors) to 7.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/char-tsne.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The algorithm manages to separate and group lowercase, uppercase, and numerals rather distinctly. Quadrupling the dimensionality of the preprocessing step to 64D and changing perplexity to 2 generates a depiction closer to the Google model projection:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/char-tsne-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;My pretrained character embeddings trick isn&amp;rsquo;t academic, but it&amp;rsquo;s successfully identifying realistic relationships. There might be something here worthwhile.&lt;/p&gt;

&lt;h2&gt;The Coolness of Deep Learning&lt;/h2&gt;

&lt;p&gt;Keras, maintained by Google employee &lt;a href=&quot;https://twitter.com/fchollet&quot;&gt;François Chollet&lt;/a&gt;, is so good that it is effectively cheating in the field of machine learning, where even TensorFlow tutorials can be replaced with a single line of code. (which is important for iteration; Keras layers are effectively Lego blocks). A simple read of the &lt;a href=&quot;https://github.com/fchollet/keras/tree/master/examples&quot;&gt;Keras examples&lt;/a&gt; and &lt;a href=&quot;https://keras.io/&quot;&gt;documentation&lt;/a&gt; will let you reverse-engineer most the revolutionary deep learning clickbait thought pieces. Some create entire startups by changing the source dataset of the Keras examples and pitch them to investors none-the-wiser, or make very light wrappers on top the examples for teaching tutorial videos and get thousands of subscribers on YouTube.&lt;/p&gt;

&lt;p&gt;I prefer to parse documentation/examples as a proof-of-concept, but never as gospel. Examples are often not the most efficient ways to implement a solution to a problem, just merely a start. In the case of Keras&amp;rsquo;s &lt;a href=&quot;https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py&quot;&gt;text generator example&lt;/a&gt;, the initial code was likely modeled after the 2015 blog post &lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt; by Andrej Karpathy and the corresponding project &lt;a href=&quot;https://github.com/karpathy/char-rnn&quot;&gt;char-rnn&lt;/a&gt;. There have been many new developments in neural network architecture since 2015 that can improve both speed and performance of the text generation model as a whole.&lt;/p&gt;

&lt;h2&gt;What Text to Generate?&lt;/h2&gt;

&lt;p&gt;The Keras example uses &lt;a href=&quot;https://en.wikipedia.org/wiki/Friedrich_Nietzsche&quot;&gt;Nietzsche&lt;/a&gt; writings as a data source, which I&amp;rsquo;m not fond of because it&amp;rsquo;s difficult to differentiate bad autogenerated Nietzsche rants from actual Nietzsche rants. What I want to generate is text with &lt;em&gt;rules&lt;/em&gt;, with the algorithm being judged by how well it follows an inherent structure. My idea is to create &lt;a href=&quot;http://magic.wizards.com/en&quot;&gt;Magic: The Gathering&lt;/a&gt; cards.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/dragon-whelp.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Inspired by the &lt;a href=&quot;https://twitter.com/RoboRosewater&quot;&gt;@RoboRosewater&lt;/a&gt; Twitter account by Reed Milewicz and the &lt;a href=&quot;http://www.mtgsalvation.com/forums/creativity/custom-card-creation/612057-generating-magic-cards-using-deep-recurrent-neural&quot;&gt;corresponding research&lt;/a&gt; and &lt;a href=&quot;https://motherboard.vice.com/en_us/article/the-ai-that-learned-magic-the-gathering&quot;&gt;articles&lt;/a&gt;, I aim to see if it&amp;rsquo;s possible to recreate the structured design creativity for myself.&lt;/p&gt;

&lt;p&gt;Even if you are not familiar with Magic and its rules, you can still find the &lt;a href=&quot;https://twitter.com/RoboRosewater/status/756198572282949632&quot;&gt;card text&lt;/a&gt; of RoboRosewater cards hilarious:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/horse.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Occasionally RoboRosewater, using a weaker model, produces amusing &lt;a href=&quot;https://twitter.com/RoboRosewater/status/689184317721960448&quot;&gt;neural network trainwrecks&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/carl.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;More importantly, all Magic cards have an explicit structure; they have a name, mana cost in the upper-right, card type, card text, and usually a power and toughness in the bottom-right.&lt;/p&gt;

&lt;p&gt;I wrote &lt;a href=&quot;https://github.com/minimaxir/char-embeddings/blob/master/create_magic_text.py&quot;&gt;another Python script&lt;/a&gt; to parse all Magic card data from &lt;a href=&quot;https://mtgjson.com&quot;&gt;MTG JSON&lt;/a&gt; into an encoding which matches this architecture, where each section transition has its own symbol delimiter, along with other encoding simplicities. For example, here is the card &lt;a href=&quot;http://gatherer.wizards.com/Pages/Card/Details.aspx?multiverseid=247314&quot;&gt;Dragon Whelp&lt;/a&gt; in my encoding:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[Dragon Whelp@{2}{R}{R}#Creature — Dragon$Flying|{R}: ~ gets +1/+0 until end of turn. If this ability has been activated four or more times this turn, sacrifice ~ at the beginning of the next end step.%2^3]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;These card encodings are all combined into one .txt file, which will be fed into the model.&lt;/p&gt;

&lt;h2&gt;Building and Training the Model&lt;/h2&gt;

&lt;p&gt;The Keras text generation example operates by breaking a given .txt file into 40-character sequences, and the model tries to predict the 41st character by outputting a probability for each possible character (108 in this dataset). For example, if the input based on the above example is &lt;code&gt;[&amp;#39;D&amp;#39;, &amp;#39;r&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;g&amp;#39;, ..., &amp;#39;D&amp;#39;, &amp;#39;r&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;g&amp;#39;]&lt;/code&gt; (with the latter Drag being part of the creature type), the model will optimize for outputting a probability of 1.0 of &lt;code&gt;o&lt;/code&gt;; per the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression&quot;&gt;categorical crossentropy&lt;/a&gt; loss function, the model is rewarded for assigning correct guesses with 1.0 probability and incorrect guesses with 0.0 probabilities, penalizing half-guesses and wrong guesses.&lt;/p&gt;

&lt;p&gt;Each possible 40-character sequence is collected, however only every other third sequence is kept; this prevents the model from being able to learn card text verbatim, plus it also makes training faster. (for this model, there are about &lt;strong&gt;1 million&lt;/strong&gt; sequences for the final training). The example uses only a 128-node &lt;a href=&quot;https://en.wikipedia.org/wiki/Long_short-term_memory&quot;&gt;long-short-term-memory&lt;/a&gt; (LSTM) &lt;a href=&quot;https://en.wikipedia.org/wiki/Recurrent_neural_network&quot;&gt;recurrent neural network&lt;/a&gt; (RNN) layer, popular for incorporating a &amp;ldquo;memory&amp;rdquo; into a neural network model, but the example notes at the beginning it can take awhile to train before generated text is coherent.&lt;/p&gt;

&lt;p&gt;There are a few optimizations we can make. Instead of supplying the characters directly to the RNN, we can first encode them using an &lt;a href=&quot;https://keras.io/layers/embeddings/&quot;&gt;Embedding layer&lt;/a&gt; so the model can train character context. We can stack more layers on the RNN by adding a 2-level &lt;a href=&quot;https://en.wikipedia.org/wiki/Multilayer_perceptron&quot;&gt;multilayer perceptron&lt;/a&gt;: a &lt;a href=&quot;https://www.reddit.com/r/ProgrammerHumor/comments/5si1f0/machine_learning_approaches/&quot;&gt;meme&lt;/a&gt;, yes, but it helps, as the network must learn latent representations of the data. Thanks to recent developments such as &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;batch normalization&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Rectifier_(neural_networks)&quot;&gt;rectified linear activations&lt;/a&gt; for these &lt;a href=&quot;https://keras.io/layers/core/#dense&quot;&gt;Dense layers&lt;/a&gt;, they can both be trained without as much computational overhead, and thanks to Keras, both can be added to a layer with a single line of code each. Lastly, we can add an auxiliary output via Keras&amp;rsquo;s &lt;a href=&quot;https://keras.io/models/model/&quot;&gt;functional API&lt;/a&gt; where the network makes a prediction based on only the output from the RNN in addition to the main output, which forces it to work smarter and ends up resulting in a &lt;em&gt;significant&lt;/em&gt; improvement in loss for the main path.&lt;/p&gt;

&lt;p&gt;The final architecture ends up looking like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/model.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;And because we added an Embedding layer, we can load the pretrained 300D character embeds I made earlier, giving the model a good start in understanding character relationships.&lt;/p&gt;

&lt;p&gt;The goal of the training is to minimize the total loss of the model. (but for evaluating model performance, we only look at the loss of the main output). The model is trained in &lt;strong&gt;epochs&lt;/strong&gt;, where the model sees all the input data atleast once. During each epoch, batches of size 128 are loaded into the model and evaluated, calculating a &lt;strong&gt;batch loss&lt;/strong&gt; for each; the gradients from the batch are backpropagated into the previous layers to improve them. While training with Keras, the console reports an &lt;strong&gt;epoch loss&lt;/strong&gt;, which is the average of all the batch losses so far in the current epoch, allowing the user to see in real time how the model improves, and it&amp;rsquo;s addicting.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/keras-training.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Keras/TensorFlow works just fine on the CPU, but for models with a RNN, you&amp;rsquo;ll want to consider using a GPU for performance, specifically one by nVidia. Amazon has cloud GPU instances for $0.90/hr (&lt;a href=&quot;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html&quot;&gt;not prorated&lt;/a&gt;), but very recently, Google announced &lt;a href=&quot;https://cloud.google.com/compute/docs/gpus/add-gpus&quot;&gt;GPU instances&lt;/a&gt; of the same caliber for ~$0.75/hr (prorated to the minute), which is what I used to train this model, although Google Compute Engine requires configuring the GPU drivers first. For 20 epochs, it took about 4 hours and 20 minutes to train the model while spending $3.26, which isn&amp;rsquo;t bad as far as deep learning goes.&lt;/p&gt;

&lt;h2&gt;Making Magic&lt;/h2&gt;

&lt;p&gt;After each epoch, the original Keras text generation example takes a sentence from the input data as a seed and predicts the next character in the sequence according to the model, then uses the last 40 characters generated for the next character, etc. The sampling incorporates a diversity/temperature parameter which allows the model to make suboptimal decisions and select characters with lower natural probabilities, which allows for the romantic &amp;ldquo;creativity&amp;rdquo; popular with neural network text generation.&lt;/p&gt;

&lt;p&gt;With the Magic card dataset and my tweaked model architecture, generated text is coherent &lt;a href=&quot;https://github.com/minimaxir/char-embeddings/blob/master/output/iter-01-0_9204.txt&quot;&gt;after the 1st epoch&lt;/a&gt;! After about 20 epochs, training becomes super slow, but the predicted text becomes super interesting. Here are a few fun examples from a &lt;a href=&quot;https://github.com/minimaxir/char-embeddings/blob/master/output/text_sample.txt&quot;&gt;list of hundreds of generated cards&lt;/a&gt;. (Note: the power/toughness values at the end of the card have issues; more on that later).&lt;/p&gt;

&lt;p&gt;With low diversity, the neural network generated cards that are oddly biased toward card names which include the letter &amp;ldquo;S&amp;rdquo;. The card text also conforms to the rules of the game very well.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[Reality Spider@{3}{G}#Creature — Elf Warrior$Whenever ~ deals combat damage to a player, put a +1/+1 counter on it.%^]
[Dark Soul@{2}{R}#Instant$~ deals 2 damage to each creature without flying.%^]
[Standing Stand@{2}{G}#Creature — Elf Shaman${1}{G}, {T}: Draw a card, then discard a card.%^]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In contrast, cards generated with high diversity hit the uncanny valley of coherence and incoherence in both text and game mechanic abuse, which is what makes them interesting. &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[Portrenline@{2}{R}#Sorcery$As an additional cost to cast ~, exile ~.%^]
[Clocidian Lorid@{W}{W}{W}#Instant$Regenerate each creature with flying and each player.%^]
[Icomic Convermant@{3}{G}#Sorcery$Search your library for a land card in your graveyard.%1^1]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The best-of-both-worlds cards are generated from diversity parameters between both extremes, and often have funny names.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[Seal Charm@{W}{W}#Instant$Exile target creature. Its controller loses 1 life.%^]
[Shambling Assemblaster@{4}{W}#Creature — Human Cleric$When ~ enters the battlefield, destroy target nonblack creature.%1^1]
[Lightning Strength@{3}{R}#Enchantment — Aura$Enchant creature|Enchanted creature gets +3/+3 and has flying, flying, trample, trample, lifelink, protection from black and votile all damage unless you return that card to its owner&amp;#39;s hand.%2^2]
[Skysor of Shadows@{7}{B}{B}{B}#Enchantment$As ~ enters the battlefield, choose one —|• Put a -1/-1 counter on target creature.%2^2]
[Glinding Stadiers@{4}{W}#Creature — Spirit$Protection from no creatures can&amp;#39;t attack.%^]
[Dragon Gault@{3}{G}{U}{U}#Creature — Kraven$~&amp;#39;s power and toughness are 2.%2^2]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;All Keras/Python code used in this blog post, along with sample Magic card output and the trained model itself, is available open-source &lt;a href=&quot;https://github.com/minimaxir/char-embeddings&quot;&gt;in this GitHub repository&lt;/a&gt;. The repo additionally contains &lt;a href=&quot;https://github.com/minimaxir/char-embeddings/blob/master/text_generator_keras_sample.py&quot;&gt;a Python script&lt;/a&gt; which lets you generate new cards using the model, too!&lt;/p&gt;

&lt;h2&gt;Visualizing Model Performance&lt;/h2&gt;

&lt;p&gt;One thing deep learning tutorials rarely mention is &lt;em&gt;how&lt;/em&gt; to collect the loss data and visualize the change in loss over time. Thanks to Keras&amp;rsquo;s &lt;a href=&quot;https://keras.io/callbacks/&quot;&gt;utility functions&lt;/a&gt;, I wrote a custom model callback which collects the batch losses and epoch losses and writes them to a CSV file.&lt;/p&gt;

&lt;p&gt;Using R and ggplot2, I can plot the batch loss at every 50th batch to visualize how the model converges over time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/batch-losses.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;After 20 epochs, the model loss ends up at about &lt;strong&gt;0.30&lt;/strong&gt; which is more-than-low-enough for coherent text. As you can see, there are large diminishing returns after a few epochs, which is the hard part of training deep learning models.&lt;/p&gt;

&lt;p&gt;Plotting the epoch loss over the batches makes the trend more clear.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/epoch-losses.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In order to prevent early convergence, we can make the model more complex (i.e. stack more layers unironically), but that has trade-offs, both in training &lt;em&gt;and&lt;/em&gt; predictive speed, the latter of which is important if using deep learning in a production application.&lt;/p&gt;

&lt;p&gt;Lastly, as with the Google One Billion Words benchmark, we can extract the &lt;a href=&quot;https://github.com/minimaxir/char-embeddings/blob/master/output/char-embeddings.txt&quot;&gt;trained character embeddings&lt;/a&gt; from the model (now augmented with Magic card context!) and plot them again to see what has changed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/char-embeddings/char-tsne-embed.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;There are more pairs of uppercase/lowercase characters, although  interestingly there isn&amp;rsquo;t much grouping with the special characters added as section breaks in the encoding, or mechanical uppercase characters such as W/U/B/R/G/C/T.&lt;/p&gt;

&lt;h2&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;After building the model, I did a little more research to see if others solved the power/toughness problem. Since the sentences are only 40 characters and Magic cards are much longer than 40 characters, it&amp;rsquo;s likely that power/toughness are out-of-scope for the model and it cannot learn their exact values. Turns out that the intended solution is to use a &lt;a href=&quot;https://github.com/billzorn/mtgencode&quot;&gt;completely different encoding&lt;/a&gt;, such as this one for Dragon Whelp:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;|5creature|4|6dragon|7|8&amp;amp;^^/&amp;amp;^^^|9flying\{RR}: @ gets +&amp;amp;^/+&amp;amp; until end of turn. if this ability has been activated four or more times this turn, sacrifice @ at the beginning of the next end step.|3{^^RRRR}|0N|1dragon whelp|
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Power/toughness are generated near the &lt;em&gt;beginning&lt;/em&gt; of the card. Sections are delimited by pipes, with a numeral designating the corresponding section. Instead of numerals being used card values, carets are used, which provides a more accurate &lt;em&gt;quantification&lt;/em&gt; of values. With this encoding, each character has a &lt;em&gt;singular purpose&lt;/em&gt; in the global card context, and their embeddings would likely generate more informative visualizations. (But as a consequence, the generated cards are harder to parse at a glance).&lt;/p&gt;

&lt;p&gt;The secondary encoding highlights a potential flaw in my methodology using pretrained character embeddings. Trained machine learning models must be used apples-to-apples on similar datasets; for example, you can&amp;rsquo;t accurately perform Twitter &lt;a href=&quot;https://en.wikipedia.org/wiki/Sentiment_analysis&quot;&gt;sentiment analysis&lt;/a&gt; on a dataset using a model trained on professional movie reviews since Tweets do not follow &lt;a href=&quot;https://owl.english.purdue.edu/owl/resource/735/02/&quot;&gt;AP Style&lt;/a&gt; guidelines. In my case, the &lt;a href=&quot;http://commoncrawl.org&quot;&gt;Common Crawl&lt;/a&gt;, the source of the pretrained embeddings, follows more natural text usage and would not work analogously with the atypical character usages in &lt;em&gt;either&lt;/em&gt; of the Magic card encodings.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s still a &lt;em&gt;lot&lt;/em&gt; of work to be done in terms of working with both pretrained character embeddings and improving Magic card generation, but I believe there is promise. The better way to make character embeddings than my script is to do it the hard way and train then manually, maybe even at a higher dimensionality like 500D or 1000D. Likewise, for Magic model building, the &lt;a href=&quot;https://github.com/billzorn/mtgencode#training-a-neural-net&quot;&gt;mtg-rnn instructions&lt;/a&gt; repo uses a large LSTM stacked on a LSTM along with 120/200-character sentences, both of which combined make training &lt;strong&gt;VERY&lt;/strong&gt; slow (notably, this was the architecture of the &lt;a href=&quot;https://github.com/fchollet/keras/commit/d2b229df2ea0bab712379c418115bc44508bc6f9#diff-904d72bcf9fa38b32f9c1f868ff59367&quot;&gt;very first commit&lt;/a&gt; for the Keras text generation example, and &lt;a href=&quot;https://github.com/fchollet/keras/commit/01d5e7bc4782daafcfa99e035c1bdbe13a985145&quot;&gt;was changed&lt;/a&gt; to the easily-trainable architecture). There is also promise in a &lt;a href=&quot;http://kvfrans.com/variational-autoencoders-explained/&quot;&gt;variational autoencoder&lt;/a&gt; approach, such as with &lt;a href=&quot;https://arxiv.org/abs/1702.02390&quot;&gt;textvae&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This work is potentially very expensive and I am strongly considering setting up a &lt;a href=&quot;https://www.patreon.com&quot;&gt;Patreon&lt;/a&gt; in lieu of excess venture capital to subsidize my machine learning/deep learning tasks in the future.&lt;/p&gt;

&lt;p&gt;At minimum, working with this example gave me a sufficient application of practical work with Keras, and another tool in my toolbox for data analysis and visualization. Keras makes the model-construction aspect of deep learning trivial and not scary. Hopefully, this article justifies the use of the &amp;ldquo;deep learning&amp;rdquo; buzzword in the headline.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s also worth mentioning that I actually started working on automatic text generation 6 months ago using a different, non-deep-learning approach, but hit a snag and abandoned that project. With my work on Keras, I found a way around that snag, and on the same Magic dataset with the same input construction, I obtained a model loss of &lt;strong&gt;0.03&lt;/strong&gt; at &lt;strong&gt;20% of the cloud computing cost&lt;/strong&gt; in about the same amount of time. More on that later.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;The code for generating the R/ggplot2 data visualizations is available in this &lt;a href=&quot;http://minimaxir.com/notebooks/char-tsne/&quot;&gt;R Notebook&lt;/a&gt;, and open-sourced in &lt;a href=&quot;https://github.com/minimaxir/char-tsne-visualization&quot;&gt;this GitHub Repository.&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the automatic text generation scripts and data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 04 Apr 2017 06:30:00 -0700</pubDate>
        <link>http://minimaxir.com/2017/04/char-embeddings/</link>
        <guid isPermaLink="true">http://minimaxir.com/2017/04/char-embeddings/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Predicting And Mapping Arrest Types in San Francisco with LightGBM, R, ggplot2</title>
        <description>&lt;p&gt;The new hotness in the world of data science is &lt;a href=&quot;https://en.wikipedia.org/wiki/Artificial_neural_network&quot;&gt;neural networks&lt;/a&gt;, which form the basis of &lt;a href=&quot;https://en.wikipedia.org/wiki/Deep_learning&quot;&gt;deep learning&lt;/a&gt;. But while everyone is obsessing about neural networks and how deep learning is &lt;em&gt;magic&lt;/em&gt; and can solve &lt;em&gt;any&lt;/em&gt; problem if you just &lt;a href=&quot;https://www.reddit.com/r/ProgrammerHumor/comments/5si1f0/machine_learning_approaches/&quot;&gt;stack enough layers&lt;/a&gt;, there have been many recent developments in the relatively nonmagical world of machine learning with &lt;em&gt;boring&lt;/em&gt; CPUs.&lt;/p&gt;

&lt;p&gt;Years before neural networks were the Swiss army knife of data science, there were &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_boosting&quot;&gt;gradient-boosted machines&lt;/a&gt;/&lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting&quot;&gt;gradient-boosted trees&lt;/a&gt;. GBMs/GBTs are machine learning methods which are effective on many types of data, and do not require the &lt;a href=&quot;http://r-statistics.co/Assumptions-of-Linear-Regression.html&quot;&gt;traditional model assumptions&lt;/a&gt; of linear/logistic regression models. Wikipedia has a good article on the advantages of &lt;a href=&quot;https://en.wikipedia.org/wiki/Decision_tree_learning&quot;&gt;decision tree learning&lt;/a&gt;, and visual diagrams of the architecture:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/CART_tree_titanic_survivors.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;GBMs, as &lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html&quot;&gt;implemented&lt;/a&gt; in the Python package &lt;a href=&quot;http://scikit-learn.org/stable/&quot;&gt;scikit-learn&lt;/a&gt;, are extremely popular in &lt;a href=&quot;https://www.kaggle.com&quot;&gt;Kaggle&lt;/a&gt; machine learning competitions. But scikit-learn is relatively old, and new technologies have emerged which implement GBMs/GBTs on large datasets with massive parallelization and and in-memory computation. A popular big data machine learning library, &lt;a href=&quot;http://www.h2o.ai&quot;&gt;H2O&lt;/a&gt;, has a &lt;a href=&quot;http://docs.h2o.ai/h2o-tutorials/latest-stable/tutorials/gbm-randomforest/index.html&quot;&gt;famous GBM implementation&lt;/a&gt; which, &lt;a href=&quot;https://github.com/szilard/benchm-ml&quot;&gt;per benchmarks&lt;/a&gt;, is over 10x faster than scikit-learn and is optimized for datasets with millions of records. But even &lt;em&gt;faster&lt;/em&gt; than H2O is &lt;a href=&quot;https://github.com/dmlc/xgboost&quot;&gt;xgboost&lt;/a&gt;, which can hit a 5x-10x speed-ups relative to H2O, depending on the dataset size.&lt;/p&gt;

&lt;p&gt;Enter &lt;a href=&quot;https://github.com/Microsoft/LightGBM&quot;&gt;LightGBM&lt;/a&gt;, a new (October 2016) open-source machine learning framework by &lt;a href=&quot;https://www.microsoft.com/en-us/&quot;&gt;Microsoft&lt;/a&gt; which, per &lt;a href=&quot;https://github.com/Microsoft/LightGBM/issues/211&quot;&gt;benchmarks&lt;/a&gt; on release, was up to &lt;em&gt;4x faster&lt;/em&gt; than xgboost! (xgboost very recently implemented a &lt;a href=&quot;https://github.com/dmlc/xgboost/issues/1950&quot;&gt;technique&lt;/a&gt; also used in LightGBM, which reduced the relative speedup to just ~2x). As a result, LightGBM allows for very efficient model building on large datasets without requiring cloud computing or nVidia CUDA GPUs.&lt;/p&gt;

&lt;p&gt;A year ago, I &lt;a href=&quot;http://minimaxir.com/2015/12/sf-arrests/&quot;&gt;wrote an analysis&lt;/a&gt; of the types of police arrests in San Francisco, using data from the &lt;a href=&quot;https://data.sfgov.org&quot;&gt;SF OpenData&lt;/a&gt; initiative, with a &lt;a href=&quot;http://minimaxir.com/2015/12/sf-arrest-maps/&quot;&gt;followup article&lt;/a&gt; analyzing the locations of these arrests. Months later, the same source dataset was used &lt;a href=&quot;https://www.kaggle.com/c/sf-crime&quot;&gt;for a Kaggle competition&lt;/a&gt;. Why not give the dataset another look and test LightGBM out?&lt;/p&gt;

&lt;h2&gt;Playing With The Data&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;(You can view the R code used to process the data and generate the data visualizations in &lt;a href=&quot;http://minimaxir.com/notebooks/predicting-arrests/&quot;&gt;this R Notebook&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://data.sfgov.org/Public-Safety/SFPD-Incidents-from-1-January-2003/tmnf-yvry&quot;&gt;SFPD Incidents&lt;/a&gt; dataset includes crime incidents in San Francisco from 1/1/2003 to 1/17/2017 (at time of analysis). Filtering the dataset only on incidents which resulted in arrests (since most incidents are trivial) leaves a dataset of 634,299 arrests total. The dataset also includes information on the type of crime, the location where the arrest occurred, and the date/time. There are 39 different types of arrests in the &lt;strong&gt;Category&lt;/strong&gt; column such as Assault, Burglary, and Prostitution, which serves as the response variable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/data.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Meanwhile, we can engineer features from the location and date/time. 
Performing an exploratory data analysis of both is helpful to determine at a glance which features may be relevant (fortunately, I did that a year ago).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/sf-arrests/sf-arrest-when-4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The location is given as latitude/longitude coordinates, so we can select a longitude &lt;strong&gt;X&lt;/strong&gt; and latitude &lt;strong&gt;Y&lt;/strong&gt; as features. Date/Time can be deconstructed further. We can extract the &lt;strong&gt;hour&lt;/strong&gt; in which a given arrest occurred as a feature (hour can take 24 different values from 0 — 23). Likewise, we can extract the &lt;strong&gt;month&lt;/strong&gt; in a similar manner (12 values, from 1 — 12). The &lt;strong&gt;year&lt;/strong&gt; the crime occurred can be extracted without special encoding. (2003 — 2017). It is always helpful to include a year feature in predictive models to help account for change over time. The &lt;strong&gt;DayOfWeek&lt;/strong&gt; is important, but encoding it as a numeric value is tricker; we logically encode each day of the week from 1 — 7, but which day should be #1? Making Monday #1 and Sunday #7 is the most logical, since a decision tree rule that sets a threshold on DayOfWeek values &amp;gt; 5 will translate logically to a weekend.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/predict_matrix.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s six features total. There are more features which could be helpful, but let&amp;rsquo;s check a baseline model as a start.&lt;/p&gt;

&lt;h2&gt;Modeling&lt;/h2&gt;

&lt;p&gt;Specifically, the model will predict the answer the question: &lt;em&gt;given that a San Francisco police arrest occurs at a specified time and place, what is the reason for that arrest?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For this post, I will use the &lt;a href=&quot;https://github.com/Microsoft/LightGBM/tree/master/R-package&quot;&gt;R package&lt;/a&gt; for LightGBM (which was beta-released in January 2017; it&amp;rsquo;s &lt;em&gt;extremely&lt;/em&gt; cutting edge!) We split the dataset 70%/30% into a training set of 444,011 arrests and a test set of 190,288 arrests (due to the large amount of different category labels, the split must be &lt;a href=&quot;https://en.wikipedia.org/wiki/Stratified_sampling&quot;&gt;stratified&lt;/a&gt; to ensure the training and test sets have a balanced distribution of labels; in R, this can be implemented with the &lt;code&gt;caret&lt;/code&gt; package and &lt;code&gt;createDataPartition&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;LightGBM trains the model on the training set and evaluates it on the test set to minimize the &lt;a href=&quot;https://www.kaggle.com/c/sf-crime#evaluation&quot;&gt;multiclass logarithmic loss&lt;/a&gt; of the model. For now, I use the &lt;a href=&quot;https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.md&quot;&gt;default parameters&lt;/a&gt; of LightGBM, except to massively increase the number of iterations of the training algorithm, and to stop training the model early if the model stops improving. After about 4 minutes on my laptop (which is very fast for a dataset of this size!), the model returns a multilogloss of &lt;strong&gt;1.98&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;That number sounds arbitrary. Is it good or bad? Let&amp;rsquo;s compare it to the multilogloss from the &lt;a href=&quot;https://www.kaggle.com/c/sf-crime/leaderboard&quot;&gt;top models&lt;/a&gt; from the Kaggle version of the dataset, where a lower score is better:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/kaggle.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;okay, 1.98 &lt;em&gt;is&lt;/em&gt; a good score, and without spending much time adding features to the model and &lt;a href=&quot;https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters-tuning.md&quot;&gt;tuning parameters&lt;/a&gt;! To be fair, my methodology would not necessarily result in the same score on the Kaggle dataset, but it confirms that the LightGBM model is in the top tier of models available for this problem and dataset context. And it didn&amp;rsquo;t &lt;a href=&quot;https://www.kaggle.com/smerity/sf-crime/fighting-crime-with-keras/output&quot;&gt;require any neural networks&lt;/a&gt; either!&lt;/p&gt;

&lt;p&gt;There are areas for improvement in feature engineering which &lt;a href=&quot;https://www.kaggle.com/c/sf-crime/kernels&quot;&gt;other entries&lt;/a&gt; in the Kaggle competition implemented, such as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Dummy_variable_(statistics)&quot;&gt;dummy variable&lt;/a&gt; indicating whether the offense occurred at an intersection and which SF police station was involved in the arrest. We could also encode features such as hour and DayOfWeek as categorical features (LightGBM conveniently allows this without requiring &lt;a href=&quot;https://en.wikipedia.org/wiki/One-hot&quot;&gt;one-hot encoding&lt;/a&gt; the features) instead of numeric, but in my brief testing, it made the model &lt;em&gt;worse&lt;/em&gt;, interestingly.&lt;/p&gt;

&lt;h2&gt;Analyzing the LightGBM Model&lt;/h2&gt;

&lt;p&gt;Another perk of not using a neural network for statistical model building is the ability to learn more about the importance of features in a model, as opposed to it being a &lt;a href=&quot;https://en.wikipedia.org/wiki/Black_box&quot;&gt;black box&lt;/a&gt;. In the case of gradient boosting, we can calculate the proportional contribution of each feature to the total &lt;a href=&quot;https://en.wikipedia.org/wiki/Information_gain_in_decision_trees&quot;&gt;information gain&lt;/a&gt; of the model, which will help identify the most important features, and potentially unhelpful features:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/imp.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Unsurprisingly, location features are the most important, with both location-based features establishing 70% of the total Gain in the model. But no feature is completely insignificant, which is a good thing.&lt;/p&gt;

&lt;p&gt;Back to the multilogloss of 1.98. What does that mean in the real world? What is the &lt;em&gt;accuracy&lt;/em&gt; of the model? We run each of the 190,288 arrests in the test set against the model, which returns 39 probability values for each record: one for each possible category of arrest. The category with the highest probability becomes the &lt;strong&gt;predicted&lt;/strong&gt; type of arrest.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/predicted_results.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The accuracy of the model on the test set, which is the proportion of predictions where the predicted category value matches the &lt;strong&gt;actual&lt;/strong&gt; category value, is &lt;strong&gt;39.7%&lt;/strong&gt;, with a 95% confidence interval for the true accuracy between 39.5% and 39.9%. That seems low! However, there is catch-all &amp;ldquo;Other Offenses&amp;rdquo; category for an arrest; if you predicted a &amp;ldquo;Other Offenses&amp;rdquo; label for all the test-set values, you would get an accuracy of &lt;em&gt;31.1%&lt;/em&gt;, which serves as the No Information Rate (since it would be the highest accuracy approach if there was no information at all). A 8.6 percentage point improvement is still an improvement though; many industries would &lt;em&gt;love&lt;/em&gt; an 8.6 percentage point increase in accuracy, but for this context obviously it&amp;rsquo;s not enough to usher in a &lt;a href=&quot;https://en.wikipedia.org/wiki/Minority_Report_(film)&quot;&gt;Minority Report&lt;/a&gt;/&lt;a href=&quot;https://en.wikipedia.org/wiki/Person_of_Interest_(TV_series)&quot;&gt;Person of Interest&lt;/a&gt; future.&lt;/p&gt;

&lt;p&gt;We can visualize the classifications on the test set by the model using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;confusion matrix&lt;/a&gt;; &lt;code&gt;caret&lt;/code&gt; has a simple &lt;code&gt;confusionMatrix()&lt;/code&gt; function, and ggplot2 has a &lt;code&gt;geom_tile()&lt;/code&gt; to map out the relationships, even with 39 classes. We can also annotate the tiles where actual label = predicted label by drawing a &lt;code&gt;geom_point()&lt;/code&gt; on top. Putting it all together:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/confusionMatrix.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;There is, indeed, a large amount of confusion. Many of the labels are mispredicted as Other Offenses. Specifically, the model frequently confuses the combinations of Assault, Drug/Narcotics, Larceny/Theft, and Warrants, suggesting that they also may be catch-alls.&lt;/p&gt;

&lt;p&gt;In theory, the predicted probabilities from the model between similar types of crime should also be similar, which may be causing these mispredictions. We can calculate the &lt;a href=&quot;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&quot;&gt;Pearson correlations&lt;/a&gt; between the predicted probabilities, and use &lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_clustering&quot;&gt;hierarchical clustering&lt;/a&gt; to &lt;a href=&quot;http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization&quot;&gt;arrange and plot the correlations&lt;/a&gt; and their labels in a logical order. The majority of the correlations between labels are between 0 and +/- 0.5 (weak to moderate), but their arrangement tells a different story:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/correlationMatrix.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;From top to bottom, you can see that there is a grouping of more blue-collar, physical crimes types (Assault, Vandalism), then a grouping of less-physical, white-collar crime types (Bribery, Extortion), and then a smaller grouping of seedier crime types (Liquor Laws, Prostitution).&lt;/p&gt;

&lt;p&gt;The visualization doesn&amp;rsquo;t necessarily provide more information about the confusion matrix and the mispredictions, but &lt;em&gt;it looks cool&lt;/em&gt;, which is enough.&lt;/p&gt;

&lt;h2&gt;Mapping the Predicted Types of Arrests&lt;/h2&gt;

&lt;p&gt;Kaggle competitions emphasize model creation, but don&amp;rsquo;t discuss how to implement and execute models in practice. Since we can predict the type of crime based on the given location and date/time of an arrest, we can map boundaries of the mostly likely type of offense. Using &lt;code&gt;ggmap&lt;/code&gt; to get a map of San Francisco, splitting San Francisco into tens of thousands of points, and predicting the most-likely type of arrest at the location with a given date/time.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s say we want to predict the types of crime in the future, on April 15th, 2017, during 8 PM. We construct a dataset of those points and the same date/time features used to generate the model originally. Then run those fabricated points through the model again to get new predicted labels (Additionally, we need to remove &amp;ldquo;Other Offenses&amp;rdquo; predicted labels since they cloud up the map). Plotting each point as a &lt;code&gt;geom_tile&lt;/code&gt; will interpolate regions around the city. Putting it all together:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/crime-2017-04-15-20.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Not too shabby. But that&amp;rsquo;s not all; we can &lt;em&gt;animate&lt;/em&gt; this map over a day by incrementing the hour, generating a map for each hour (while keeping the colors corresponding to the arrest type consistent), and then &lt;a href=&quot;https://github.com/minimaxir/frames-to-gif-osx&quot;&gt;stitching the maps together&lt;/a&gt; into a GIF. Let&amp;rsquo;s do March 14th, 2017 (&lt;a href=&quot;https://en.wikipedia.org/wiki/Pi_Day&quot;&gt;Pi Day&lt;/a&gt; can be dangerous!) starting at 6 AM:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/predicting-arrests/map_ani.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Wow!&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I deliberately avoided using the term &amp;ldquo;machine learning&amp;rdquo; in the headline of this post because it has been overused to the point of clickbait. Indeed, neural networks/deep learning excel at processing higher-dimensional data such as text, image, and voice data, but in cases where dataset features are &lt;a href=&quot;https://news.ycombinator.com/item?id=13563892&quot;&gt;simple and known&lt;/a&gt;, neural networks are not necessarily the most &lt;em&gt;pragmatic&lt;/em&gt; option. CPU/RAM machine learning libraries like LightGBM are still worthwhile, despite the religious fervor for deep learning.&lt;/p&gt;

&lt;p&gt;And there&amp;rsquo;s still a lot of work that can be done with the SF Crime Incidents dataset. The model only predicts the type of crime given an arrest occurred; it does not predict &lt;em&gt;if&lt;/em&gt; an arrest will occur at a given time and place, which would make a fun project for the future!&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view all the R and ggplot2 code used to visualize the San Francisco crime data in &lt;a href=&quot;http://minimaxir.com/notebooks/predicting-arrests/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&quot;https://github.com/minimaxir/sf-arrests-predict&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 08 Feb 2017 06:30:00 -0800</pubDate>
        <link>http://minimaxir.com/2017/02/predicting-arrests/</link>
        <guid isPermaLink="true">http://minimaxir.com/2017/02/predicting-arrests/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Playing with 80 Million Amazon Product Review Ratings Using Apache Spark</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.amazon.com&quot;&gt;Amazon&lt;/a&gt; product reviews and ratings are a very important business. Customers on Amazon often make purchasing decisions based on those reviews, and a single bad review can cause a potential purchaser to reconsider. A couple years ago, I wrote a blog post titled &lt;a href=&quot;http://minimaxir.com/2014/06/reviewing-reviews/&quot;&gt;A Statistical Analysis of 1.2 Million Amazon Reviews&lt;/a&gt;, which was well-received.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon/amzn-basic-score.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Back then, I was only limited to 1.2M reviews because attempting to process more data caused out-of-memory issues and my R code took &lt;em&gt;hours&lt;/em&gt; to run.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://spark.apache.org&quot;&gt;Apache Spark&lt;/a&gt;, which makes processing gigantic amounts of data efficient and sensible, has become very popular in the past couple years (for good tutorials on using Spark with Python, I recommend the &lt;a href=&quot;https://courses.edx.org/courses/course-v1:BerkeleyX+CS105x+1T2016/info&quot;&gt;free&lt;/a&gt; &lt;a href=&quot;https://courses.edx.org/courses/course-v1:BerkeleyX+CS110x+2T2016/info&quot;&gt;eDX&lt;/a&gt; &lt;a href=&quot;https://courses.edx.org/courses/course-v1:BerkeleyX+CS120x+2T2016/info&quot;&gt;courses&lt;/a&gt;). Although data scientists often use Spark to process data with distributed cloud computing via &lt;a href=&quot;https://aws.amazon.com/ec2/&quot;&gt;Amazon EC2&lt;/a&gt; or &lt;a href=&quot;https://azure.microsoft.com/en-us/services/hdinsight/apache-spark/&quot;&gt;Microsoft Azure&lt;/a&gt;, Spark works just fine even on a typical laptop, given enough memory (for this post, I use a 2016 MacBook Pro/16GB RAM, with 8GB allocated to the Spark driver).&lt;/p&gt;

&lt;p&gt;I wrote a &lt;a href=&quot;https://github.com/minimaxir/amazon-spark/blob/master/amazon_preprocess.py&quot;&gt;simple Python script&lt;/a&gt; to combine the per-category ratings-only data from the &lt;a href=&quot;http://jmcauley.ucsd.edu/data/amazon/&quot;&gt;Amazon product reviews dataset&lt;/a&gt; curated by Julian McAuley, Rahul Pandey, and Jure Leskovec for their 2015 paper &lt;a href=&quot;http://cseweb.ucsd.edu/%7Ejmcauley/pdfs/kdd15.pdf&quot;&gt;Inferring Networks of Substitutable and Complementary Products&lt;/a&gt;. The result is a 4.53 GB CSV that would definitely not open in Microsoft Excel. The truncated and combined dataset includes the &lt;strong&gt;user_id&lt;/strong&gt; of the user leaving the review, the &lt;strong&gt;item_id&lt;/strong&gt; indicating the Amazon product receiving the review, the &lt;strong&gt;rating&lt;/strong&gt; the user gave the product from 1 to 5, and the &lt;strong&gt;timestamp&lt;/strong&gt; indicating the time when the review was written (truncated to the Day). We can also infer the &lt;strong&gt;category&lt;/strong&gt; of the reviewed product from the name of the data subset.&lt;/p&gt;

&lt;p&gt;Afterwards, using the new &lt;a href=&quot;http://spark.rstudio.com&quot;&gt;sparklyr&lt;/a&gt; package for R, I can easily start a local Spark cluster with a single &lt;code&gt;spark_connect()&lt;/code&gt; command and load the entire CSV into the cluster in seconds with a single &lt;code&gt;spark_read_csv()&lt;/code&gt; command.  &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/output.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;There are 80.74 million records total in the dataset, or as the output helpfully reports, &lt;code&gt;8.074e+07&lt;/code&gt; records. Performing advanced queries with traditional tools like &lt;a href=&quot;https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html&quot;&gt;dplyr&lt;/a&gt; or even Python&amp;rsquo;s &lt;a href=&quot;http://pandas.pydata.org&quot;&gt;pandas&lt;/a&gt; on such a dataset would take a considerable amount of time to execute.&lt;/p&gt;

&lt;p&gt;With sparklyr, manipulating actually-big-data is &lt;em&gt;just as easy&lt;/em&gt; as performing an analysis on a dataset with only a few records (and an order of magnitude easier than the Python approaches taught in the eDX class mentioned above!).&lt;/p&gt;

&lt;h2&gt;Exploratory Analysis&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;(You can view the R code used to process the data with Spark and generate the data visualizations in &lt;a href=&quot;http://minimaxir.com/notebooks/amazon-spark/&quot;&gt;this R Notebook&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;There are &lt;strong&gt;20,368,412&lt;/strong&gt; unique users who provided reviews in this dataset. &lt;strong&gt;51.9%&lt;/strong&gt; of those users have only written one review.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/user_count_cum.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Relatedly, there are &lt;strong&gt;8,210,439&lt;/strong&gt; unique products in this dataset, where &lt;strong&gt;43.3%&lt;/strong&gt; have only one review.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/item_count_cum.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;After removing duplicate ratings, I added a few more features to each rating which may help illustrate how review behavior changed over time: a ranking value indicating the # review that the author of a given review has written (1st review by author, 2nd review by author, etc.), a ranking value indicating the # review that the product of a given review has received (1st review for product, 2nd review for product, etc.), and the month and year the review was made.&lt;/p&gt;

&lt;p&gt;The first two added features require a &lt;em&gt;very&lt;/em&gt; large amount of processing power, and highlight the convenience of Spark&amp;rsquo;s speed (and the fact that Spark uses all CPU cores by default, while typical R/Python approaches are single-threaded!)&lt;/p&gt;

&lt;p&gt;These changes are cached into a Spark DataFrame &lt;code&gt;df_t&lt;/code&gt;. If I wanted to determine which Amazon product category receives the best review ratings on average, I can aggregate the data by category, calculate the average rating score for each category, and sort. Thanks to the power of Spark, the data processing for this many-millions-of-records takes seconds.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;df_agg &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; df_t &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
            group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
            summarize&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;count &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; n&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; avg_rating &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;rating&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
            arrange&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;desc&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;avg_rating&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;
            collect&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/avg.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Or, visualized in chart form using &lt;a href=&quot;http://ggplot2.org&quot;&gt;ggplot2&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/avg_rating_desc.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Digital Music/CD products receive the highest reviews on average, while Video Games and Cell Phones receive the lowest reviews on average, with a &lt;strong&gt;0.77&lt;/strong&gt; rating range between them. This does make some intuitive sense; Digital Music and CDs are types of products where you know &lt;em&gt;exactly&lt;/em&gt; what you are getting with no chance of a random product defect, while Cell Phones and Accessories can have variable quality from shady third-party sellers (Video Games in particular are also prone to irrational &lt;a href=&quot;http://steamed.kotaku.com/steam-games-are-now-even-more-susceptible-to-review-bom-1774940065&quot;&gt;review bombing&lt;/a&gt; over minor grievances).&lt;/p&gt;

&lt;p&gt;We can refine this visualization by splitting each bar into a percentage breakdown of each rating from 1-5. This could be plotted with a pie chart for each category, however a stacked bar chart, scaled to 100%, looks much cleaner.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/category_breakdown.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The new visualization does help support the theory above; the top categories have a significantly higher percentage of 4/5-star ratings than the bottom categories, and a much a lower proportion of 1/2/3-star ratings. The inverse holds true for the bottom categories.&lt;/p&gt;

&lt;p&gt;How have these breakdowns changed over time? Are there other factors in play?&lt;/p&gt;

&lt;h2&gt;Rating Breakdowns Over Time&lt;/h2&gt;

&lt;p&gt;Perhaps the advent of the binary Like/Dislike behaviors in social media in the 2000&amp;rsquo;s have translated into a change in behavior for a 5-star review system. Here are the rating breakdowns for reviews written in each month from January 2000 to July 2014:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/time_breakdown.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The voting behavior oscillates very slightly over time with no clear spikes or inflection points, which dashes that theory.&lt;/p&gt;

&lt;h2&gt;Distribution of Average Scores&lt;/h2&gt;

&lt;p&gt;We should look at the global averages of Amazon product scores (i.e. what customers see when they buy products), and the users who give the ratings. We would expect the distributions to match, so any deviations would be interesting.&lt;/p&gt;

&lt;p&gt;Products on average, when looking at products with atleast 5 ratings, have a &lt;strong&gt;4.16&lt;/strong&gt; overall rating.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/item_histogram.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;When looking at a similar graph for the overall ratings given by users, (5 ratings minimum), the average rating is slightly higher at &lt;strong&gt;4.20&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/user_histogram.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The primary difference between the two distributions is that there is significantly higher proportion of Amazon customers giving &lt;em&gt;only&lt;/em&gt; 5-star reviews. Normalizing and overlaying the two charts clearly highlights that discrepancy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/user_item_histogram.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;The Marginal Review&lt;/h2&gt;

&lt;p&gt;A few posts ago, I discussed how the &lt;a href=&quot;http://minimaxir.com/2016/11/first-comment/&quot;&gt;first comment on a Reddit post&lt;/a&gt; has dramatically more influence than subsequent comments. Does user rating behavior change after making more and more reviews? Is the typical rating behavior different for the first review of a given product? &lt;/p&gt;

&lt;p&gt;Here is the ratings breakdown for the &lt;em&gt;n&lt;/em&gt;-th Amazon review a user gives:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/user_nth_breakdown.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The first user review has a slightly higher proportion of being a 1-star review than subsequent reviews. Otherwise, the voting behavior is mostly the same overtime, although users have an increased proportion of giving a 4-star review instead of a 5-star review as they get more comfortable.&lt;/p&gt;

&lt;p&gt;In contrast, here is the ratings breakdown for the &lt;em&gt;n&lt;/em&gt;-th review an Amazon product received:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/amazon-spark/item_nth_breakdown.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The first product review has a slightly higher proportion of being a 5-star review than subsequent reviews. However, after the 10th review, there is &lt;em&gt;zero&lt;/em&gt; change in the distribution of ratings, which implies that the marginal rating behavior is independent from the current score after that threshold.&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;Granted, this blog post is more playing with data and less analyzing data. What might be interesting to look into for future technical posts is conditional behavior, such as predicting the rating of a review given the previous ratings on that product/by that user. However, this post shows that while &amp;ldquo;big data&amp;rdquo; may be an inscrutable buzzword nowadays, you don&amp;rsquo;t have to work for a Fortune 500 company to be able to understand it. Even with a data set consisting of 5 simple features, you can extract a large number of insights. &lt;/p&gt;

&lt;p&gt;And this post doesn&amp;rsquo;t even look at the text of the Amazon product reviews or the metadata associated with the products! I do have a few ideas lined up there which I won&amp;rsquo;t spoil.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view all the R and ggplot2 code used to visualize the Amazon data in &lt;a href=&quot;http://minimaxir.com/notebooks/amazon-spark/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&quot;https://github.com/minimaxir/amazon-spark&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 02 Jan 2017 09:00:00 -0800</pubDate>
        <link>http://minimaxir.com/2017/01/amazon-spark/</link>
        <guid isPermaLink="true">http://minimaxir.com/2017/01/amazon-spark/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Network Visualization of Breached Internet Services Using HaveIBeenPwned? Data</title>
        <description>&lt;p&gt;Last week, Yahoo &lt;a href=&quot;https://yahoo.tumblr.com/post/154479236569/important-security-information-for-yahoo-users&quot;&gt;announced&lt;/a&gt; that 1 billion accounts on their service were compromised by attackers in 2013. That is bad, and unfortunately common nowadays.&lt;/p&gt;

&lt;p&gt;Security expert &lt;a href=&quot;https://twitter.com/troyhunt&quot;&gt;Troy Hunt&lt;/a&gt; maintains &lt;a href=&quot;https://haveibeenpwned.com&quot;&gt;Have I been pwned?&lt;/a&gt;, a database of breached internet services where users can check to see if their account information has been compromised in such an attack as the Yahoo attack. Recently, Hunt &lt;a href=&quot;https://www.troyhunt.com/heres-1-4-billion-records-from-have-i-been-pwned-for-you-to-analyse/&quot;&gt;released a dataset&lt;/a&gt; consisting of &lt;strong&gt;1.4 billion&lt;/strong&gt; unique breached accounts, and the services where those specific accounts were compromised.&lt;/p&gt;

&lt;p&gt;The dataset has been scrubbed of identifying information and sensitive data (justifiability so), which strongly limits the scope of any potential analysis. However, what may be interesting is taking a look at the interrelated networks between the services and creating a neat data visualization.&lt;/p&gt;

&lt;h2&gt;Methodology&lt;/h2&gt;

&lt;p&gt;Here&amp;rsquo;s a line from the 141.8 MB text file:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;Adobe;GFAN;HeroesOfNewerth;NetEase;Tumblr 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this example, 2 users had their accounts breached at these specific 5 services.&lt;/p&gt;

&lt;p&gt;I wrote a &lt;a href=&quot;https://github.com/minimaxir/breach-network/blob/master/hibp_service_edges.py&quot;&gt;simple Python script&lt;/a&gt; that takes in the HIBP data dump and outputs two files:&lt;/p&gt;

&lt;p&gt;One, &lt;a href=&quot;https://github.com/minimaxir/breach-network/blob/master/hibp_services.csv&quot;&gt;a CSV file&lt;/a&gt; containing the total number of breached accounts from each service in this dataset. From the example data point, we would add 2 to the counts of Adobe breaches, GFAN breaches, etc. There are &lt;strong&gt;1,768,628,867&lt;/strong&gt; total records in the dataset (which is greater than the earlier 1.4B metric since it multicounts accounts which have been breached multiple times). The 1.77B number approximately matches the given number of total number of records on HIBP (1,989,141,353) minus the number of records from sensitive breaches (~221M).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/breach-network/nodes.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Two, &lt;a href=&quot;https://github.com/minimaxir/breach-network/blob/master/hibp_edges.csv&quot;&gt;a CSV file&lt;/a&gt; containing the unique combination pairs of each service in a data point, From the example data point, we would add 2 to the counts of [Adobe, GFAN], [Adobe, HeroesOfNewerth], etc. (statistically-minded readers will notice that there are 10 unique two-value combinations for a set of 5 services). &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/breach-network/edges.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Although the HIBP dataset represents 1.77 Billion records, it is far from &amp;ldquo;big data&amp;rdquo;: my Python script takes less than a minute to process it.&lt;/p&gt;

&lt;p&gt;The latter CSV serves as the edge list for a network graph. There are 10,816 unique edges. Using &lt;a href=&quot;https://www.r-project.org&quot;&gt;R&lt;/a&gt;, &lt;a href=&quot;http://ggplot2.org&quot;&gt;ggplot2&lt;/a&gt;, and &lt;a href=&quot;https://briatte.github.io/ggnetwork/&quot;&gt;ggnetwork&lt;/a&gt;, I connected all the edges into a graph network (removing edges with too few breached accounts), set the layout according to 50,000 iterations of the &lt;a href=&quot;https://github.com/gephi/gephi/wiki/Fruchterman-Reingold&quot;&gt;Fruchterman-Reingold algorithm&lt;/a&gt;, and attempted to make it pretty.&lt;/p&gt;

&lt;p&gt;The results of my first made-in-an-hour-after-getting-home-from-work draft were &lt;a href=&quot;http://i.imgur.com/FpLiFGk.png&quot;&gt;not pretty&lt;/a&gt;. On Hacker News, user flashman &lt;a href=&quot;https://news.ycombinator.com/item?id=13112461&quot;&gt;provides a sensible fix&lt;/a&gt;; only include edges in the network with a proportional number of accounts shared between the two internet services it connects (e.g. the edge contains atleast 1% of the accounts in both services).&lt;/p&gt;

&lt;p&gt;Removing edges which do not fit that criteria dramatically reduces the clutter and makes communities much more distinct. After rerunning the code and making further style tweaks, here&amp;rsquo;s the final result:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/img/breach-network/hibp.png&quot;&gt;&lt;img src=&quot;/img/breach-network/hibp.png&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(click on the image to view at full resolution)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The interactive version at the top of the page was created with &lt;a href=&quot;https://plot.ly&quot;&gt;Plotly&lt;/a&gt;, via my workflow mentioned in a &lt;a href=&quot;http://minimaxir.com/2016/12/interactive-network/&quot;&gt;previous post&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Analysis&lt;/h2&gt;

&lt;p&gt;The colors of the nodes represent the communities as determined by the &lt;a href=&quot;http://arxiv.org/abs/physics/0512106&quot;&gt;Walktrap community finding algorithm&lt;/a&gt; run on the network. There are a few noteworthy groups: the turquoise group of mainstream social networking services including LinkedIn and MySpace, the brown group of mainstream gaming services like Nexus Mods and XSplit, and mustard-colored services of questionable legality on the right of the cluster. There are clusters of services extended far from the general clusters which represent non-English services: the yellow-green cluster on the left consists of Russian internet services, while the lime-green cluster at the top represents Chinese internet services.&lt;/p&gt;

&lt;p&gt;The size of the nodes represent the degree of the node, or the number of nodes connected to a given node. With that, we can easily see services like LinkedIn and XSplit have strong connections to other breached services. Relatedly, the transparency of the edges in the image is determined by the corresponding weight of the edge, and demonstrates the relative magnitude of the LinkedIn/MySpace breaches. (And it&amp;rsquo;s also why we can&amp;rsquo;t use other metrics like &lt;a href=&quot;https://en.wikipedia.org/wiki/Centrality&quot;&gt;centrality&lt;/a&gt; for sizing the nodes, as the relative weights of those breaches skew the result.)&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s important is that the network is generated &lt;em&gt;entirely from user behavior&lt;/em&gt;, and not by manually establishing the actual relationships between the internet services.&lt;/p&gt;

&lt;p&gt;Given the wildly-varying timing and magnitude of these breaches, along with the numerous potential &lt;em&gt;causes&lt;/em&gt; of breaches which are not always publicly disclosed, it is difficult to make accurate predictive models about future breaches from the HaveIBeenPwned? dataset. The records in HIBP are a &lt;em&gt;very&lt;/em&gt; small sample of all the leaked data worldwide, unfortunately. However, it shows what  relationships can be visualized from simple user fingerprints all around the web, even when the fingerprint &lt;em&gt;itself&lt;/em&gt; is unknown.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view all the R and ggplot2 code used to visualize the network data in &lt;a href=&quot;http://minimaxir.com/notebooks/breach-network/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&quot;https://github.com/minimaxir/breach-network&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Dec 2016 08:30:00 -0800</pubDate>
        <link>http://minimaxir.com/2016/12/pwned-network/</link>
        <guid isPermaLink="true">http://minimaxir.com/2016/12/pwned-network/</guid>
        
        
        <category>Interactive</category>
        
        <category>Visualization</category>
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Infinite-Quality Abstract Art and Animations with Primitive</title>
        <description>&lt;p&gt;4k media (&amp;ldquo;&lt;a href=&quot;https://en.wikipedia.org/wiki/Ultra-high-definition_television&quot;&gt;Ultra HD&lt;/a&gt;&amp;rdquo;) is the new big thing. &lt;a href=&quot;https://www.youtube.com&quot;&gt;YouTube&lt;/a&gt; and &lt;a href=&quot;https://www.netflix.com/&quot;&gt;Netflix&lt;/a&gt; now offer 4k video streaming, cell phones such as the &lt;a href=&quot;http://www.apple.com/iphone-7/&quot;&gt;iPhone 7&lt;/a&gt; can now record 4k video, gaming consoles such as the &lt;a href=&quot;https://www.playstation.com/en-us/explore/ps4-pro/&quot;&gt;PlayStation 4 Pro&lt;/a&gt; can play video games in native 4k, and 4k-compatible computer monitors and television sets are now priced reasonably.&lt;/p&gt;

&lt;p&gt;However, the improvements offered by 4k do not come for free. From 1080p, 4k media requires much more resources to store the media on disk, much more resources to read from disk or stream over the Internet, and much more resources to store in memory. And Moore&amp;rsquo;s Law has been slowing down.&lt;/p&gt;

&lt;p&gt;Another option worth considering in light of these potential constraints is vector graphics, which can be scaled to &lt;em&gt;any&lt;/em&gt; resolution at a significant fraction of the storage space. Although graphic formats such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Scalable_Vector_Graphics&quot;&gt;Scalable Vector Graphics&lt;/a&gt; (SVG) have existed &lt;em&gt;long&lt;/em&gt; before 4k media (and even 1080p media), support for it had died out over the years since JPGs and PNGs were more practical for the 1024x768px screens of the day, and older versions of Internet Explorer did not support SVGs. However, creating complex SVGs is not trivial, and there aren&amp;rsquo;t any magic applications that can convert a normal image into vector graphics automatically (the closest is &lt;a href=&quot;http://potrace.sourceforge.net&quot;&gt;potrace&lt;/a&gt;, which only works for one color).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/fogleman/primitive&quot;&gt;Primitive&lt;/a&gt;, an open-source project by &lt;a href=&quot;https://twitter.com/FogleBird&quot;&gt;Michael Fogleman&lt;/a&gt;, is a cross-platform command-line application that creates abstract art by taking simple polygons such as triangles and rectangles and placing them such that the group of polygons is as close as possible to the original image. The Twitter account &lt;a href=&quot;https://twitter.com/PrimitivePic&quot;&gt;@PrimitivePic&lt;/a&gt; posts examples of such images every half hour.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/primitive/git.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://primitive.lol&quot;&gt;Primitive application&lt;/a&gt; on the &lt;a href=&quot;https://itunes.apple.com/us/app/primitive/id1175103038?mt=12&quot;&gt;Mac App Store&lt;/a&gt;, also by Fogleman, provides a simple user interface for the application for $9.99 (worth it for the productivity increase over fiddling with the command-line). With this GUI, you can see exactly &lt;em&gt;how&lt;/em&gt; the art is being made, in real time. The app has also been &lt;a href=&quot;https://medium.com/art-marketing/product-launch-post-mortem-primitive-for-macos-2eee316134ad&quot;&gt;financially successful&lt;/a&gt; for a side project.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/primitive/primitive.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Both interfaces allow for SVG export, which means that we can use Primitive to take small images and scale them &lt;em&gt;indefinitely&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;But what cool things can you do with these fancy SVGs? Let&amp;rsquo;s take a look.&lt;/p&gt;

&lt;h2&gt;Playing with Primitive&lt;/h2&gt;

&lt;p&gt;Here&amp;rsquo;s a photo I took of the &lt;a href=&quot;https://en.wikipedia.org/wiki/San_Francisco_Ferry_Building&quot;&gt;San Francisco Ferry Building&lt;/a&gt; last year, cropped to 16:9 with an attempt to follow the &lt;a href=&quot;https://en.wikipedia.org/wiki/Rule_of_thirds&quot;&gt;rule of thirds&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/primitive/San_Francisco.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;This PNG image is 672 KB. Let&amp;rsquo;s try running it through Primitive to see if we can make it smaller, and make it &lt;em&gt;cooler&lt;/em&gt; by drawing 50 quadrilaterals (with zero transparency), at the 1024px &amp;ldquo;nicest&amp;rdquo; working size for maximum quality.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/primitive/SF_Final_50.svg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Now that is definitely minimalistic. Maybe &lt;em&gt;too&lt;/em&gt; abstract. What happens if we want to add detail? We can do that by adding many quadratic &lt;a href=&quot;https://en.wikipedia.org/wiki/B%C3%A9zier_curve&quot;&gt;Bèzier curves&lt;/a&gt;. Let&amp;rsquo;s add 500 solid curves to this image.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/primitive/SF_Final_550.svg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Now that looks fancy, is only 94 KB (about 1/8th the file size of the static image!), and can scale to any screen size.&lt;/p&gt;

&lt;p&gt;You may have noticed that this SVG is the final result from the &lt;a href=&quot;/img/primitive/SF_Final_550_animated.svg&quot;&gt;animation&lt;/a&gt; at the beginning of this article. This particular shenanigan is &lt;a href=&quot;http://minimaxir.com/2016/12/interactive-network/&quot;&gt;another&lt;/a&gt; of my trademark weird-tricks-that-should-not-even-work-but-do. By passing the final SVG through &lt;a href=&quot;https://maxwellito.github.io/vivus/&quot;&gt;Vivus&lt;/a&gt; (specifically, &lt;a href=&quot;https://maxwellito.github.io/vivus-instant/&quot;&gt;Vivus Instant&lt;/a&gt;), we can animate the Bèzier curves such that it looks like they are being drawn &lt;em&gt;in real time&lt;/em&gt; on the quadrilateral background.&lt;/p&gt;

&lt;p&gt;The animations generated from Vivus Instant are pure CSS and require no additional dependencies (although you&amp;rsquo;ll need to &lt;a href=&quot;https://css-tricks.com/scale-svg/&quot;&gt;manually add&lt;/a&gt; the &lt;code&gt;viewBox&lt;/code&gt; attribute to make the SVG mobile-friendly). Even then, the result is 276 KB; still much smaller than the original raster image!&lt;/p&gt;

&lt;p&gt;Of the polygons available in Primitive, Vivus Instant will only animate the Bèzier curves. If you wanted to animate other polygons, you could use &lt;a href=&quot;http://snapsvg.io&quot;&gt;Snap.svg&lt;/a&gt;, which might make a fun project for a future post.&lt;/p&gt;

&lt;p&gt;These SVG animations only work on the web, but it&amp;rsquo;s not difficult to make animations of SVG creation into a share-friendly format.&lt;/p&gt;

&lt;h2&gt;Abstract GIFs&lt;/h2&gt;

&lt;p&gt;GIFs nowadays can be shared anywhere, and Primitive has a few ways of making GIFs. The command-line interface has a GIF-maker built in; essentially, it outputs each frame as an image and stitches them together.&lt;/p&gt;

&lt;p&gt;The Primitive Mac App has another option. Since the polygons are rendered on-screen, you can &lt;em&gt;record the screen&lt;/em&gt; using tools like &lt;a href=&quot;https://support.apple.com/en-us/HT201066&quot;&gt;QuickTime&amp;rsquo;s screen recording&lt;/a&gt; to simultaneously visualize and record the vector image. Once recorded (and after editing the video to speed things up), you can use one of any number of video-to-GIF converters to make a sharable animation.&lt;/p&gt;

&lt;p&gt;For this test, let&amp;rsquo;s try using an &lt;em&gt;extremely&lt;/em&gt; small image and see how well Primitive can extrapolate to an infinite size. Here&amp;rsquo;s a 64x64px sprite of the &lt;a href=&quot;http://www.pokemon.com/us/&quot;&gt;Pokèmon&lt;/a&gt; Pikachu from the 3rd generation of Pokèmon games (via &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Pikachu_(Pok%C3%A9mon)&quot;&gt;Bulbapedia&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/primitive/Spr_3r_025.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;I made a video of Primitive rendering Pikachu using a combination of 1,000 ellipses, rectangles, triangles and curves, and converted it to a GIF using my noncreatively-named &lt;a href=&quot;https://github.com/minimaxir/video-to-gif-osx&quot;&gt;Convert Video to GIF&lt;/a&gt; tool. The result?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/primitive/Pikachu_Record.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Not too bad, given the input. Again, the GIF can be sized to any resolution, bandwidth considerations aside.&lt;/p&gt;

&lt;h2&gt;Abstract 4k Videos&lt;/h2&gt;

&lt;p&gt;So how do you get these infinite-quality images into 4k videos? You can export the Primitive renderings as a super-high-resolution PNG and embed them into the video, but there may still be pixellation if you cinematically zoom into the image. SVGs aren&amp;rsquo;t natively supported by video editing programs such as Final Cut Pro and Adobe Premiere. But &lt;em&gt;PDFs&lt;/em&gt; are, and there are many SVG-to-PDF converters which preserve the vector information (On macOS, &lt;a href=&quot;https://itunes.apple.com/us/app/gapplin/id768053424?mt=12&quot;&gt;Gapplin&lt;/a&gt; works fine for this purpose).&lt;/p&gt;

&lt;p&gt;For vector scaling in Final Cut Pro, you must first &lt;a href=&quot;http://www.fcp.co/forum/4-final-cut-pro-x-fcpx/25544-best-way-to-use-illustrador-files-in-fcpx#77676&quot;&gt;import through Motion&lt;/a&gt; first. Here&amp;rsquo;s a quick 4k/60fps video as proof using the Ferry Building vector image above, with a bit of style.&lt;/p&gt;

&lt;div class=&quot;responsive-video&quot;&gt;&lt;iframe src=&quot;http://www.youtube.com/embed/Cv4P6VMvBCw &quot; style=&quot;width: 100%; height: 100%; border: none; padding-bottom: 20px&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;p&gt;Again, vector images are not a new concept, but given the changes in the media and technology landscape, it is very worthwhile to give them a second chance. Once technology evolves and the media industries start pushing &lt;em&gt;8k media&lt;/em&gt; (and they will), having a sensible method of producing high-quality assets pays for itself.&lt;/p&gt;

&lt;p&gt;At the least, Primitive will give me some nice background visuals for when I start producing 4k data visualizations videos (yes, that&amp;rsquo;s a thing!).&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Dec 2016 06:30:00 -0800</pubDate>
        <link>http://minimaxir.com/2016/12/primitive/</link>
        <guid isPermaLink="true">http://minimaxir.com/2016/12/primitive/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>How to Create an Interactive WebGL Network Graph Using R </title>
        <description>&lt;p&gt;I&amp;rsquo;ve done &lt;a href=&quot;http://minimaxir.com/2016/05/reddit-graph/&quot;&gt;a lot of experimentation&lt;/a&gt; into determining the most efficient way to generate &lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_theory&quot;&gt;network graphs&lt;/a&gt; for visualizing relationships between groups.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/reddit-graph/group-006.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Among popular network graph visualization tools for the web, &lt;a href=&quot;https://gephi.org&quot;&gt;Gephi&lt;/a&gt; is a pain to work with and the workflows are not reproducible, &lt;a href=&quot;http://sigmajs.org&quot;&gt;Sigma.js&lt;/a&gt; is better but trickier to configure, and my stop-gap method of exporting network graphs as a PDF has issues on mobile devices.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve had success with &lt;a href=&quot;https://plot.ly&quot;&gt;Plotly&lt;/a&gt; for data visualizations, particularly its use for automatically converting R and &lt;a href=&quot;http://ggplot2.org&quot;&gt;ggplot2&lt;/a&gt; charts into &lt;a href=&quot;https://plot.ly/ggplot2/&quot;&gt;interactive charts&lt;/a&gt;. There are a &lt;a href=&quot;https://plot.ly/r/network-graphs/&quot;&gt;few official tutorials&lt;/a&gt; for Plotly network graphs using network-related R packages, but they are not straightforward, and even if I adapted the tutorial for other datasets, the resulting chart would be difficult to customize for maximum usability.&lt;/p&gt;

&lt;p&gt;Recently, I had an incredibly stupid idea to try and &lt;em&gt;combine&lt;/em&gt; Plotly and the customization of ggplot2 using several layers of R packages to make effective interactive network graphs with very little code. Normally, I would not call this &lt;strong&gt;ONE WEIRD TRICK&lt;/strong&gt; because that is clickbait, but this &lt;em&gt;is&lt;/em&gt; indeed a weird trick that shouldn&amp;rsquo;t even work. But it does!&lt;/p&gt;

&lt;h2&gt;R and Plotly&lt;/h2&gt;

&lt;p&gt;For this example of a network graph, we will use the flights paths of domestic airline flights from New York City airports in 2013, provided by the &lt;code&gt;nycflights13&lt;/code&gt; &lt;a href=&quot;https://cran.r-project.org/web/packages/nycflights13/index.html&quot;&gt;R package&lt;/a&gt; by Hadley Wickham (usually, tutorials on &lt;a href=&quot;https://gephi.org/tutorials/gephi-tutorial-quick_start.pdf&quot;&gt;working with networks&lt;/a&gt; use the character network map from &lt;em&gt;Les Misèrables&lt;/em&gt;, so let&amp;rsquo;s mix it up a bit).&lt;/p&gt;

&lt;p&gt;First, we install and load a few R packages:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dplyr&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;nycflights13&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;igraph&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;intergraph&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sna&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ggplot2&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ggnetwork&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;plotly&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dplyr&lt;/code&gt; helps aggregate and manipulate tabular data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nycflights13&lt;/code&gt; contains the data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;igraph&lt;/code&gt; allows the creation of network graphs, with &lt;code&gt;sna&lt;/code&gt; and &lt;code&gt;intergraph&lt;/code&gt; helping allow compatibity with other packages.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ggplot2&lt;/code&gt; for constructing the chart, with &lt;code&gt;ggnetwork&lt;/code&gt; by François Briatte having &lt;a href=&quot;https://briatte.github.io/ggnetwork/&quot;&gt;special interactions with ggplot2&lt;/a&gt; for graphing network graphs specifically. (note: at time-of-writing, ggnetwork must be installed after ggplot2 &lt;a href=&quot;https://github.com/briatte/ggnetwork/issues/13&quot;&gt;from source&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;plotly&lt;/code&gt; for converting the ggplot2 chart into the final interactive graph.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First, let&amp;rsquo;s look at the included &lt;code&gt;flights&lt;/code&gt; dataset with nycflights13. The dataset contains 336,776 total flights, with information such as date/time departed, the carrier, and most importantly, the airport where the plane leaves, and the airport where the plane arrives. There are only three airports where the plane leaves from in this dataset: Newark Liberty International Airport (EWR), John F. Kennedy International Airport (JFK), and LaGuardia Airport (LGA). All three airports have approximately the same number of outbound flights.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/interactive-network/flight-data.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;We want to aggregate the counts of pairs of (origin, destination): the pairs will serve as the &lt;em&gt;edges&lt;/em&gt; of our network graph, and the airports will serve as the vertices. The counts of pairs (i.e. number of flights from X to Y) will serve as the &lt;em&gt;weight&lt;/em&gt; of the edge during the graph layout phase; nodes with a higher edge weight between them have a greater &amp;ldquo;pull.&amp;rdquo; This aggregation takes just one line of &lt;code&gt;dplyr&lt;/code&gt; code.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;df_edges &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; flights &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; group_by&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;origin&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; dest&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; summarize&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;weight &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; n&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/interactive-network/airport-edges.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Using &lt;code&gt;igraph&lt;/code&gt;, we create a network graph object from the aggregated dataset. In this context, the graph is &lt;em&gt;directed&lt;/em&gt;, since logically each flight is in one direction.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;net &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; graph.data.frame&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;df_edges&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; directed &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/interactive-network/airport-graph.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As noted by the numbers at the top of the output, there are 107 vertices/unique airports, and 224 unique edges.&lt;/p&gt;

&lt;p&gt;We may want to size the vertices of each of the airports in the final chart. We can set that in igraph as well by calculating the degree of each vertex, so nodes with more connected airports will be larger.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;V&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;net&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;degree &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; centralization.degree&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;net&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;res
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we can convert the network to a &lt;code&gt;ggplot2&lt;/code&gt; friendly format. &lt;code&gt;ggnetwork&lt;/code&gt; both calculates x/y coordinates for the nodes of the network graph according to the &lt;a href=&quot;https://github.com/gephi/gephi/wiki/Fruchterman-Reingold&quot;&gt;Fruchterman-Reingold&lt;/a&gt; force-directed layout algorithm (so that nodes connected by higher weights will be closer), and also formats the data into a ggplot2-friendly tabular format. 5,000 iterations of the algorithm on a smaller graph is enough for a quick demo, but you should use as many iterations as possible.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;df_net &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; ggnetwork&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;net&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; layout &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;fruchtermanreingold&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; weights &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;weight&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; niter &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we can plot the graph in R. The base aesthetics for the ggplot are the x/y coordinates of the points, and the xend/yend-points of the edge line segments. ggnetwork exposes a &lt;code&gt;geom_edges()&lt;/code&gt; which plots the edges of a network graph, and &lt;code&gt;geom_nodes()&lt;/code&gt; which plots the nodes. Both of these functions work by extending normal ggplot2 functions: the edges are actually ggplot2 lines (via &lt;code&gt;geom_segment()&lt;/code&gt;), while the nodes are ggplot2 points (via &lt;code&gt;geom_points()&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Style-wise, for the &lt;em&gt;edges&lt;/em&gt;, we should apply a low opacity so we can see where they overlap. For the &lt;em&gt;nodes&lt;/em&gt;, we can size the nodes depending on their degree, and also set the text to the airport name for use later. We should include a plot title as always, and use the &lt;code&gt;theme_blank()&lt;/code&gt; ggplot2 theme included with ggnetwork such that the visualization does not use ggplot2&amp;rsquo;s default theme.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;plot &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;df_net&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; x&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; y &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; y&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; xend &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; xend&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; yend &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; yend&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
    geom_edges&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; alpha &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
    geom_nodes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; degree&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; text &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; vertex.names&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
    ggtitle&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Network Graph of U.S. Flights Outbound from NYC in 2013&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
    theme_blank&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Putting it all together:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/interactive-network/ggplot3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Nifty! So how does this become interactive? Easily.&lt;/p&gt;

&lt;h2&gt;One Weird Trick&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;plotly&lt;/code&gt; R package has a &lt;code&gt;ggplotly()&lt;/code&gt; function which converts a ggplot2 chart to an interactive Plotly chart, and the resulting parity to the static chart is surprisingly good.&lt;/p&gt;

&lt;p&gt;Plotly also has as a &lt;code&gt;toWebGL()&lt;/code&gt; function, which turns a Plotly chart to the &lt;a href=&quot;https://en.wikipedia.org/wiki/WebGL&quot;&gt;WebGL&lt;/a&gt; equivalent, allowing the system GPU to power crazy data visualizations with tons of points (my &lt;a href=&quot;http://minimaxir.com/2016/08/clickbait-cluster/&quot;&gt;Interactive Clickbait chart&lt;/a&gt; using this WebGL interface has about 10,000 points and can be manipulated without slowdown). The Plotly documentation is &lt;a href=&quot;https://plot.ly/r/webgl-vs-svg/&quot;&gt;sparse on the limitations&lt;/a&gt; of its WebGL support, but examining the examples indicates that WebGL support is limited to only points and straight lines; no polygons or curves.&lt;/p&gt;

&lt;p&gt;Hey, isn&amp;rsquo;t a network graph just points and straight lines?&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s chain the plot into ggplotly() while setting the hover text to the airport names, and chain that to the WebGL functionality:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;plot &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; ggplotly&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;tooltip &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt; toWebGL&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div id=&quot;htmlwidget_container&quot;&gt;
  &lt;div id=&quot;htmlwidget-51f6648a07e11b1abf04&quot; style=&quot;width:100%;height:400px;&quot; class=&quot;plotly html-widget&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;script type=&quot;application/json&quot; data-for=&quot;htmlwidget-51f6648a07e11b1abf04&quot;&gt;{&quot;x&quot;:{&quot;data&quot;:[{&quot;x&quot;:[0.375141921794262,0.398336772616253,null,0.375141921794262,0.231416853311704,null,0.375141921794262,0.0928746359693099,null,0.375141921794262,0.442147435673452,null,0.375141921794262,0.490194633546464,null,0.375141921794262,0.603225203504635,null,0.375141921794262,0.59081153788807,null,0.375141921794262,0.562500489561425,null,0.375141921794262,0.595744847078923,null,0.375141921794262,0.1686611791086,null,0.375141921794262,0.142654710390808,null,0.375141921794262,0.177330930601635,null,0.375141921794262,0.402266165312681,null,0.375141921794262,0.476654226843358,null,0.375141921794262,0.664463361490263,null,0.375141921794262,0.656801959684286,null,0.375141921794262,0.0691764330632262,null,0.375141921794262,0.335464933617332,null,0.375141921794262,0.196727130575685,null,0.375141921794262,0.398446144104167,null,0.375141921794262,0.606082836307656,null,0.375141921794262,0.520107909395174,null,0.375141921794262,0.158776650341963,null,0.375141921794262,0.563994474758855,null,0.375141921794262,0.0238200589019235,null,0.375141921794262,0.434964515152466,null,0.375141921794262,0.332109159196612,null,0.375141921794262,0.207553381065049,null,0.375141921794262,0.190245124570343,null,0.375141921794262,0.44193410115448,null,0.375141921794262,0.464012942332853,null,0.375141921794262,0.348223592984635,null,0.375141921794262,0.1217205768029,null,0.375141921794262,0.436840691975811,null,0.375141921794262,0.674997763793532,null,0.375141921794262,0.0423976548695413,null,0.375141921794262,0.653189750038107,null,0.375141921794262,0.556679418800422,null,0.375141921794262,0.174000555485329,null,0.375141921794262,0.367056482353336,null,0.375141921794262,0.18315313322535,null,0.375141921794262,0.668277727225314,null,0.375141921794262,0.634074632241642,null,0.375141921794262,0.248454202401703,null,0.375141921794262,0.500788657268025,null,0.375141921794262,0.380158437151396,null,0.375141921794262,0.154241945142639,null,0.375141921794262,0.279904368800208,null,0.375141921794262,0.346849932058201,null,0.375141921794262,0.362011359179019,null,0.375141921794262,0.433451836740657,null,0.375141921794262,0.568430460694556,null,0.375141921794262,0.681209464401851,null,0.375141921794262,0.362520337066271,null,0.375141921794262,0.520989301885846,null,0.375141921794262,0.627050834716232,null,0.375141921794262,0.404070049517213,null,0.375141921794262,0.645842634157814,null,0.375141921794262,0.200852084173203,null,0.375141921794262,0.14735862416214,null,0.375141921794262,0.408780079201348,null,0.375141921794262,0.499629189203938,null,0.375141921794262,0.531773138536121,null,0.375141921794262,0.488714420679938,null,0.375141921794262,0.556533455426346,null,0.375141921794262,0.292463432908503,null,0.375141921794262,0.216088281672444,null,0.375141921794262,0.156296749226243,null,0.521403286626722,0.750818281003784,null,0.521403286626722,0.43545836434104,null,0.521403286626722,0.427912880330646,null,0.521403286626722,0.816466804778435,null,0.521403286626722,0.241285731394685,null,0.521403286626722,0.531810769022582,null,0.521403286626722,0.505897317405868,null,0.521403286626722,0.605126259728004,null,0.521403286626722,0.87060842793947,null,0.521403286626722,0.5873270521506,null,0.521403286626722,0.574885544124051,null,0.521403286626722,0.600219422263835,null,0.521403286626722,0.330479335262988,null,0.521403286626722,0.167301895659982,null,0.521403286626722,0.427389022095212,null,0.521403286626722,0.493945663096591,null,0.521403286626722,0.668615904804107,null,0.521403286626722,0.667204341091844,null,0.521403286626722,0.340432890558217,null,0.521403286626722,0.197641812575988,null,0.521403286626722,0.424263504260501,null,0.521403286626722,0.618020109274438,null,0.521403286626722,0.532847510026951,null,0.521403286626722,0.163880496510408,null,0.521403286626722,0.567379227972389,null,0.521403286626722,0.866131098966022,null,0.521403286626722,0.454535649459538,null,0.521403286626722,0.345045006660964,null,0.521403286626722,0.21312475718605,null,0.521403286626722,0.198750811921407,null,0.521403286626722,0.659142578049148,null,0.521403286626722,0.843504166296951,null,0.521403286626722,0.477664733700597,null,0.521403286626722,0.476234788750302,null,0.521403286626722,0.350099512882592,null,0.521403286626722,0.463326215609288,null,0.521403286626722,0.835144570998741,null,0.521403286626722,0.684183642178402,null,0.521403286626722,0.846142494357672,null,0.521403286626722,0.885871897653275,null,0.521403286626722,0.39332314244744,null,0.521403286626722,0.650637973739079,null,0.521403286626722,0.570886886619552,null,0.521403286626722,0.180895010452889,null,0.521403286626722,0.388235599662527,null,0.521403286626722,0.181071014328054,null,0.521403286626722,0.668300300206767,null,0.521403286626722,0.645442796507026,null,0.521403286626722,0.259460402233345,null,0.521403286626722,0.521018205051867,null,0.521403286626722,0.390105270228954,null,0.521403286626722,0.483692356075904,null,0.521403286626722,0.157624248823495,null,0.521403286626722,0.385585326200774,null,0.521403286626722,0.29272576755674,null,0.521403286626722,0.354590116934059,null,0.521403286626722,0.37124788790749,null,0.521403286626722,0.445457243430657,null,0.521403286626722,0.882170875002285,null,0.521403286626722,0.57373155931436,null,0.521403286626722,0.846321838922237,null,0.521403286626722,0.68874120606007,null,0.521403286626722,0.703909136774732,null,0.521403286626722,0.364702766017597,null,0.521403286626722,0.541538920728358,null,0.521403286626722,0.626167487094621,null,0.521403286626722,0.414870529009423,null,0.521403286626722,0.643407035246014,null,0.521403286626722,0.751440995258101,null,0.521403286626722,0.866871530927171,null,0.521403286626722,0.198673390185873,null,0.521403286626722,0.148882035026252,null,0.521403286626722,0.424819988421373,null,0.521403286626722,0.890354401571159,null,0.521403286626722,0.875108152947903,null,0.521403286626722,0.834324919709448,null,0.521403286626722,0.807728656063105,null,0.521403286626722,0.570484572625621,null,0.521403286626722,0.540575009029753,null,0.521403286626722,0.788739572051865,null,0.521403286626722,0.501781512069948,null,0.521403286626722,0.573282573695601,null,0.521403286626722,0.617707664388415,null,0.521403286626722,0.30468783901352,null,0.521403286626722,0.225983396674046,null,0.521403286626722,0.15615498564717,null,0.671140685588431,0.912815072204364,null,0.671140685588431,0.954582330919281,null,0.671140685588431,0.423579027344162,null,0.671140685588431,0.826733312617325,null,0.671140685588431,0.46111216958178,null,0.671140685588431,0.523376677952971,null,0.671140685588431,0.624039874399396,null,0.671140685588431,0.87470211024138,null,0.671140685588431,0.618461211574893,null,0.671140685588431,0.58894246702335,null,0.671140685588431,0.966844932439542,null,0.671140685588431,0.631446987517471,null,0.671140685588431,0.440646916775815,null,0.671140685588431,0.50013146938416,null,0.671140685588431,0.682418870529126,null,0.671140685588431,0.677440629488422,null,0.671140685588431,0.349279771512629,null,0.671140685588431,0.420678600389709,null,0.671140685588431,0.631421228412645,null,0.671140685588431,0.547399438282292,null,0.671140685588431,0.588400612211921,null,0.671140685588431,0.864598406346657,null,0.671140685588431,0.456225312904585,null,0.671140685588431,0.853251619940646,null,0.671140685588431,0.484768637491492,null,0.671140685588431,0.490201233313888,null,0.671140685588431,0.357485317157183,null,0.671140685588431,0.461766951300564,null,0.671140685588431,0.84187595203203,null,0.671140685588431,0.690063967426859,null,0.671140685588431,0.84351930888583,null,0.671140685588431,0.88755105473655,null,0.671140685588431,0.97836713491032,null,0.671140685588431,0.673919270057091,null,0.671140685588431,0.588517349902531,null,0.671140685588431,0.387136625885949,null,0.671140685588431,0.688218313991044,null,0.671140685588431,0.658106253756941,null,0.671140685588431,0.543685777322744,null,0.671140685588431,0.402199379964802,null,0.671140685588431,0.910931255352872,null,0.671140685588431,0.953164981737936,null,0.671140685588431,0.364963250124481,null,0.671140685588431,0.382656067064239,null,0.671140685588431,0.459149576310406,null,0.671140685588431,0.882046335378367,null,0.671140685588431,0.589192224857842,null,0.671140685588431,0.84691577856393,null,0.671140685588431,0.684611589953847,null,0.671140685588431,0.947319339337379,null,0.671140685588431,0.808790133859673,null,0.671140685588431,0.368025790799691,null,0.671140685588431,0.569825431470493,null,0.671140685588431,0.648271884465125,null,0.671140685588431,0.427627978099028,null,0.671140685588431,0.66879035203972,null,0.671140685588431,0.764901105705134,null,0.671140685588431,0.874652504924122,null,0.671140685588431,0.439155327003178,null,0.671140685588431,0.894382978650812,null,0.671140685588431,0.881479125122771,null,0.671140685588431,0.95855460672269,null,0.671140685588431,0.830925437832968,null,0.671140685588431,0.819215511370555,null,0.671140685588431,0.867349257682671,null,0.671140685588431,0.518857907477492,null,0.671140685588431,0.552830416638066,null,0.671140685588431,0.800986045002673,null,0.671140685588431,0.509644020442292,null,0.671140685588431,0.601514639570558],&quot;y&quot;:[0.569160995688867,0.446610941607707,null,0.569160995688867,0.355888963266907,null,0.569160995688867,0.834852253134975,null,0.569160995688867,0.909220427999938,null,0.569160995688867,0.732468182156298,null,0.569160995688867,0.31596162521941,null,0.569160995688867,0.419431910874468,null,0.569160995688867,0.791438300229966,null,0.569160995688867,0.513560740080228,null,0.569160995688867,0.562515151270471,null,0.569160995688867,0.870464779365022,null,0.569160995688867,0.907219809102619,null,0.569160995688867,0.611404626497019,null,0.569160995688867,0.338866019563371,null,0.569160995688867,0.54574073725109,null,0.569160995688867,0.706905669147101,null,0.569160995688867,0.790750513602846,null,0.569160995688867,0.652893102514717,null,0.569160995688867,0.507330838524802,null,0.569160995688867,0.397382531719702,null,0.569160995688867,0.766391283806825,null,0.569160995688867,0.794267718308876,null,0.569160995688867,0.400502456724901,null,0.569160995688867,0.353917095092187,null,0.569160995688867,0.681102634202229,null,0.569160995688867,0.330126896249326,null,0.569160995688867,0.226078960900972,null,0.569160995688867,0.433071950534731,null,0.569160995688867,0.318177218131819,null,0.569160995688867,0.52108692904819,null,0.569160995688867,0.795580474185788,null,0.569160995688867,0.602473048893196,null,0.569160995688867,0.890637266562741,null,0.569160995688867,0.38541974057496,null,0.569160995688867,0.673983644043835,null,0.569160995688867,0.743738953933047,null,0.569160995688867,0.391621046140257,null,0.569160995688867,0.738554817935996,null,0.569160995688867,0.362277075606099,null,0.569160995688867,0.499892480849464,null,0.569160995688867,0.596306756988927,null,0.569160995688867,0.48663250019003,null,0.569160995688867,0.731603132724176,null,0.569160995688867,0.248224947253395,null,0.569160995688867,0.660967609845298,null,0.569160995688867,0.757704690180885,null,0.569160995688867,0.440833042358277,null,0.569160995688867,0.29230613907727,null,0.569160995688867,0.692108547150632,null,0.569160995688867,0.722552593201093,null,0.569160995688867,0.779566772792364,null,0.569160995688867,0.293658571587712,null,0.569160995688867,0.623872010701402,null,0.569160995688867,0.558400508620058,null,0.569160995688867,0.567379900773263,null,0.569160995688867,0.35140592652204,null,0.569160995688867,0.776667140978426,null,0.569160995688867,0.439970611795418,null,0.569160995688867,0.630420659925768,null,0.569160995688867,0.481745560133813,null,0.569160995688867,0.682727918749366,null,0.569160995688867,0.92057629612655,null,0.569160995688867,0.290597906211216,null,0.569160995688867,0.293020895485337,null,0.569160995688867,0.646450184799606,null,0.569160995688867,0.234796574249824,null,0.569160995688867,0.282678203793642,null,0.569160995688867,0.525240441471489,null,0.431120229838299,0.112745725388303,null,0.431120229838299,0.0444056056746168,null,0.431120229838299,0.423956953801238,null,0.431120229838299,0.363966682255993,null,0.431120229838299,0.342683823825281,null,0.431120229838299,0.0249917953368865,null,0.431120229838299,0.72793955906703,null,0.431120229838299,0.317512112957195,null,0.431120229838299,0.456188967076627,null,0.431120229838299,0.412103712493418,null,0.431120229838299,0.785832962930004,null,0.431120229838299,0.492145540267895,null,0.431120229838299,0.0790955843221721,null,0.431120229838299,0.553542181247174,null,0.431120229838299,0.610303574424963,null,0.431120229838299,0.339928250070011,null,0.431120229838299,0.529803288783676,null,0.431120229838299,0.69598769885774,null,0.431120229838299,0.656008187370694,null,0.431120229838299,0.494352565072096,null,0.431120229838299,0.383595999466942,null,0.431120229838299,0.758648437487308,null,0.431120229838299,0.790299043594228,null,0.431120229838299,0.38811812093232,null,0.431120229838299,0.356415884525852,null,0.431120229838299,0.567791599633868,null,0.431120229838299,0.326915446133837,null,0.431120229838299,0.220443275046877,null,0.431120229838299,0.418347411815101,null,0.431120229838299,0.30702377903189,null,0.431120229838299,0.0658807267901205,null,0.431120229838299,0.323211485611884,null,0.431120229838299,0.486820205426182,null,0.431120229838299,0.794043440951209,null,0.431120229838299,0.604151876231488,null,0.431120229838299,0.378505154407203,null,0.431120229838299,0.430136789994817,null,0.431120229838299,0.661806919823414,null,0.431120229838299,0.59297633568824,null,0.431120229838299,0.497708160513814,null,0.431120229838299,0.552001647928522,null,0.431120229838299,0.386350248794115,null,0.431120229838299,0.730944243145205,null,0.431120229838299,0.350136815874867,null,0.431120229838299,0.468332796516163,null,0.431120229838299,0.589271318459943,null,0.431120229838299,0.473002761793368,null,0.431120229838299,0.721893780615461,null,0.431120229838299,0.239720531920411,null,0.431120229838299,0.65071679012198,null,0.431120229838299,0.759482783021375,null,0.431120229838299,0.0328254834407966,null,0.431120229838299,0.428457965102359,null,0.431120229838299,0.0552949392361833,null,0.431120229838299,0.282301943960739,null,0.431120229838299,0.695332510166948,null,0.431120229838299,0.725196030215553,null,0.431120229838299,0.779233255836001,null,0.431120229838299,0.535995349933078,null,0.431120229838299,0.296494673471202,null,0.431120229838299,0.525245247427962,null,0.431120229838299,0.610013650135566,null,0.431120229838299,0.0808642105121057,null,0.431120229838299,0.528942468255864,null,0.431120229838299,0.542473592025233,null,0.431120229838299,0.350324392742041,null,0.431120229838299,0.777532139878526,null,0.431120229838299,0.429528939963174,null,0.431120229838299,0.264228305333004,null,0.431120229838299,0.368840712442177,null,0.431120229838299,0.625797494890473,null,0.431120229838299,0.470181257271697,null,0.431120229838299,0.683351609245627,null,0.431120229838299,0.44656137124754,null,0.431120229838299,0.401730764927989,null,0.431120229838299,0.626347514647346,null,0.431120229838299,0.306693554067584,null,0.431120229838299,0.0591609727033197,null,0.431120229838299,0.293567152525727,null,0.431120229838299,0.278705189823673,null,0.431120229838299,0.294645590613804,null,0.431120229838299,0.632043822399884,null,0.431120229838299,0.0355237610241484,null,0.431120229838299,0.227639887177766,null,0.431120229838299,0.272639222721547,null,0.431120229838299,0.514741952975215,null,0.606625452346477,0.859535865093592,null,0.606625452346477,0.739756232183998,null,0.606625452346477,0.436221837301925,null,0.606625452346477,0.379056237744055,null,0.606625452346477,0.91312608624495,null,0.606625452346477,0.736407738618357,null,0.606625452346477,0.322051155219775,null,0.606625452346477,0.471785034415842,null,0.606625452346477,0.429141262769335,null,0.606625452346477,0.787787381108505,null,0.606625452346477,0.833036829113688,null,0.606625452346477,0.529669391638273,null,0.606625452346477,0.62992689580365,null,0.606625452346477,0.337099350037149,null,0.606625452346477,0.567734378152831,null,0.606625452346477,0.692955070500771,null,0.606625452346477,0.670610502274201,null,0.606625452346477,0.389006460104837,null,0.606625452346477,0.758440984144511,null,0.606625452346477,0.794411052861901,null,0.606625452346477,0.3588378789462,null,0.606625452346477,0.580367806858259,null,0.606625452346477,0.325729957208961,null,0.606625452346477,0.33601079954507,null,0.606625452346477,0.517288855379863,null,0.606625452346477,0.800572023199591,null,0.606625452346477,0.620790174377316,null,0.606625452346477,0.38007998333845,null,0.606625452346477,0.4471248276189,null,0.606625452346477,0.658734961431972,null,0.606625452346477,0.604444621877097,null,0.606625452346477,0.512199211193021,null,0.606625452346477,0.784584825804592,null,0.606625452346477,0.403164457722146,null,0.606625452346477,0.73460721437942,null,0.606625452346477,0.48490907838717,null,0.606625452346477,0.504514992091818,null,0.606625452346477,0.720052366793743,null,0.606625452346477,0.66526726504584,null,0.606625452346477,0.769731814483659,null,0.606625452346477,0.908715323244131,null,0.606625452346477,0.800506299098387,null,0.606625452346477,0.708573846552134,null,0.606625452346477,0.73715564666885,null,0.606625452346477,0.787435383216903,null,0.606625452346477,0.54950894420136,null,0.606625452346477,0.297359040053189,null,0.606625452346477,0.540951316685004,null,0.606625452346477,0.615033702946875,null,0.606625452346477,0.768513227719205,null,0.606625452346477,0.976569368809676,null,0.606625452346477,0.547005982613965,null,0.606625452346477,0.57460788618157,null,0.606625452346477,0.359950196244683,null,0.606625452346477,0.786570205626223,null,0.606625452346477,0.454199922220728,null,0.606625452346477,0.273611892389914,null,0.606625452346477,0.382898722233648,null,0.606625452346477,0.697573634631695,null,0.606625452346477,0.461249178084479,null,0.606625452346477,0.41642819083354,null,0.606625452346477,0.862476091840542,null,0.606625452346477,0.635182177283979,null,0.606625452346477,0.318957682534318,null,0.606625452346477,0.939468290680027,null,0.606625452346477,0.921633477814331,null,0.606625452346477,0.292204861042371,null,0.606625452346477,0.289459298431681,null,0.606625452346477,0.292139116145475,null,0.606625452346477,0.644342212099804],&quot;text&quot;:&quot;&quot;,&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;lines&quot;,&quot;name&quot;:&quot;&quot;,&quot;line&quot;:{&quot;width&quot;:1.51181102362205,&quot;color&quot;:&quot;rgba(0,0,0,0.25)&quot;,&quot;dash&quot;:&quot;solid&quot;},&quot;hoveron&quot;:&quot;points&quot;,&quot;showlegend&quot;:false,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;},{&quot;x&quot;:[0.521403286626722,0.671140685588431,0.375141921794262,0.765433674821922,0.43003460140041,0.402985942440944,0.84084345291753,0.21744563280704,0.532451210931874,0.504593085123351,0.619957582285487,0.8955442569087,0.611347637416103,0.578612821595516,0.619986741987121,0.31856048451924,0.143674118503684,0.41577369478791,0.486737879369046,0.689381852752525,0.67926017758219,0.324759599339248,0.173105393811894,0.401806967433101,0.625093468651365,0.533643660739264,0.139059392615991,0.580482498031979,0.889371263506008,0.441034023506735,0.328997789998789,0.188146187976479,0.175417155899145,0.667964135344807,0.867209259774224,0.462224807828379,0.473147173626519,0.332510771213912,0.444798800647148,0.860144448181576,0.698597335052531,0.868517308402764,0.910464825406683,0.674260653107368,0.574957868338127,0.15657340761276,0.364158010341015,0.158399345383069,0.69234220151995,0.655252166509386,0.239274886254818,0.520974365455486,0.380823367989187,0.481335870748195,0.132624918275902,0.377088499410607,0.271772128789835,0.341243594957798,0.359879117638533,0.440128461028902,0.906177103569992,0.582788790098704,0.870334570284953,0.705819372835664,0.715461522230034,0.343495780883717,0.545987437918483,0.645964077621439,0.407521881572988,0.668404909032591,0.77167646526947,0.8914749306502,0.177266541298859,0.124018346349651,0.415880094563685,0.915332535986102,0.900022297154391,0.855535494382103,0.830657240556608,0.573755057967315,0.544026072872229,0.810457837840253,0.498223697293128,0.579532690993623,0.623620987764108,0.286462405990908,0.20395324106583,0.131785501344588,0.93008668223084,0.977210590176681,0.44698052174715,0.986694656148139,1,0.926474161477072,0.97376640007797,0.968887131203832,0.817508248450742,0.977227846723922,0.880044881121601,0.507977017129905,0.0746705351486458,0.127382447038518,0.164705115708696,0.0489287697707225,0,0.106243608944116,0.0202596198892614],&quot;y&quot;:[0.431120229838299,0.606625452346477,0.569160995688867,0.09246296759897,0.0200010406187948,0.422047040860041,0.358418797478641,0.335157224371917,0,0.752905515450738,0.297386709329046,0.457979060263399,0.405174680562283,0.810553549546238,0.507450868456385,0.0571196657532421,0.561710911053716,0.632441419205886,0.315989832124438,0.543723612264242,0.717888767473633,0.675485043953967,0.499144657958617,0.372609464357107,0.78262691923918,0.815286363259276,0.38513268939525,0.33512494011877,0.577005434457349,0.305874863997627,0.201273328844625,0.417312481748539,0.29804934330396,0.0424888451454258,0.315269915034613,0.506482572757214,0.818852040928785,0.621918028502378,0.361720194031298,0.430058426462415,0.682233506854299,0.6041283622506,0.502201255718198,0.378166788678553,0.755610558391853,0.344352385454589,0.47506107210985,0.599806755197404,0.479857466837873,0.744888916191422,0.224971127027988,0.675716751683746,0.782695845956098,0.00793679169333242,0.428275011085709,0.0317831563497688,0.268665777988368,0.716471818366063,0.747461498155205,0.803658735935986,0.542973959390201,0.273193030384949,0.532201448438718,0.628271147762158,0.0586934552184285,0.542181191061762,0.567074622385955,0.335056943593166,0.801427691365256,0.429202893723559,0.249547509938375,0.364405318201653,0.638710543358149,0.472788360145209,0.706698521200172,0.44760674254476,0.399660639700303,0.639580485668839,0.296729618443331,0.0343758173552134,0.268806495055556,0.266323068392153,0.26990004648938,0.656249938027159,0.0112331742330788,0.210527505954269,0.260820921495153,0.520321221280843,0.877610473999273,0.750384584971701,0.933748805015228,0.848235133910355,0.797115553956288,0.928296387291171,0.814668981131777,0.781155630734667,1,0.879098670095927,0.961004797952491,0.944141392538796,0.851987325743841,0.890257656167,0.928797315869835,0.805414487525129,0.688692416406541,0.910270490085591,0.755353918729029],&quot;text&quot;:[&quot;EWR&quot;,&quot;JFK&quot;,&quot;LGA&quot;,&quot;ALB&quot;,&quot;ANC&quot;,&quot;ATL&quot;,&quot;AUS&quot;,&quot;AVL&quot;,&quot;BDL&quot;,&quot;BNA&quot;,&quot;BOS&quot;,&quot;BQN&quot;,&quot;BTV&quot;,&quot;BUF&quot;,&quot;BWI&quot;,&quot;BZN&quot;,&quot;CAE&quot;,&quot;CHS&quot;,&quot;CLE&quot;,&quot;CLT&quot;,&quot;CMH&quot;,&quot;CVG&quot;,&quot;DAY&quot;,&quot;DCA&quot;,&quot;DEN&quot;,&quot;DFW&quot;,&quot;DSM&quot;,&quot;DTW&quot;,&quot;EGE&quot;,&quot;FLL&quot;,&quot;GRR&quot;,&quot;GSO&quot;,&quot;GSP&quot;,&quot;HDN&quot;,&quot;HNL&quot;,&quot;HOU&quot;,&quot;IAD&quot;,&quot;IAH&quot;,&quot;IND&quot;,&quot;JAC&quot;,&quot;JAX&quot;,&quot;LAS&quot;,&quot;LAX&quot;,&quot;MCI&quot;,&quot;MCO&quot;,&quot;MDW&quot;,&quot;MEM&quot;,&quot;MHT&quot;,&quot;MIA&quot;,&quot;MKE&quot;,&quot;MSN&quot;,&quot;MSP&quot;,&quot;MSY&quot;,&quot;MTJ&quot;,&quot;MYR&quot;,&quot;OKC&quot;,&quot;OMA&quot;,&quot;ORD&quot;,&quot;ORF&quot;,&quot;PBI&quot;,&quot;PDX&quot;,&quot;PHL&quot;,&quot;PHX&quot;,&quot;PIT&quot;,&quot;PVD&quot;,&quot;PWM&quot;,&quot;RDU&quot;,&quot;RIC&quot;,&quot;ROC&quot;,&quot;RSW&quot;,&quot;SAN&quot;,&quot;SAT&quot;,&quot;SAV&quot;,&quot;SBN&quot;,&quot;SDF&quot;,&quot;SEA&quot;,&quot;SFO&quot;,&quot;SJU&quot;,&quot;SLC&quot;,&quot;SNA&quot;,&quot;STL&quot;,&quot;STT&quot;,&quot;SYR&quot;,&quot;TPA&quot;,&quot;TUL&quot;,&quot;TVC&quot;,&quot;TYS&quot;,&quot;XNA&quot;,&quot;ABQ&quot;,&quot;ACK&quot;,&quot;BHM&quot;,&quot;BUR&quot;,&quot;LGB&quot;,&quot;MVY&quot;,&quot;OAK&quot;,&quot;PSE&quot;,&quot;PSP&quot;,&quot;SJC&quot;,&quot;SMF&quot;,&quot;SRQ&quot;,&quot;BGR&quot;,&quot;CAK&quot;,&quot;CHO&quot;,&quot;CRW&quot;,&quot;EYW&quot;,&quot;ILM&quot;,&quot;LEX&quot;],&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;markers&quot;,&quot;marker&quot;:{&quot;autocolorscale&quot;:false,&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;,&quot;opacity&quot;:1,&quot;size&quot;:[22.6771653543307,20.8059185906475,20.6820886488173,3.77952755905512,3.77952755905512,6.67829287123416,5.82926416836526,5.82926416836526,3.77952755905512,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,3.77952755905512,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,5.82926416836526,5.82926416836526,3.77952755905512,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,5.82926416836526,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,3.77952755905512,5.82926416836526,3.77952755905512,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,6.67829287123416,3.77952755905512,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,5.82926416836526,5.82926416836526,5.82926416836526,6.67829287123416,5.82926416836526,5.82926416836526,5.82926416836526,5.82926416836526,3.77952755905512,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,3.77952755905512,5.82926416836526,5.82926416836526,5.82926416836526,3.77952755905512,3.77952755905512,5.82926416836526,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,5.82926416836526,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512],&quot;symbol&quot;:&quot;circle&quot;,&quot;line&quot;:{&quot;width&quot;:1.88976377952756,&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;}},&quot;hoveron&quot;:&quot;points&quot;,&quot;showlegend&quot;:false,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;,&quot;name&quot;:&quot;&quot;}],&quot;layout&quot;:{&quot;margin&quot;:{&quot;t&quot;:48.079701120797,&quot;r&quot;:7.97011207970112,&quot;b&quot;:16.9364881693649,&quot;l&quot;:11.9551681195517},&quot;plot_bgcolor&quot;:&quot;rgba(255,255,255,1)&quot;,&quot;paper_bgcolor&quot;:&quot;rgba(255,255,255,1)&quot;,&quot;font&quot;:{&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;,&quot;family&quot;:&quot;&quot;,&quot;size&quot;:15.9402241594022},&quot;title&quot;:&quot;Network Graph of U.S. Flights Outbound from NYC in 2013&quot;,&quot;titlefont&quot;:{&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;,&quot;family&quot;:&quot;&quot;,&quot;size&quot;:19.1282689912827},&quot;xaxis&quot;:{&quot;domain&quot;:[0,1],&quot;type&quot;:&quot;linear&quot;,&quot;autorange&quot;:false,&quot;tickmode&quot;:&quot;array&quot;,&quot;range&quot;:[-0.05,1.05],&quot;ticktext&quot;:[&quot;0.00&quot;,&quot;0.25&quot;,&quot;0.50&quot;,&quot;0.75&quot;,&quot;1.00&quot;],&quot;tickvals&quot;:[0,0.25,0.5,0.75,1],&quot;ticks&quot;:&quot;&quot;,&quot;tickcolor&quot;:null,&quot;ticklen&quot;:3.98505603985056,&quot;tickwidth&quot;:0,&quot;showticklabels&quot;:false,&quot;tickfont&quot;:{&quot;color&quot;:null,&quot;family&quot;:null,&quot;size&quot;:0},&quot;tickangle&quot;:-0,&quot;showline&quot;:false,&quot;linecolor&quot;:null,&quot;linewidth&quot;:0,&quot;showgrid&quot;:false,&quot;gridcolor&quot;:null,&quot;gridwidth&quot;:0,&quot;zeroline&quot;:false,&quot;anchor&quot;:&quot;y&quot;,&quot;title&quot;:&quot;&quot;,&quot;titlefont&quot;:{&quot;color&quot;:null,&quot;family&quot;:null,&quot;size&quot;:0},&quot;hoverformat&quot;:&quot;.2f&quot;},&quot;yaxis&quot;:{&quot;domain&quot;:[0,1],&quot;type&quot;:&quot;linear&quot;,&quot;autorange&quot;:false,&quot;tickmode&quot;:&quot;array&quot;,&quot;range&quot;:[-0.05,1.05],&quot;ticktext&quot;:[&quot;0.00&quot;,&quot;0.25&quot;,&quot;0.50&quot;,&quot;0.75&quot;,&quot;1.00&quot;],&quot;tickvals&quot;:[0,0.25,0.5,0.75,1],&quot;ticks&quot;:&quot;&quot;,&quot;tickcolor&quot;:null,&quot;ticklen&quot;:3.98505603985056,&quot;tickwidth&quot;:0,&quot;showticklabels&quot;:false,&quot;tickfont&quot;:{&quot;color&quot;:null,&quot;family&quot;:null,&quot;size&quot;:0},&quot;tickangle&quot;:-0,&quot;showline&quot;:false,&quot;linecolor&quot;:null,&quot;linewidth&quot;:0,&quot;showgrid&quot;:false,&quot;gridcolor&quot;:null,&quot;gridwidth&quot;:0,&quot;zeroline&quot;:false,&quot;anchor&quot;:&quot;x&quot;,&quot;title&quot;:&quot;&quot;,&quot;titlefont&quot;:{&quot;color&quot;:null,&quot;family&quot;:null,&quot;size&quot;:0},&quot;hoverformat&quot;:&quot;.2f&quot;},&quot;shapes&quot;:[{&quot;type&quot;:&quot;rect&quot;,&quot;fillcolor&quot;:null,&quot;line&quot;:{&quot;color&quot;:null,&quot;width&quot;:0,&quot;linetype&quot;:[]},&quot;yref&quot;:&quot;paper&quot;,&quot;xref&quot;:&quot;paper&quot;,&quot;x0&quot;:0,&quot;x1&quot;:1,&quot;y0&quot;:0,&quot;y1&quot;:1}],&quot;showlegend&quot;:false,&quot;legend&quot;:{&quot;bgcolor&quot;:&quot;rgba(255,255,255,1)&quot;,&quot;bordercolor&quot;:&quot;transparent&quot;,&quot;borderwidth&quot;:1.88976377952756,&quot;font&quot;:{&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;,&quot;family&quot;:&quot;&quot;,&quot;size&quot;:12.7521793275218}},&quot;hovermode&quot;:&quot;closest&quot;,&quot;height&quot;:400},&quot;source&quot;:&quot;A&quot;,&quot;config&quot;:{&quot;modeBarButtonsToAdd&quot;:[{&quot;name&quot;:&quot;Collaborate&quot;,&quot;icon&quot;:{&quot;width&quot;:1000,&quot;ascent&quot;:500,&quot;descent&quot;:-50,&quot;path&quot;:&quot;M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z&quot;},&quot;click&quot;:&quot;function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == '?viewer_pane=1') {\n          alert('To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html');\n        } else {\n          window.open('https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html', '_blank');\n        }\n      }&quot;}],&quot;modeBarButtonsToRemove&quot;:[&quot;sendDataToCloud&quot;]},&quot;.plotlyWebGl&quot;:true,&quot;base_url&quot;:&quot;https://plot.ly&quot;},&quot;evals&quot;:[&quot;config.modeBarButtonsToAdd.0.click&quot;],&quot;jsHooks&quot;:[]}&lt;/script&gt;

&lt;script type=&quot;application/htmlwidget-sizing&quot; data-for=&quot;htmlwidget-51f6648a07e11b1abf04&quot;&gt;{&quot;viewer&quot;:{&quot;width&quot;:&quot;100%&quot;,&quot;height&quot;:400,&quot;padding&quot;:0,&quot;fill&quot;:false},&quot;browser&quot;:{&quot;width&quot;:&quot;100%&quot;,&quot;height&quot;:400,&quot;padding&quot;:0,&quot;fill&quot;:false}}&lt;/script&gt;

&lt;p&gt;You can now mouse over the points to see the corresponding airport. Not too shabby!&lt;/p&gt;

&lt;p&gt;When generating the interactive charts in R, a browser window will pop up with the chart, and the chart contains an option to save the chart to a Plotly account. This is the most practical way to embed the chart for a blog service such as Wordpress or Medium. (in my case, I embed the charts directly into the blog post as static data so it will always be accessible).&lt;/p&gt;

&lt;p&gt;With a little more data manipulation, we can integrate more metadata into the network (not shown; however all code is available in &lt;a href=&quot;http://minimaxir.com/notebooks/interactive-network/&quot;&gt;this R Notebook&lt;/a&gt;). The nycflights13 package also contains an &lt;code&gt;airports&lt;/code&gt; dataset with the full name of the airports and their location in latitude/longitude coordinates. We can map that data into the corresponding vertices, and use some of it for more informative tooltip popovers, such as including the total number of flights to/from each airport. Additionally, we can set the colors of edges to correspond to the NYC origin airport. The algorithm is also set to 50,000 iterations for even further convergence.&lt;/p&gt;

&lt;p&gt;The result is the network graph you saw at the beginning of the post.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/interactive-network/ggplot1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Looking at this network graph, you can clearly see that some airports receive flights from all 3 airports, some from only 2 airports, and some from only 1 airport. I admit I am not an expert in the inner-workings of the airline industry, but what would cause this?&lt;/p&gt;

&lt;h2&gt;Sea to Shining Sea&lt;/h2&gt;

&lt;p&gt;Another approach is to map the airports by their physical location. This is easy to do on the ggplot2-side since the latitude/longitudes were added to the data set for the previous chart, so all we have to do is tell ggplot2 to use those instead, where the base aesthetics of the ggplot statement now become:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;df_net&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; lon&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; y &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; lat&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; xend &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; endlon&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; yend &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; endlat&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The result is a highly-abstract depiction of the United States. (+ Alaska and Hawaii)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/interactive-network/ggplot2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Again, one line of code makes it interactive.&lt;/p&gt;

&lt;div id=&quot;htmlwidget_container&quot;&gt;
  &lt;div id=&quot;htmlwidget-ae87c24ac18b3ac8a6fa&quot; style=&quot;width:100%;height:400px;&quot; class=&quot;plotly html-widget&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;script type=&quot;application/json&quot; data-for=&quot;htmlwidget-ae87c24ac18b3ac8a6fa&quot;&gt;{&quot;x&quot;:{&quot;data&quot;:[{&quot;x&quot;:[-74.168667,-73.801692,null,-74.168667,-149.996361,null,-74.168667,-84.428067,null,-74.168667,-97.669889,null,-74.168667,-82.541806,null,-74.168667,-72.683222,null,-74.168667,-86.678194,null,-74.168667,-71.005181,null,-74.168667,-73.153278,null,-74.168667,-78.732167,null,-74.168667,-76.668333,null,-74.168667,-111.160151,null,-74.168667,-81.119528,null,-74.168667,-80.040528,null,-74.168667,-81.849794,null,-74.168667,-80.943139,null,-74.168667,-82.891889,null,-74.168667,-84.667822,null,-74.168667,-84.219375,null,-74.168667,-77.037722,null,-74.168667,-104.673178,null,-74.168667,-97.037997,null,-74.168667,-93.663083,null,-74.168667,-83.353389,null,-74.168667,-106.917694,null,-74.168667,-80.15275,null,-74.168667,-85.522806,null,-74.168667,-79.937306,null,-74.168667,-82.218889,null,-74.168667,-107.21766,null,-74.168667,-157.922428,null,-74.168667,-95.278889,null,-74.168667,-77.455811,null,-74.168667,-95.341442,null,-74.168667,-86.294383,null,-74.168667,-110.73775,null,-74.168667,-81.687861,null,-74.168667,-115.15225,null,-74.168667,-118.408075,null,-74.168667,-73.872608,null,-74.168667,-94.713905,null,-74.168667,-81.308994,null,-74.168667,-87.752417,null,-74.168667,-89.976667,null,-74.168667,-71.435667,null,-74.168667,-80.290556,null,-74.168667,-87.896583,null,-74.168667,-89.337514,null,-74.168667,-93.221767,null,-74.168667,-90.258028,null,-74.168667,-107.894242,null,-74.168667,-78.928333,null,-74.168667,-97.600733,null,-74.168667,-95.894069,null,-74.168667,-87.904842,null,-74.168667,-76.201222,null,-74.168667,-80.095589,null,-74.168667,-122.5975,null,-74.168667,-75.241139,null,-74.168667,-112.011583,null,-74.168667,-80.232872,null,-74.168667,-71.420383,null,-74.168667,-70.309281,null,-74.168667,-78.787472,null,-74.168667,-77.319667,null,-74.168667,-77.672389,null,-74.168667,-81.755167,null,-74.168667,-117.189667,null,-74.168667,-98.469778,null,-74.168667,-81.202139,null,-74.168667,-86.31725,null,-74.168667,-85.7364989,null,-74.168667,-122.309306,null,-74.168667,-122.374889,null,-74.168667,-111.977772,null,-74.168667,-117.868222,null,-74.168667,-90.370028,null,-74.168667,-76.106311,null,-74.168667,-82.53325,null,-74.168667,-95.888111,null,-74.168667,-85.582235,null,-74.168667,-83.994028,null,-74.168667,-94.3068111],&quot;y&quot;:[40.6925,42.748267,null,40.6925,61.174361,null,40.6925,33.636719,null,40.6925,30.194528,null,40.6925,35.436194,null,40.6925,41.938889,null,40.6925,36.124472,null,40.6925,42.364347,null,40.6925,44.471861,null,40.6925,42.940525,null,40.6925,39.175361,null,40.6925,45.777643,null,40.6925,33.938833,null,40.6925,32.898647,null,40.6925,41.411689,null,40.6925,35.214,null,40.6925,39.997972,null,40.6925,39.048836,null,40.6925,39.902375,null,40.6925,38.852083,null,40.6925,39.861656,null,40.6925,32.896828,null,40.6925,41.533972,null,40.6925,42.212444,null,40.6925,39.642556,null,40.6925,26.072583,null,40.6925,42.880833,null,40.6925,36.09775,null,40.6925,34.895556,null,40.6925,40.481181,null,40.6925,21.318681,null,40.6925,29.645419,null,40.6925,38.944533,null,40.6925,29.984433,null,40.6925,39.717331,null,40.6925,43.607333333,null,40.6925,30.494056,null,40.6925,36.080056,null,40.6925,33.942536,null,40.6925,40.777245,null,40.6925,39.297606,null,40.6925,28.429394,null,40.6925,41.785972,null,40.6925,35.042417,null,40.6925,42.932556,null,40.6925,25.79325,null,40.6925,42.947222,null,40.6925,43.139858,null,40.6925,44.881956,null,40.6925,29.993389,null,40.6925,38.509794,null,40.6925,33.67975,null,40.6925,35.393089,null,40.6925,41.303167,null,40.6925,41.978603,null,40.6925,36.894611,null,40.6925,26.683161,null,40.6925,45.588722,null,40.6925,39.871944,null,40.6925,33.434278,null,40.6925,40.491467,null,40.6925,41.732581,null,40.6925,43.646161,null,40.6925,35.877639,null,40.6925,37.505167,null,40.6925,43.118866,null,40.6925,26.536167,null,40.6925,32.733556,null,40.6925,29.533694,null,40.6925,32.127583,null,40.6925,41.708661,null,40.6925,38.1740858,null,40.6925,47.449,null,40.6925,37.618972,null,40.6925,40.788389,null,40.6925,33.675667,null,40.6925,38.748697,null,40.6925,43.111187,null,40.6925,27.975472,null,40.6925,36.198389,null,40.6925,44.741445,null,40.6925,35.810972,null,40.6925,36.2818694],&quot;text&quot;:&quot;&quot;,&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;lines&quot;,&quot;name&quot;:&quot;EWR&quot;,&quot;line&quot;:{&quot;width&quot;:1.51181102362205,&quot;color&quot;:&quot;rgba(52,152,219,0.25)&quot;,&quot;dash&quot;:&quot;solid&quot;},&quot;hoveron&quot;:&quot;points&quot;,&quot;legendgroup&quot;:&quot;EWR&quot;,&quot;showlegend&quot;:true,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;},{&quot;x&quot;:[-73.778925,-106.6091944,null,-73.778925,-70.060181,null,-73.778925,-84.428067,null,-73.778925,-97.669889,null,-73.778925,-86.75355,null,-73.778925,-86.678194,null,-73.778925,-71.005181,null,-73.778925,-73.153278,null,-73.778925,-78.732167,null,-73.778925,-118.358667,null,-73.778925,-76.668333,null,-73.778925,-80.040528,null,-73.778925,-81.849794,null,-73.778925,-80.943139,null,-73.778925,-82.891889,null,-73.778925,-84.667822,null,-73.778925,-77.037722,null,-73.778925,-104.673178,null,-73.778925,-97.037997,null,-73.778925,-83.353389,null,-73.778925,-106.917694,null,-73.778925,-80.15275,null,-73.778925,-157.922428,null,-73.778925,-95.278889,null,-73.778925,-77.455811,null,-73.778925,-95.341442,null,-73.778925,-86.294383,null,-73.778925,-110.73775,null,-73.778925,-81.687861,null,-73.778925,-115.15225,null,-73.778925,-118.408075,null,-73.778925,-118.151611,null,-73.778925,-94.713905,null,-73.778925,-81.308994,null,-73.778925,-89.976667,null,-73.778925,-80.290556,null,-73.778925,-87.896583,null,-73.778925,-93.221767,null,-73.778925,-90.258028,null,-73.778925,-70.615278,null,-73.778925,-122.220722,null,-73.778925,-87.904842,null,-73.778925,-76.201222,null,-73.778925,-80.095589,null,-73.778925,-122.5975,null,-73.778925,-75.241139,null,-73.778925,-112.011583,null,-73.778925,-80.232872,null,-73.778925,-116.506694,null,-73.778925,-70.309281,null,-73.778925,-78.787472,null,-73.778925,-77.319667,null,-73.778925,-77.672389,null,-73.778925,-81.755167,null,-73.778925,-117.189667,null,-73.778925,-98.469778,null,-73.778925,-85.7364989,null,-73.778925,-122.309306,null,-73.778925,-122.374889,null,-73.778925,-121.929022,null,-73.778925,-111.977772,null,-73.778925,-121.590778,null,-73.778925,-82.554389,null,-73.778925,-90.370028,null,-73.778925,-76.106311,null,-73.778925,-82.53325],&quot;y&quot;:[40.639751,35.0402222,null,40.639751,41.253053,null,40.639751,33.636719,null,40.639751,30.194528,null,40.639751,33.562942,null,40.639751,36.124472,null,40.639751,42.364347,null,40.639751,44.471861,null,40.639751,42.940525,null,40.639751,34.200667,null,40.639751,39.175361,null,40.639751,32.898647,null,40.639751,41.411689,null,40.639751,35.214,null,40.639751,39.997972,null,40.639751,39.048836,null,40.639751,38.852083,null,40.639751,39.861656,null,40.639751,32.896828,null,40.639751,42.212444,null,40.639751,39.642556,null,40.639751,26.072583,null,40.639751,21.318681,null,40.639751,29.645419,null,40.639751,38.944533,null,40.639751,29.984433,null,40.639751,39.717331,null,40.639751,43.607333333,null,40.639751,30.494056,null,40.639751,36.080056,null,40.639751,33.942536,null,40.639751,33.817722,null,40.639751,39.297606,null,40.639751,28.429394,null,40.639751,35.042417,null,40.639751,25.79325,null,40.639751,42.947222,null,40.639751,44.881956,null,40.639751,29.993389,null,40.639751,41.391667,null,40.639751,37.721278,null,40.639751,41.978603,null,40.639751,36.894611,null,40.639751,26.683161,null,40.639751,45.588722,null,40.639751,39.871944,null,40.639751,33.434278,null,40.639751,40.491467,null,40.639751,33.829667,null,40.639751,43.646161,null,40.639751,35.877639,null,40.639751,37.505167,null,40.639751,43.118866,null,40.639751,26.536167,null,40.639751,32.733556,null,40.639751,29.533694,null,40.639751,38.1740858,null,40.639751,47.449,null,40.639751,37.618972,null,40.639751,37.3626,null,40.639751,40.788389,null,40.639751,38.695417,null,40.639751,27.395444,null,40.639751,38.748697,null,40.639751,43.111187,null,40.639751,27.975472],&quot;text&quot;:&quot;&quot;,&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;lines&quot;,&quot;name&quot;:&quot;JFK&quot;,&quot;line&quot;:{&quot;width&quot;:1.51181102362205,&quot;color&quot;:&quot;rgba(231,76,60,0.25)&quot;,&quot;dash&quot;:&quot;solid&quot;},&quot;hoveron&quot;:&quot;points&quot;,&quot;legendgroup&quot;:&quot;JFK&quot;,&quot;showlegend&quot;:true,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;},{&quot;x&quot;:[-73.872608,-84.428067,null,-73.872608,-82.541806,null,-73.872608,-68.828139,null,-73.872608,-86.75355,null,-73.872608,-86.678194,null,-73.872608,-71.005181,null,-73.872608,-73.153278,null,-73.872608,-78.732167,null,-73.872608,-76.668333,null,-73.872608,-81.119528,null,-73.872608,-81.4421944,null,-73.872608,-78.452861,null,-73.872608,-80.040528,null,-73.872608,-81.849794,null,-73.872608,-80.943139,null,-73.872608,-82.891889,null,-73.872608,-81.593189,null,-73.872608,-84.667822,null,-73.872608,-84.219375,null,-73.872608,-77.037722,null,-73.872608,-104.673178,null,-73.872608,-97.037997,null,-73.872608,-93.663083,null,-73.872608,-83.353389,null,-73.872608,-81.759556,null,-73.872608,-80.15275,null,-73.872608,-85.522806,null,-73.872608,-79.937306,null,-73.872608,-82.218889,null,-73.872608,-95.278889,null,-73.872608,-77.455811,null,-73.872608,-95.341442,null,-73.872608,-77.902569,null,-73.872608,-86.294383,null,-73.872608,-81.687861,null,-73.872608,-84.605889,null,-73.872608,-94.713905,null,-73.872608,-81.308994,null,-73.872608,-87.752417,null,-73.872608,-89.976667,null,-73.872608,-71.435667,null,-73.872608,-80.290556,null,-73.872608,-87.896583,null,-73.872608,-89.337514,null,-73.872608,-93.221767,null,-73.872608,-90.258028,null,-73.872608,-78.928333,null,-73.872608,-95.894069,null,-73.872608,-87.904842,null,-73.872608,-76.201222,null,-73.872608,-80.095589,null,-73.872608,-75.241139,null,-73.872608,-80.232872,null,-73.872608,-70.309281,null,-73.872608,-78.787472,null,-73.872608,-77.319667,null,-73.872608,-77.672389,null,-73.872608,-81.755167,null,-73.872608,-81.202139,null,-73.872608,-86.31725,null,-73.872608,-85.7364989,null,-73.872608,-82.554389,null,-73.872608,-90.370028,null,-73.872608,-76.106311,null,-73.872608,-82.53325,null,-73.872608,-85.582235,null,-73.872608,-83.994028,null,-73.872608,-94.3068111],&quot;y&quot;:[40.777245,33.636719,null,40.777245,35.436194,null,40.777245,44.807444,null,40.777245,33.562942,null,40.777245,36.124472,null,40.777245,42.364347,null,40.777245,44.471861,null,40.777245,42.940525,null,40.777245,39.175361,null,40.777245,33.938833,null,40.777245,40.9160833,null,40.777245,38.138639,null,40.777245,32.898647,null,40.777245,41.411689,null,40.777245,35.214,null,40.777245,39.997972,null,40.777245,38.373147,null,40.777245,39.048836,null,40.777245,39.902375,null,40.777245,38.852083,null,40.777245,39.861656,null,40.777245,32.896828,null,40.777245,41.533972,null,40.777245,42.212444,null,40.777245,24.556111,null,40.777245,26.072583,null,40.777245,42.880833,null,40.777245,36.09775,null,40.777245,34.895556,null,40.777245,29.645419,null,40.777245,38.944533,null,40.777245,29.984433,null,40.777245,34.270615,null,40.777245,39.717331,null,40.777245,30.494056,null,40.777245,38.0365,null,40.777245,39.297606,null,40.777245,28.429394,null,40.777245,41.785972,null,40.777245,35.042417,null,40.777245,42.932556,null,40.777245,25.79325,null,40.777245,42.947222,null,40.777245,43.139858,null,40.777245,44.881956,null,40.777245,29.993389,null,40.777245,33.67975,null,40.777245,41.303167,null,40.777245,41.978603,null,40.777245,36.894611,null,40.777245,26.683161,null,40.777245,39.871944,null,40.777245,40.491467,null,40.777245,43.646161,null,40.777245,35.877639,null,40.777245,37.505167,null,40.777245,43.118866,null,40.777245,26.536167,null,40.777245,32.127583,null,40.777245,41.708661,null,40.777245,38.1740858,null,40.777245,27.395444,null,40.777245,38.748697,null,40.777245,43.111187,null,40.777245,27.975472,null,40.777245,44.741445,null,40.777245,35.810972,null,40.777245,36.2818694],&quot;text&quot;:&quot;&quot;,&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;lines&quot;,&quot;name&quot;:&quot;LGA&quot;,&quot;line&quot;:{&quot;width&quot;:1.51181102362205,&quot;color&quot;:&quot;rgba(46,204,113,0.25)&quot;,&quot;dash&quot;:&quot;solid&quot;},&quot;hoveron&quot;:&quot;points&quot;,&quot;legendgroup&quot;:&quot;LGA&quot;,&quot;showlegend&quot;:true,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;},{&quot;x&quot;:[-74.168667],&quot;y&quot;:[40.6925],&quot;text&quot;:&quot;EWR&lt;br&gt;Newark Liberty Intl&lt;br&gt;120,835 Flights&quot;,&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;markers&quot;,&quot;marker&quot;:{&quot;autocolorscale&quot;:false,&quot;color&quot;:&quot;rgba(52,152,219,1)&quot;,&quot;opacity&quot;:1,&quot;size&quot;:22.6771653543307,&quot;symbol&quot;:&quot;circle&quot;,&quot;line&quot;:{&quot;width&quot;:1.88976377952756,&quot;color&quot;:&quot;rgba(52,152,219,1)&quot;}},&quot;hoveron&quot;:&quot;points&quot;,&quot;name&quot;:&quot;EWR&quot;,&quot;legendgroup&quot;:&quot;EWR&quot;,&quot;showlegend&quot;:false,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;},{&quot;x&quot;:[-73.778925],&quot;y&quot;:[40.639751],&quot;text&quot;:&quot;JFK&lt;br&gt;John F Kennedy Intl&lt;br&gt;111,279 Flights&quot;,&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;markers&quot;,&quot;marker&quot;:{&quot;autocolorscale&quot;:false,&quot;color&quot;:&quot;rgba(231,76,60,1)&quot;,&quot;opacity&quot;:1,&quot;size&quot;:20.8059185906475,&quot;symbol&quot;:&quot;circle&quot;,&quot;line&quot;:{&quot;width&quot;:1.88976377952756,&quot;color&quot;:&quot;rgba(231,76,60,1)&quot;}},&quot;hoveron&quot;:&quot;points&quot;,&quot;name&quot;:&quot;JFK&quot;,&quot;legendgroup&quot;:&quot;JFK&quot;,&quot;showlegend&quot;:false,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;},{&quot;x&quot;:[-73.872608],&quot;y&quot;:[40.777245],&quot;text&quot;:&quot;LGA&lt;br&gt;La Guardia&lt;br&gt;104,663 Flights&quot;,&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;markers&quot;,&quot;marker&quot;:{&quot;autocolorscale&quot;:false,&quot;color&quot;:&quot;rgba(46,204,113,1)&quot;,&quot;opacity&quot;:1,&quot;size&quot;:20.6820886488173,&quot;symbol&quot;:&quot;circle&quot;,&quot;line&quot;:{&quot;width&quot;:1.88976377952756,&quot;color&quot;:&quot;rgba(46,204,113,1)&quot;}},&quot;hoveron&quot;:&quot;points&quot;,&quot;name&quot;:&quot;LGA&quot;,&quot;legendgroup&quot;:&quot;LGA&quot;,&quot;showlegend&quot;:false,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;},{&quot;x&quot;:[-73.801692,-149.996361,-84.428067,-97.669889,-82.541806,-72.683222,-86.678194,-71.005181,null,-73.153278,-78.732167,-76.668333,-111.160151,-81.119528,-80.040528,-81.849794,-80.943139,-82.891889,-84.667822,-84.219375,-77.037722,-104.673178,-97.037997,-93.663083,-83.353389,-106.917694,-80.15275,-85.522806,-79.937306,-82.218889,-107.21766,-157.922428,-95.278889,-77.455811,-95.341442,-86.294383,-110.73775,-81.687861,-115.15225,-118.408075,-94.713905,-81.308994,-87.752417,-89.976667,-71.435667,-80.290556,-87.896583,-89.337514,-93.221767,-90.258028,-107.894242,-78.928333,-97.600733,-95.894069,-87.904842,-76.201222,-80.095589,-122.5975,-75.241139,-112.011583,-80.232872,-71.420383,-70.309281,-78.787472,-77.319667,-77.672389,-81.755167,-117.189667,-98.469778,-81.202139,-86.31725,-85.7364989,-122.309306,-122.374889,null,-111.977772,-117.868222,-90.370028,null,-76.106311,-82.53325,-95.888111,-85.582235,-83.994028,-94.3068111,-106.6091944,-70.060181,-86.75355,-118.358667,-118.151611,-70.615278,-122.220722,null,-116.506694,-121.929022,-121.590778,-82.554389,-68.828139,-81.4421944,-78.452861,-81.593189,-81.759556,-77.902569,-84.605889],&quot;y&quot;:[42.748267,61.174361,33.636719,30.194528,35.436194,41.938889,36.124472,42.364347,null,44.471861,42.940525,39.175361,45.777643,33.938833,32.898647,41.411689,35.214,39.997972,39.048836,39.902375,38.852083,39.861656,32.896828,41.533972,42.212444,39.642556,26.072583,42.880833,36.09775,34.895556,40.481181,21.318681,29.645419,38.944533,29.984433,39.717331,43.607333333,30.494056,36.080056,33.942536,39.297606,28.429394,41.785972,35.042417,42.932556,25.79325,42.947222,43.139858,44.881956,29.993389,38.509794,33.67975,35.393089,41.303167,41.978603,36.894611,26.683161,45.588722,39.871944,33.434278,40.491467,41.732581,43.646161,35.877639,37.505167,43.118866,26.536167,32.733556,29.533694,32.127583,41.708661,38.1740858,47.449,37.618972,null,40.788389,33.675667,38.748697,null,43.111187,27.975472,36.198389,44.741445,35.810972,36.2818694,35.0402222,41.253053,33.562942,34.200667,33.817722,41.391667,37.721278,null,33.829667,37.3626,38.695417,27.395444,44.807444,40.9160833,38.138639,38.373147,24.556111,34.270615,38.0365],&quot;text&quot;:[&quot;ALB&lt;br&gt;Albany Intl&lt;br&gt;439 Flights&quot;,&quot;ANC&lt;br&gt;Ted Stevens Anchorage Intl&lt;br&gt;8 Flights&quot;,&quot;ATL&lt;br&gt;Hartsfield Jackson Atlanta Intl&lt;br&gt;17,215 Flights&quot;,&quot;AUS&lt;br&gt;Austin Bergstrom Intl&lt;br&gt;2,439 Flights&quot;,&quot;AVL&lt;br&gt;Asheville Regional Airport&lt;br&gt;275 Flights&quot;,&quot;BDL&lt;br&gt;Bradley Intl&lt;br&gt;443 Flights&quot;,&quot;BNA&lt;br&gt;Nashville Intl&lt;br&gt;6,333 Flights&quot;,&quot;BOS&lt;br&gt;General Edward Lawrence Logan Intl&lt;br&gt;15,508 Flights&quot;,&quot;BQN&lt;br&gt;NA&lt;br&gt;896 Flights&quot;,&quot;BTV&lt;br&gt;Burlington Intl&lt;br&gt;2,589 Flights&quot;,&quot;BUF&lt;br&gt;Buffalo Niagara Intl&lt;br&gt;4,681 Flights&quot;,&quot;BWI&lt;br&gt;Baltimore Washington Intl&lt;br&gt;1,781 Flights&quot;,&quot;BZN&lt;br&gt;Gallatin Field&lt;br&gt;36 Flights&quot;,&quot;CAE&lt;br&gt;Columbia Metropolitan&lt;br&gt;116 Flights&quot;,&quot;CHS&lt;br&gt;Charleston Afb Intl&lt;br&gt;2,884 Flights&quot;,&quot;CLE&lt;br&gt;Cleveland Hopkins Intl&lt;br&gt;4,573 Flights&quot;,&quot;CLT&lt;br&gt;Charlotte Douglas Intl&lt;br&gt;14,064 Flights&quot;,&quot;CMH&lt;br&gt;Port Columbus Intl&lt;br&gt;3,524 Flights&quot;,&quot;CVG&lt;br&gt;Cincinnati Northern Kentucky Intl&lt;br&gt;3,941 Flights&quot;,&quot;DAY&lt;br&gt;James M Cox Dayton Intl&lt;br&gt;1,525 Flights&quot;,&quot;DCA&lt;br&gt;Ronald Reagan Washington Natl&lt;br&gt;9,705 Flights&quot;,&quot;DEN&lt;br&gt;Denver Intl&lt;br&gt;7,266 Flights&quot;,&quot;DFW&lt;br&gt;Dallas Fort Worth Intl&lt;br&gt;8,738 Flights&quot;,&quot;DSM&lt;br&gt;Des Moines Intl&lt;br&gt;569 Flights&quot;,&quot;DTW&lt;br&gt;Detroit Metro Wayne Co&lt;br&gt;9,384 Flights&quot;,&quot;EGE&lt;br&gt;Eagle Co Rgnl&lt;br&gt;213 Flights&quot;,&quot;FLL&lt;br&gt;Fort Lauderdale Hollywood Intl&lt;br&gt;12,055 Flights&quot;,&quot;GRR&lt;br&gt;Gerald R Ford Intl&lt;br&gt;765 Flights&quot;,&quot;GSO&lt;br&gt;Piedmont Triad&lt;br&gt;1,606 Flights&quot;,&quot;GSP&lt;br&gt;Greenville-Spartanburg International&lt;br&gt;849 Flights&quot;,&quot;HDN&lt;br&gt;Yampa Valley&lt;br&gt;15 Flights&quot;,&quot;HNL&lt;br&gt;Honolulu Intl&lt;br&gt;707 Flights&quot;,&quot;HOU&lt;br&gt;William P Hobby&lt;br&gt;2,115 Flights&quot;,&quot;IAD&lt;br&gt;Washington Dulles Intl&lt;br&gt;5,700 Flights&quot;,&quot;IAH&lt;br&gt;George Bush Intercontinental&lt;br&gt;7,198 Flights&quot;,&quot;IND&lt;br&gt;Indianapolis Intl&lt;br&gt;2,077 Flights&quot;,&quot;JAC&lt;br&gt;Jackson Hole Airport&lt;br&gt;25 Flights&quot;,&quot;JAX&lt;br&gt;Jacksonville Intl&lt;br&gt;2,720 Flights&quot;,&quot;LAS&lt;br&gt;Mc Carran Intl&lt;br&gt;5,997 Flights&quot;,&quot;LAX&lt;br&gt;Los Angeles Intl&lt;br&gt;16,174 Flights&quot;,&quot;MCI&lt;br&gt;Kansas City Intl&lt;br&gt;2,008 Flights&quot;,&quot;MCO&lt;br&gt;Orlando Intl&lt;br&gt;14,082 Flights&quot;,&quot;MDW&lt;br&gt;Chicago Midway Intl&lt;br&gt;4,113 Flights&quot;,&quot;MEM&lt;br&gt;Memphis Intl&lt;br&gt;1,789 Flights&quot;,&quot;MHT&lt;br&gt;Manchester Regional Airport&lt;br&gt;1,009 Flights&quot;,&quot;MIA&lt;br&gt;Miami Intl&lt;br&gt;11,728 Flights&quot;,&quot;MKE&lt;br&gt;General Mitchell Intl&lt;br&gt;2,802 Flights&quot;,&quot;MSN&lt;br&gt;Dane Co Rgnl Truax Fld&lt;br&gt;572 Flights&quot;,&quot;MSP&lt;br&gt;Minneapolis St Paul Intl&lt;br&gt;7,185 Flights&quot;,&quot;MSY&lt;br&gt;Louis Armstrong New Orleans Intl&lt;br&gt;3,799 Flights&quot;,&quot;MTJ&lt;br&gt;Montrose Regional Airport&lt;br&gt;15 Flights&quot;,&quot;MYR&lt;br&gt;Myrtle Beach Intl&lt;br&gt;59 Flights&quot;,&quot;OKC&lt;br&gt;Will Rogers World&lt;br&gt;346 Flights&quot;,&quot;OMA&lt;br&gt;Eppley Afld&lt;br&gt;849 Flights&quot;,&quot;ORD&lt;br&gt;Chicago Ohare Intl&lt;br&gt;17,283 Flights&quot;,&quot;ORF&lt;br&gt;Norfolk Intl&lt;br&gt;1,536 Flights&quot;,&quot;PBI&lt;br&gt;Palm Beach Intl&lt;br&gt;6,554 Flights&quot;,&quot;PDX&lt;br&gt;Portland Intl&lt;br&gt;1,354 Flights&quot;,&quot;PHL&lt;br&gt;Philadelphia Intl&lt;br&gt;1,632 Flights&quot;,&quot;PHX&lt;br&gt;Phoenix Sky Harbor Intl&lt;br&gt;4,656 Flights&quot;,&quot;PIT&lt;br&gt;Pittsburgh Intl&lt;br&gt;2,875 Flights&quot;,&quot;PVD&lt;br&gt;Theodore Francis Green State&lt;br&gt;376 Flights&quot;,&quot;PWM&lt;br&gt;Portland Intl Jetport&lt;br&gt;2,352 Flights&quot;,&quot;RDU&lt;br&gt;Raleigh Durham Intl&lt;br&gt;8,163 Flights&quot;,&quot;RIC&lt;br&gt;Richmond Intl&lt;br&gt;2,454 Flights&quot;,&quot;ROC&lt;br&gt;Greater Rochester Intl&lt;br&gt;2,416 Flights&quot;,&quot;RSW&lt;br&gt;Southwest Florida Intl&lt;br&gt;3,537 Flights&quot;,&quot;SAN&lt;br&gt;San Diego Intl&lt;br&gt;2,737 Flights&quot;,&quot;SAT&lt;br&gt;San Antonio Intl&lt;br&gt;686 Flights&quot;,&quot;SAV&lt;br&gt;Savannah Hilton Head Intl&lt;br&gt;804 Flights&quot;,&quot;SBN&lt;br&gt;South Bend Rgnl&lt;br&gt;10 Flights&quot;,&quot;SDF&lt;br&gt;Louisville International Airport&lt;br&gt;1,157 Flights&quot;,&quot;SEA&lt;br&gt;Seattle Tacoma Intl&lt;br&gt;3,923 Flights&quot;,&quot;SFO&lt;br&gt;San Francisco Intl&lt;br&gt;13,331 Flights&quot;,&quot;SJU&lt;br&gt;NA&lt;br&gt;5,819 Flights&quot;,&quot;SLC&lt;br&gt;Salt Lake City Intl&lt;br&gt;2,467 Flights&quot;,&quot;SNA&lt;br&gt;John Wayne Arpt Orange Co&lt;br&gt;825 Flights&quot;,&quot;STL&lt;br&gt;Lambert St Louis Intl&lt;br&gt;4,339 Flights&quot;,&quot;STT&lt;br&gt;NA&lt;br&gt;522 Flights&quot;,&quot;SYR&lt;br&gt;Syracuse Hancock Intl&lt;br&gt;1,761 Flights&quot;,&quot;TPA&lt;br&gt;Tampa Intl&lt;br&gt;7,466 Flights&quot;,&quot;TUL&lt;br&gt;Tulsa Intl&lt;br&gt;315 Flights&quot;,&quot;TVC&lt;br&gt;Cherry Capital Airport&lt;br&gt;101 Flights&quot;,&quot;TYS&lt;br&gt;Mc Ghee Tyson&lt;br&gt;631 Flights&quot;,&quot;XNA&lt;br&gt;NW Arkansas Regional&lt;br&gt;1,036 Flights&quot;,&quot;ABQ&lt;br&gt;Albuquerque International Sunport&lt;br&gt;254 Flights&quot;,&quot;ACK&lt;br&gt;Nantucket Mem&lt;br&gt;265 Flights&quot;,&quot;BHM&lt;br&gt;Birmingham Intl&lt;br&gt;297 Flights&quot;,&quot;BUR&lt;br&gt;Bob Hope&lt;br&gt;371 Flights&quot;,&quot;LGB&lt;br&gt;Long Beach&lt;br&gt;668 Flights&quot;,&quot;MVY&lt;br&gt;Martha\\\\'s Vineyard&lt;br&gt;221 Flights&quot;,&quot;OAK&lt;br&gt;Metropolitan Oakland Intl&lt;br&gt;312 Flights&quot;,&quot;PSE&lt;br&gt;NA&lt;br&gt;365 Flights&quot;,&quot;PSP&lt;br&gt;Palm Springs Intl&lt;br&gt;19 Flights&quot;,&quot;SJC&lt;br&gt;Norman Y Mineta San Jose Intl&lt;br&gt;329 Flights&quot;,&quot;SMF&lt;br&gt;Sacramento Intl&lt;br&gt;284 Flights&quot;,&quot;SRQ&lt;br&gt;Sarasota Bradenton Intl&lt;br&gt;1,211 Flights&quot;,&quot;BGR&lt;br&gt;Bangor Intl&lt;br&gt;375 Flights&quot;,&quot;CAK&lt;br&gt;Akron Canton Regional Airport&lt;br&gt;864 Flights&quot;,&quot;CHO&lt;br&gt;Charlottesville-Albemarle&lt;br&gt;52 Flights&quot;,&quot;CRW&lt;br&gt;Yeager&lt;br&gt;138 Flights&quot;,&quot;EYW&lt;br&gt;Key West Intl&lt;br&gt;17 Flights&quot;,&quot;ILM&lt;br&gt;Wilmington Intl&lt;br&gt;110 Flights&quot;,&quot;LEX&lt;br&gt;Blue Grass&lt;br&gt;1 Flights&quot;],&quot;key&quot;:null,&quot;type&quot;:&quot;scattergl&quot;,&quot;mode&quot;:&quot;markers&quot;,&quot;marker&quot;:{&quot;autocolorscale&quot;:false,&quot;color&quot;:&quot;rgba(26,26,26,1)&quot;,&quot;opacity&quot;:1,&quot;size&quot;:[3.77952755905512,3.77952755905512,6.67829287123416,5.82926416836526,5.82926416836526,3.77952755905512,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,3.77952755905512,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,5.82926416836526,5.82926416836526,3.77952755905512,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,5.82926416836526,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,3.77952755905512,5.82926416836526,3.77952755905512,5.82926416836526,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,6.67829287123416,5.82926416836526,6.67829287123416,3.77952755905512,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,6.67829287123416,5.82926416836526,5.82926416836526,5.82926416836526,5.82926416836526,6.67829287123416,5.82926416836526,5.82926416836526,5.82926416836526,5.82926416836526,3.77952755905512,6.67829287123416,5.82926416836526,6.67829287123416,6.67829287123416,3.77952755905512,5.82926416836526,5.82926416836526,5.82926416836526,3.77952755905512,3.77952755905512,5.82926416836526,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,5.82926416836526,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512,3.77952755905512],&quot;symbol&quot;:&quot;circle&quot;,&quot;line&quot;:{&quot;width&quot;:1.88976377952756,&quot;color&quot;:&quot;rgba(26,26,26,1)&quot;}},&quot;hoveron&quot;:&quot;points&quot;,&quot;name&quot;:&quot;Others&quot;,&quot;legendgroup&quot;:&quot;Others&quot;,&quot;showlegend&quot;:true,&quot;xaxis&quot;:&quot;x&quot;,&quot;yaxis&quot;:&quot;y&quot;,&quot;hoverinfo&quot;:&quot;text&quot;}],&quot;layout&quot;:{&quot;margin&quot;:{&quot;t&quot;:48.079701120797,&quot;r&quot;:7.97011207970112,&quot;b&quot;:16.9364881693649,&quot;l&quot;:11.9551681195517},&quot;plot_bgcolor&quot;:&quot;rgba(255,255,255,1)&quot;,&quot;paper_bgcolor&quot;:&quot;rgba(255,255,255,1)&quot;,&quot;font&quot;:{&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;,&quot;family&quot;:&quot;&quot;,&quot;size&quot;:15.9402241594022},&quot;title&quot;:&quot;Locations of U.S. Flights Outbound from NYC in 2013&quot;,&quot;titlefont&quot;:{&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;,&quot;family&quot;:&quot;Source Sans Pro&quot;,&quot;size&quot;:19.1282689912827},&quot;xaxis&quot;:{&quot;domain&quot;:[0,1],&quot;type&quot;:&quot;linear&quot;,&quot;autorange&quot;:false,&quot;tickmode&quot;:&quot;array&quot;,&quot;range&quot;:[-162.37714245,-64.37342455],&quot;ticktext&quot;:[&quot;-160&quot;,&quot;-140&quot;,&quot;-120&quot;,&quot;-100&quot;,&quot;-80&quot;],&quot;tickvals&quot;:[-160,-140,-120,-100,-80],&quot;ticks&quot;:&quot;&quot;,&quot;tickcolor&quot;:null,&quot;ticklen&quot;:3.98505603985056,&quot;tickwidth&quot;:0,&quot;showticklabels&quot;:false,&quot;tickfont&quot;:{&quot;color&quot;:null,&quot;family&quot;:null,&quot;size&quot;:0},&quot;tickangle&quot;:-0,&quot;showline&quot;:false,&quot;linecolor&quot;:null,&quot;linewidth&quot;:0,&quot;showgrid&quot;:false,&quot;gridcolor&quot;:null,&quot;gridwidth&quot;:0,&quot;zeroline&quot;:false,&quot;anchor&quot;:&quot;y&quot;,&quot;title&quot;:&quot;&quot;,&quot;titlefont&quot;:{&quot;color&quot;:null,&quot;family&quot;:null,&quot;size&quot;:0},&quot;hoverformat&quot;:&quot;.2f&quot;},&quot;yaxis&quot;:{&quot;domain&quot;:[0,1],&quot;type&quot;:&quot;linear&quot;,&quot;autorange&quot;:false,&quot;tickmode&quot;:&quot;array&quot;,&quot;range&quot;:[19.325897,63.167145],&quot;ticktext&quot;:[&quot;20&quot;,&quot;30&quot;,&quot;40&quot;,&quot;50&quot;,&quot;60&quot;],&quot;tickvals&quot;:[20,30,40,50,60],&quot;ticks&quot;:&quot;&quot;,&quot;tickcolor&quot;:null,&quot;ticklen&quot;:3.98505603985056,&quot;tickwidth&quot;:0,&quot;showticklabels&quot;:false,&quot;tickfont&quot;:{&quot;color&quot;:null,&quot;family&quot;:null,&quot;size&quot;:0},&quot;tickangle&quot;:-0,&quot;showline&quot;:false,&quot;linecolor&quot;:null,&quot;linewidth&quot;:0,&quot;showgrid&quot;:false,&quot;gridcolor&quot;:null,&quot;gridwidth&quot;:0,&quot;zeroline&quot;:false,&quot;anchor&quot;:&quot;x&quot;,&quot;title&quot;:&quot;&quot;,&quot;titlefont&quot;:{&quot;color&quot;:null,&quot;family&quot;:null,&quot;size&quot;:0},&quot;hoverformat&quot;:&quot;.2f&quot;},&quot;shapes&quot;:[{&quot;type&quot;:&quot;rect&quot;,&quot;fillcolor&quot;:null,&quot;line&quot;:{&quot;color&quot;:null,&quot;width&quot;:0,&quot;linetype&quot;:[]},&quot;yref&quot;:&quot;paper&quot;,&quot;xref&quot;:&quot;paper&quot;,&quot;x0&quot;:0,&quot;x1&quot;:1,&quot;y0&quot;:0,&quot;y1&quot;:1}],&quot;showlegend&quot;:true,&quot;legend&quot;:{&quot;bgcolor&quot;:&quot;rgba(255,255,255,1)&quot;,&quot;bordercolor&quot;:&quot;transparent&quot;,&quot;borderwidth&quot;:1.88976377952756,&quot;font&quot;:{&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;,&quot;family&quot;:&quot;Source Sans Pro&quot;,&quot;size&quot;:12.7521793275218},&quot;y&quot;:0.91496062992126},&quot;annotations&quot;:[{&quot;text&quot;:&quot;Airports&quot;,&quot;x&quot;:1.02,&quot;y&quot;:1,&quot;showarrow&quot;:false,&quot;ax&quot;:0,&quot;ay&quot;:0,&quot;font&quot;:{&quot;color&quot;:&quot;rgba(0,0,0,1)&quot;,&quot;family&quot;:&quot;Source Sans Pro&quot;,&quot;size&quot;:15.9402241594022},&quot;xref&quot;:&quot;paper&quot;,&quot;yref&quot;:&quot;paper&quot;,&quot;textangle&quot;:-0,&quot;xanchor&quot;:&quot;left&quot;,&quot;yanchor&quot;:&quot;bottom&quot;,&quot;legendTitle&quot;:true}],&quot;hovermode&quot;:&quot;closest&quot;,&quot;height&quot;:400},&quot;source&quot;:&quot;A&quot;,&quot;config&quot;:{&quot;modeBarButtonsToAdd&quot;:[{&quot;name&quot;:&quot;Collaborate&quot;,&quot;icon&quot;:{&quot;width&quot;:1000,&quot;ascent&quot;:500,&quot;descent&quot;:-50,&quot;path&quot;:&quot;M487 375c7-10 9-23 5-36l-79-259c-3-12-11-23-22-31-11-8-22-12-35-12l-263 0c-15 0-29 5-43 15-13 10-23 23-28 37-5 13-5 25-1 37 0 0 0 3 1 7 1 5 1 8 1 11 0 2 0 4-1 6 0 3-1 5-1 6 1 2 2 4 3 6 1 2 2 4 4 6 2 3 4 5 5 7 5 7 9 16 13 26 4 10 7 19 9 26 0 2 0 5 0 9-1 4-1 6 0 8 0 2 2 5 4 8 3 3 5 5 5 7 4 6 8 15 12 26 4 11 7 19 7 26 1 1 0 4 0 9-1 4-1 7 0 8 1 2 3 5 6 8 4 4 6 6 6 7 4 5 8 13 13 24 4 11 7 20 7 28 1 1 0 4 0 7-1 3-1 6-1 7 0 2 1 4 3 6 1 1 3 4 5 6 2 3 3 5 5 6 1 2 3 5 4 9 2 3 3 7 5 10 1 3 2 6 4 10 2 4 4 7 6 9 2 3 4 5 7 7 3 2 7 3 11 3 3 0 8 0 13-1l0-1c7 2 12 2 14 2l218 0c14 0 25-5 32-16 8-10 10-23 6-37l-79-259c-7-22-13-37-20-43-7-7-19-10-37-10l-248 0c-5 0-9-2-11-5-2-3-2-7 0-12 4-13 18-20 41-20l264 0c5 0 10 2 16 5 5 3 8 6 10 11l85 282c2 5 2 10 2 17 7-3 13-7 17-13z m-304 0c-1-3-1-5 0-7 1-1 3-2 6-2l174 0c2 0 4 1 7 2 2 2 4 4 5 7l6 18c0 3 0 5-1 7-1 1-3 2-6 2l-173 0c-3 0-5-1-8-2-2-2-4-4-4-7z m-24-73c-1-3-1-5 0-7 2-2 3-2 6-2l174 0c2 0 5 0 7 2 3 2 4 4 5 7l6 18c1 2 0 5-1 6-1 2-3 3-5 3l-174 0c-3 0-5-1-7-3-3-1-4-4-5-6z&quot;},&quot;click&quot;:&quot;function(gd) { \n        // is this being viewed in RStudio?\n        if (location.search == '?viewer_pane=1') {\n          alert('To learn about plotly for collaboration, visit:\\n https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html');\n        } else {\n          window.open('https://cpsievert.github.io/plotly_book/plot-ly-for-collaboration.html', '_blank');\n        }\n      }&quot;}],&quot;modeBarButtonsToRemove&quot;:[&quot;sendDataToCloud&quot;]},&quot;.plotlyWebGl&quot;:true,&quot;base_url&quot;:&quot;https://plot.ly&quot;},&quot;evals&quot;:[&quot;config.modeBarButtonsToAdd.0.click&quot;],&quot;jsHooks&quot;:[]}&lt;/script&gt;

&lt;script type=&quot;application/htmlwidget-sizing&quot; data-for=&quot;htmlwidget-ae87c24ac18b3ac8a6fa&quot;&gt;{&quot;viewer&quot;:{&quot;width&quot;:&quot;100%&quot;,&quot;height&quot;:400,&quot;padding&quot;:0,&quot;fill&quot;:false},&quot;browser&quot;:{&quot;width&quot;:&quot;100%&quot;,&quot;height&quot;:400,&quot;padding&quot;:0,&quot;fill&quot;:false}}&lt;/script&gt;

&lt;p&gt;This is an instance where Plotly&amp;rsquo;s native zooming and filtering are very helpful! For example, if you filter solely on flights from LGA/LaGuardia, you will see that the airport never shuttles flights to the western United States.&lt;/p&gt;

&lt;p&gt;However, there are no obvious trends outside of that observation. The 1-degree airports and the 2-degree airports are scattered around the country with no apparent pattern. Oh well.&lt;/p&gt;

&lt;p&gt;I should mention that since there is a relatively low amount of data, these examples do not benefit as much from rendering with WebGL than with Plotly&amp;rsquo;s native d3/SVG. And even then, there are still further optimizations that can be done; after finishing the code write up, I discovered &lt;a href=&quot;https://github.com/thomasp85/ggraph&quot;&gt;ggraph&lt;/a&gt;, which is more actively developed than ggnetwork, although ggraph does not interact as well with Plotly.&lt;/p&gt;

&lt;p&gt;This creation workflow is pragmatic enough that I can included these interactive network graphs in more blog posts. At the least, this approach is a good proof-of-concept for some &lt;em&gt;very crazy&lt;/em&gt; data visualizations I have planned.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view all the R and ggplot2 code used to visualize the data in &lt;a href=&quot;http://minimaxir.com/notebooks/interactive-network/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&quot;https://github.com/minimaxir/interactive-network&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 05 Dec 2016 06:30:00 -0800</pubDate>
        <link>http://minimaxir.com/2016/12/interactive-network/</link>
        <guid isPermaLink="true">http://minimaxir.com/2016/12/interactive-network/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
        <category>Interactive</category>
        
      </item>
    
      <item>
        <title>What Percent of the Top-Voted Comments in Reddit Threads Were Also 1st Comment?</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.reddit.com&quot;&gt;Reddit&lt;/a&gt; threads can be a crowded place. In popular subreddits such as &lt;a href=&quot;https://www.reddit.com/r/AskReddit/&quot;&gt;/r/AskReddit&lt;/a&gt; and &lt;a href=&quot;https://www.reddit.com/r/pics/&quot;&gt;/r/pics&lt;/a&gt;, Reddit submissions can receive hundreds, even &lt;em&gt;thousands&lt;/em&gt; of unique comments. Some comments inevitably become lost in the noise. Reddit&amp;rsquo;s &lt;a href=&quot;https://redditblog.com/2009/10/15/reddits-new-comment-sorting-system/&quot;&gt;ranking algorithm&lt;/a&gt; attempts to rectify this by determining comment ranking using both time and community voting; comments in a thread, by default, are ordered based on the &lt;strong&gt;points score&lt;/strong&gt; (upvotes - downvotes) the comment receives, subject to a rank decay based on the age of the comment.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/reddit_askreddit.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In theory, this system should allow comments that posted later in the thread&amp;rsquo;s lifetime to rank much higher temporarily, then Redditors can vote on the new comment; if the new comment is good, it can now rise to the top and therefore the content which would otherwise be buried is now surfaced. Anecdotally, that doesn&amp;rsquo;t be the case with Reddit&amp;rsquo;s modern algorithm; comments made late in the thread appear at the bottom, where they likely will not receive any upvotes (this led to a minor &amp;ldquo;&lt;a href=&quot;https://www.google.com/#q=site:reddit.com+%22late+to+this+thread%22&quot;&gt;I know I&amp;rsquo;m late to this thread but&amp;hellip;&lt;/a&gt;&amp;rdquo; meme).&lt;/p&gt;

&lt;p&gt;I, of course, am not satisfied with anecdotes. A month ago, a Redditor asked &amp;ldquo;&lt;a href=&quot;https://www.reddit.com/r/TheoryOfReddit/comments/53d5ep/what_percentage_of_the_top_comment_in_threads/&quot;&gt;What percentage of the top comment in threads were also the first comment?&lt;/a&gt;&amp;rdquo; Why not calculate it &lt;em&gt;exactly&lt;/em&gt; using big data?&lt;/p&gt;

&lt;h2&gt;Getting the Reddit Data&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;You can view all the &lt;a href=&quot;https://www.r-project.org&quot;&gt;R&lt;/a&gt; and &lt;a href=&quot;http://ggplot2.org&quot;&gt;ggplot2&lt;/a&gt; code used to query, analyze, and visualize the Reddit data in &lt;a href=&quot;http://minimaxir.com/notebooks/first-comment/&quot;&gt;this R Notebook&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In order to process a great amount of Reddit data, I turned to &lt;a href=&quot;https://cloud.google.com/bigquery/&quot;&gt;BigQuery&lt;/a&gt;, which now has data for &lt;a href=&quot;https://www.reddit.com/r/datasets/comments/590re2/updated_reddit_comments_and_posts_updated_on/&quot;&gt;all Reddit comments&lt;/a&gt; until September 2016.&lt;/p&gt;

&lt;p&gt;For this analysis, I will only look at the &lt;strong&gt;top-level comments&lt;/strong&gt; (i.e. comments which are not replies to other comments), since those are the ones most affected by the ordering and submission of new comments. Additionally I will only look at comments within Reddit threads with &lt;strong&gt;atleast 30 top-level comments&lt;/strong&gt; to ensure I only look at threads with sufficient discussion and where late posts are more likely to become hidden. It also mirrors the &amp;ldquo;late to this thread&amp;rdquo; meme: can posts be &lt;em&gt;too&lt;/em&gt; late?&lt;/p&gt;

&lt;p&gt;The queried data will be all comments posted from January 2015 to September 2016: this give a good balance of sample size and foundation around the modern comment ranking algorithms. The total number of Reddit comments analyzed, after filtering on threads with sufficient conversation and limiting the scope to the first 100 comments of a thread scoring within the Top 100, is &lt;strong&gt;n = 86,561,476&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;With clever use of BigQuery window functions, I obtained the aggregate data, counting the number of comments from the filtered Reddit threads at each voting rank and created rank.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/data.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Visualizing the Discussion&lt;/h2&gt;

&lt;p&gt;Filtering on the top-voted comments (&lt;code&gt;score_rank = 1&lt;/code&gt;) only, &lt;em&gt;what percent of the top-voted comments in Reddit threads were also 1st Comment?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/reddit-first-4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The answer is &lt;strong&gt;17.24%&lt;/strong&gt; of all top-voted comments! That&amp;rsquo;s certainly more than what I expected! Additionally, 56% of the top-voted comments were posted within the first 5 comments, and 77% within the first 10 comments. The chart follows a &lt;a href=&quot;https://en.wikipedia.org/wiki/Power_law&quot;&gt;power-law distribution&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s invert it: filtering on only the first comments (&lt;code&gt;created_rank = 1&lt;/code&gt;) made in comment threads, &lt;em&gt;what percentage of the 1st Comments in Reddit threads were also the top-voted comment?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/reddit-first-3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;By construction, the answer is the same as before (17.24%), however the followup proportions are slightly different, with the first comment ranking within the Top 5 comments 46% of the time, and within the Top 10 comments 62% of the time.&lt;/p&gt;

&lt;p&gt;It may be worth it to visualize both dimensions at the same time using a heatmap, with the created rank on one axis, score rank on the other, and a z-axis representing the number of comments at each rank pairing. We can also add a faint contour line to help visualize clusters of the data. Putting it together:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/reddit-first-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Woah, most of the values are constrained between the semisquare constrained by the first 5 comments and the top 5 comments! But it&amp;rsquo;s harder to see trends, so let&amp;rsquo;s try applying a logarithmic base-10 scaling on the comment count:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/reddit-first-2a.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Much better! We can see a grouping of the 5x5 semisquare, but also smaller groupings of a 30x30 shape (this may possibly be due to the 30 comment filter threshold), a faint 60x60 shape, and &lt;em&gt;voids&lt;/em&gt; in the upper-left and lower-right corners.&lt;/p&gt;

&lt;p&gt;From the 2D heatmap, there appears to be a &lt;strong&gt;positive correlation&lt;/strong&gt; between the rank of the comment and the time it was submitted. Ideally, if Reddit&amp;rsquo;s algorithm correctly cycled posts so that each comment gets a fair chance at going viral, then there should be &lt;strong&gt;no correlation&lt;/strong&gt; between score rank and time posted.&lt;/p&gt;

&lt;h2&gt;Analysis by Subreddit&lt;/h2&gt;

&lt;p&gt;When working with Reddit data, it is always important to facet the analysis by subreddit, as subreddits can have idiosyncratic behaviors which deviate from general Reddit behavior. As noted in the original Reddit thread with the initial question, it is possible that the percentage of first comments becoming top comment is &amp;ldquo;higher in lighter subs (funny, pics, videos) than more serious subs (askscience, history, etc).&amp;rdquo;&lt;/p&gt;

&lt;p&gt;I tweaked the BigQuery above to retrieve the same data for each of the Top 100 subreddits (determined by unique commenter count over the same time period). Afterward, via scripting, I created a 1D proportion-of-first-comments-by-score-rank and 2D heatmaps for each subreddit. You can view and download the 1D charts &lt;a href=&quot;https://github.com/minimaxir/first-comment/tree/master/img-1d&quot;&gt;here&lt;/a&gt;, and the 2D heatmaps &lt;a href=&quot;https://github.com/minimaxir/first-comment/tree/master/img-2d&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For example, here&amp;rsquo;s the chart of first-comment-rankings for &lt;a href=&quot;https://www.reddit.com/r/IAmA/&quot;&gt;/r/IAmA&lt;/a&gt;, one of Reddit&amp;rsquo;s biggest subreddits where normal Redditors can ask celebrities any question they want.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/IAmA-1d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Unlike the all-Reddit chart, the distribution of first-comment proportions is more uniform instead of following a power law. It makes sense in theory; people would likely upvote top-level questions which the original poster replied to, so there should be less of a bias toward the first top-level comment.&lt;/p&gt;

&lt;p&gt;What does the 2D heatmap show?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/IAmA-2d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Damn it.&lt;/p&gt;

&lt;p&gt;While the 1D behavior is different, the overall 2D behavior is the same albeit with larger voids (indeed, in the heatmap, you can see at &lt;code&gt;created_rank = 1&lt;/code&gt;, the vertical strip doesn&amp;rsquo;t fit the pattern).&lt;/p&gt;

&lt;p&gt;It turns out that most /r/IAmA threads have this comment:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/automoderator.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As it&amp;rsquo;s made by a robot, it&amp;rsquo;s always the first comment, and it gets ignored/downvoted in normal circumstances. Other subreddits with the same pattern of 1D irregularities, 2D regularities, and AutoModerator usage are &lt;a href=&quot;https://www.reddit.com/r/gameofthrones/&quot;&gt;/r/gameofthrones&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/photoshopbattles/&quot;&gt;/r/photoshopbattles&lt;/a&gt;, and &lt;a href=&quot;https://www.reddit.com/r/WritingPrompts/&quot;&gt;/r/WritingPrompts&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Some subreddits have more uniformity than typical Reddit rank behavior. In &lt;a href=&quot;https://www.reddit.com/r/funny/&quot;&gt;/r/funny&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/leagueoflegends/&quot;&gt;/r/leagueoflegends&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/pics/&quot;&gt;/r/pics&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/todayilearned/&quot;&gt;/r/todayilearned&lt;/a&gt;, and &lt;a href=&quot;https://www.reddit.com/r/video/&quot;&gt;/r/videos&lt;/a&gt; (i.e. many default subreddits), there is no upper-left void (early comments can be poorly ranked) and the bottom-right void is minimized but still present.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/funny-2d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/leagueoflegends-2d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Inversely, there are subreddits where the correlation is obvious. &lt;a href=&quot;https://www.reddit.com/r/pcmasterrace/&quot;&gt;/r/pcmasterrace&lt;/a&gt; and /r/gonewild both exhibit very straight lines, and are subreddits where the comments themselves are not very constructive, so whatever gets posted gets upvoted anyways.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/pcmasterrace-2d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/first-comment/gonewild-2d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Rushing to say &lt;strong&gt;FIRST!!1!11!&lt;/strong&gt; in a comments section of a blog post or forum thread is a meme that long predates Reddit. However, rushing to make the first comment in a Reddit thread may have strategic merit if you want to get your voice heard.&lt;/p&gt;

&lt;p&gt;Even in the most optimistic circumstances, comments that are late to a thread have a very, very low probability of becoming one of the top comments. In fairness, it&amp;rsquo;s hard to determine with public Reddit data if tweaking the ranking algorithm such that new comments will always rank at the top initially will actually improve the Reddit user experience as a whole. On the other hand, this behavior presents an opportunity: if there is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Long_tail&quot;&gt;long tail&lt;/a&gt; of Reddit content that is unjustifiably being buried due to lack of attention, then perhaps there is a &lt;em&gt;business opportunity&lt;/em&gt; in creating a service to discover and resurface quality comments&amp;hellip;&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view all the &lt;a href=&quot;https://www.r-project.org&quot;&gt;R&lt;/a&gt; and &lt;a href=&quot;http://ggplot2.org&quot;&gt;ggplot2&lt;/a&gt; code used to query, analyze, and visualize the Reddit data in &lt;a href=&quot;http://minimaxir.com/notebooks/first-comment/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&quot;https://github.com/minimaxir/first-comment&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Nov 2016 06:30:00 -0800</pubDate>
        <link>http://minimaxir.com/2016/11/first-comment/</link>
        <guid isPermaLink="true">http://minimaxir.com/2016/11/first-comment/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Visualizing Clusters of Clickbait Headlines Using Spark, Word2vec, and Plotly</title>
        <description>&lt;p&gt;Facebook &lt;a href=&quot;http://newsroom.fb.com/news/2016/08/news-feed-fyi-further-reducing-clickbait-in-feed/&quot;&gt;recently announced&lt;/a&gt; that they will punish Facebook Posts which link to articles using clickbait headlines by limiting their exposure on the News Feed. They also announced that they have a large team manually classifying what is and isn’t linkbait. From &lt;a href=&quot;http://minimaxir.com/2015/01/linkbait/&quot;&gt;my analysis of BuzzFeed headlines&lt;/a&gt; last year, I found that clickbait typically follows very specific tropes with phrases such as &amp;ldquo;The [X] Most&amp;rdquo; or &amp;ldquo;You Should Do.&amp;rdquo; It shouldn&amp;rsquo;t be &lt;em&gt;that&lt;/em&gt; difficult to identify clickbait using heuristics/machine learning.&lt;/p&gt;

&lt;p&gt;Relatedly, I recently read &lt;a href=&quot;http://blog.yhat.com/posts/words2map.html&quot;&gt;a blog post&lt;/a&gt; by Lance Legel describing &lt;a href=&quot;https://github.com/overlap-ai/words2map&quot;&gt;words2map&lt;/a&gt;, a project which takes in keywords and converts Google News articles representing those keywords into numerical vector representations, clusters them together in 2D, and plots those on a chart.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/words2map-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Why not combine the two ideas? Let&amp;rsquo;s deconstruct thousands of news headlines into numeric representations and cluster them together to see if we can isolate submissions which intrinsincly  hit those clickbait tropes.&lt;/p&gt;

&lt;h2&gt;5 Big Data Processing Techniques You Should Know&lt;/h2&gt;

&lt;p&gt;Using a modified version of my &lt;a href=&quot;https://github.com/minimaxir/facebook-page-post-scraper&quot;&gt;Facebook Page Post Scraper&lt;/a&gt;, I downloaded &lt;em&gt;all&lt;/em&gt; Facebook Posts by the Facebook Pages representing news publications &lt;a href=&quot;https://www.facebook.com/cnn&quot;&gt;CNN&lt;/a&gt;, &lt;a href=&quot;https://www.facebook.com/nytimes&quot;&gt;NYTimes&lt;/a&gt;, &lt;a href=&quot;https://www.facebook.com/BuzzFeed/&quot;&gt;BuzzFeed&lt;/a&gt;, and &lt;a href=&quot;https://www.facebook.com/Upworthy/&quot;&gt;Upworthy&lt;/a&gt;, and stored the headlines of each linked article if present. &lt;a href=&quot;http://www.cnn.com/&quot;&gt;CNN&lt;/a&gt; and &lt;a href=&quot;http://www.nytimes.com/&quot;&gt;NYTimes&lt;/a&gt; represent traditional media whose headlines tend to follow &lt;a href=&quot;https://owl.english.purdue.edu/owl/resource/735/02/&quot;&gt;AP Style guidelines&lt;/a&gt;, while &lt;a href=&quot;https://www.buzzfeed.com/&quot;&gt;BuzzFeed&lt;/a&gt; and &lt;a href=&quot;https://www.upworthy.com/&quot;&gt;Upworthy&lt;/a&gt; are more known for their clickbait headlines. &lt;/p&gt;

&lt;p&gt;However, those are not absolute rules; BuzzFeed occasionally has more-serious headlines, and CNN occasionally has more-gimmicky headlines. &lt;strong&gt;That&amp;rsquo;s okay.&lt;/strong&gt; If my hypothesis is correct, the nonappropriate headlines will be clustered with other headlines of the same style.&lt;/p&gt;

&lt;p&gt;First, I load the four datasets into the hip new big data tool &lt;a href=&quot;https://spark.apache.org&quot;&gt;Apache Spark&lt;/a&gt; 2.0, (via the Python interface, &lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/&quot;&gt;PySpark&lt;/a&gt;), and combine them all into a single DataFrame, with a little extra post-processing to remove invalid entries.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-Python&quot; data-lang=&quot;Python&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_cnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;fb_headlines/CNN_fb.tsv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_nytimes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;fb_headlines/NYTimes_fb.tsv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_buzzfeed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;fb_headlines/BuzzFeed_fb.tsv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_upworthy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;fb_headlines/Upworthy_fb.tsv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_cnn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;union&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_nytimes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;union&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_buzzfeed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;union&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_upworthy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;process_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/cc-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In all, I had 102,267 valid news headlines to analyze; not &amp;ldquo;big data,&amp;rdquo; but enough data that it&amp;rsquo;s worth optimizing the analysis code as much as possible, especially in this case where the computation can be intensive.&lt;/p&gt;

&lt;p&gt;Once the data is loaded, we convert the headlines to an array of tokens representing each word from the headline, all lowercase and with punctuation stripped. This task can normally be difficult and have poor performance on large datasets, however Spark has a RegexTokenizer that quickly executes all the necessary tasks in one fell swoop.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-Python&quot; data-lang=&quot;Python&quot;&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RegexTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;[^\w]&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;words&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/cc-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Most analyses would remove &lt;a href=&quot;https://en.wikipedia.org/wiki/Stop_words&quot;&gt;stop words&lt;/a&gt; as their high frequency can cause noise in the subsequent analysis. In this case, we should &lt;em&gt;not&lt;/em&gt; remove them as many stop words  are critical components of the clickbait tropes (e.g. &amp;ldquo;I Am&amp;rdquo; and &amp;ldquo;The [X] Most&amp;rdquo;).&lt;/p&gt;

&lt;p&gt;Now that the tokens are created, we can apply &lt;a href=&quot;https://en.wikipedia.org/wiki/Word2vec&quot;&gt;Word2vec&lt;/a&gt;, an algorithm which converts a collection of words into a dictionary of multidimensional numerical representations. Once the dictionary is created, we can average all the word vectors for a given headline to get the numeric representation of the headline itself. Again, Spark has convenient functions for those actions, setting a randomness seed for reproducibility:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-Python&quot; data-lang=&quot;Python&quot;&gt;&lt;span class=&quot;n&quot;&gt;word2Vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vectorSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;words&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;vectors&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word2Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/cc-3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In this case, each word and phrase are converted into a 50-dimension vector for speed later; usually, the word vectors from Word2vec are between 100 and 1,000 dimensions.&lt;/p&gt;

&lt;p&gt;Another step to add context to the data is to add features representing the page that posted the status. This takes two steps in Spark; first, use a StringIndexer to covert the names of the four Facebook Pages into numerical 0-indexed representations, then use a &lt;a href=&quot;https://en.wikipedia.org/wiki/One-hot&quot;&gt;OneHotEncoder&lt;/a&gt; to convert the data into &lt;a href=&quot;https://en.wikipedia.org/wiki/Dummy_variable_(statistics)&quot;&gt;dummy variables&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-Python&quot; data-lang=&quot;Python&quot;&gt;&lt;span class=&quot;n&quot;&gt;stringIndexer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StringIndexer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;page_id&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;indexed&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stringIndexer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OneHotEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;indexed&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;page_ohe&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/cc-5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;This adds 3 columns, where the column containing the 1.0 represents the corresponding page. (the 4th page is represented by none of the 3 columns containing 1.0)&lt;/p&gt;

&lt;p&gt;Lastly, combine the 3D page numeric vectors and the 50D word numeric vectors with a VectorAssembler:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-Python&quot; data-lang=&quot;Python&quot;&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VectorAssembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputCols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;page_ohe&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;vectors&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputCol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;merged_vectors&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/cc-7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s it! And these code blocks could be combined into a &lt;a href=&quot;http://spark.apache.org/docs/latest/ml-pipeline.html&quot;&gt;Spark Pipeline&lt;/a&gt; and be used on datasets hundreds or thousands times as large with just &lt;em&gt;two lines of code&lt;/em&gt;, something which will help me make interesting blog posts in the future.&lt;/p&gt;

&lt;h2&gt;This Chart Literally Just Totes Made Me Can&amp;rsquo;t Even&lt;/h2&gt;

&lt;p&gt;To keep comparisons between news sources apples-to-apples with respect to current events (and there have been a &lt;em&gt;lot&lt;/em&gt; of events in the past couple months!), we will only look at headlines from &lt;strong&gt;June 1st, 2016 to August 12&lt;/strong&gt; among the four pages; 9,500 headlines total. That&amp;rsquo;s a fair maximum sample size, both because all the points need to be loaded onto this webpage, and because the clustering algorithm is slow.&lt;/p&gt;

&lt;p&gt;Speaking of clustering, I load the 53D vectors created above for this subset into &lt;a href=&quot;https://www.r-project.org/about.html&quot;&gt;R&lt;/a&gt; and apply the &lt;a href=&quot;https://lvdmaaten.github.io/tsne/&quot;&gt;t-SNE&lt;/a&gt; algorithm to project and cluster each point into 2 dimensions. (since the algorithm performance scales quadratically with sample size and is single-threaded, calculating the projected points took &lt;em&gt;over 8 hours&lt;/em&gt;!)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-R&quot; data-lang=&quot;R&quot;&gt;cluster_coords &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; tsne&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; initial_dims&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; perplexity&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; epoch&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/cc-6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Prototyping the plot extremely quickly in &lt;a href=&quot;http://docs.ggplot2.org/current/&quot;&gt;ggplot2&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-R&quot; data-lang=&quot;R&quot;&gt;ggplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;df_plot&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; aes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; y&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;y&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; color&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;page_id&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
    geom_point&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;alpha&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; stroke&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
    theme_bw&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/fb-headlines-cluster-test-53D.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Gives us a map close to what we want. Hooray, my crazy clustering idea was not completely crazy!&lt;/p&gt;

&lt;p&gt;However, for this visualization, it is extremely important to be able to determine which point corresponds to which headline. A static image opens up further questions on what causes points to be spatially located where. Therefore, I plot the chart interactively using &lt;a href=&quot;https://plot.ly/&quot;&gt;Plotly&lt;/a&gt;, specifically with its &lt;a href=&quot;https://plot.ly/r/webgl-vs-svg/&quot;&gt;WebGL&lt;/a&gt; interface, as rendering 9,500 points in the browser with the typical &lt;a href=&quot;https://d3js.org/&quot;&gt;d3&lt;/a&gt;/SVG without hitting massive slowdown is difficult. The speed of WebGL also allows users to scan the headlines rapidly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/clickbait-cluster/cnn-clickbait.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As you&amp;rsquo;ve seen from the visualizations above, all four Facebook pages have their own clusters, thanks to the added identifier feature. The left side of the 2D representation represents the more serious headlines, while the right side represents the more silly headlines. There is a little overlap between the NYTimes/CNN/BuzzFeed articles; notably, the NYTimes/CNN articles close to the BuzzFeed cluster tend to be more linkbaity, as shown in the image above. Upworthy is in its own little bubble with little similarity to the other news publications (the Upworthy headlines are much more verbose, which is likely causing more entropy and dissimilarity with the other, more concise headlines).&lt;/p&gt;

&lt;p&gt;Something particularly interesting is the formation of natural subclusters outside of the main clusters. These clusters are based around keywords in the headlines, which is significant since the input data is a linear combination of that keyword and many other words, without using explicit word-importance statistical tools such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&quot;&gt;tf-idf&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;top clusters&lt;/strong&gt; are based around pop-culture keywords: Taylor Swift, Harry Potter/J.K. Rowling, Pokémon Go, and Game of Thrones.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;bottom clusters&lt;/strong&gt; are based around political keywords, including Bernie Sanders, Hillary Clinton, Donald Trump, and the U.S. itself.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;cluster between BuzzFeed and Upworthy&lt;/strong&gt; contains headlines with the &amp;ldquo;[X]-year-old&amp;rdquo; trope from all pages.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you may have noticed playing around with the interactive chart, this methodology is not perfect. Some linkbait headlines are present in the center of CNN/NYTimes clusters, and some serious headlines are present in the center of the BuzzFeed cluster. The more academic method of identifying clickbait in an unsupervised manner using machine learning would be to incorporate other inherent attributes of words and phrases, such as using &lt;a href=&quot;https://en.wikipedia.org/wiki/Bigram&quot;&gt;bigrams&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Part-of-speech_tagging&quot;&gt;part-of-speech tagging&lt;/a&gt;, bag-of-words/tf-idf, and &lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;character-level language models&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Coincidentally around the same time Facebook announced their anticlickbait initiative, Facebook open-sourced their &lt;a href=&quot;https://github.com/facebookresearch/fastText&quot;&gt;fasttext&lt;/a&gt; project, which can quickly build models to classify text using some of the above example techniques. &lt;strong&gt;Hmmmmmm&amp;hellip;&lt;/strong&gt;&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;The full code used to process the Facebook Page data using Spark is available in &lt;a href=&quot;https://github.com/minimaxir/clickbait-cluster/blob/master/fb_news_53D_spark.ipynb&quot;&gt;this Jupyter notebook&lt;/a&gt;, and the code used to generate the Plotly visualizations in R is available in &lt;a href=&quot;https://github.com/minimaxir/clickbait-cluster/blob/master/fb_news_53D_plotly.ipynb&quot;&gt;this Jupyter notebook&lt;/a&gt;, both open-sourced &lt;a href=&quot;https://github.com/minimaxir/clickbait-cluster&quot;&gt;on GitHub&lt;/a&gt;.  In the GitHub repository, you can download a standalone, offline version of the interactive WebGL chart.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 06:30:00 -0700</pubDate>
        <link>http://minimaxir.com/2016/08/clickbait-cluster/</link>
        <guid isPermaLink="true">http://minimaxir.com/2016/08/clickbait-cluster/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
        <category>Interactive</category>
        
      </item>
    
      <item>
        <title>Interactive 3D Clusters of all 721 Pokémon Using Spark and Plotly</title>
        <description>&lt;p&gt;There has been a lot of talk lately about &lt;a href=&quot;http://www.pokemon.com/us/&quot;&gt;Pokémon&lt;/a&gt; due to the runaway success of &lt;a href=&quot;http://www.pokemongo.com&quot;&gt;Pokémon GO&lt;/a&gt; (I myself am Trainer Level 18 and on &lt;span style=&quot;color: #e74c3c&quot;&gt;Team Valor&lt;/span&gt;). Players revel in the nostalgia of 1996 by now having the ability catching the original 151 Pokémon in real life.&lt;/p&gt;

&lt;p&gt;However, while players most-fondly remember the first generation, Pokémon is currently on its &lt;em&gt;sixth&lt;/em&gt; generation, with the seventh generation beginning later this year with &lt;a href=&quot;http://www.pokemon-sunmoon.com/en-us/&quot;&gt;Pokémon Sun and Moon&lt;/a&gt;. As of now, there are &lt;em&gt;721&lt;/em&gt; total Pokémon &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/List_of_Pok%C3%A9mon_by_National_Pok%C3%A9dex_number&quot;&gt;in the Pokédex&lt;/a&gt;, from &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Bulbasaur_(Pok%C3%A9mon)&quot;&gt;Bulbasaur&lt;/a&gt; to &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Volcanion_(Pok%C3%A9mon)&quot;&gt;Volcanion&lt;/a&gt;, not counting alternate Forms of several Pokémon such as &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Mega_Evolution&quot;&gt;Mega Evolutions&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the meantime, I&amp;rsquo;ve seen a few interesting data visualizations which capitalize on the frenzy. A &lt;a href=&quot;https://www.reddit.com/r/dataisbeautiful/comments/4uumqs/gotta_plot_em_all_the_height_versus_weight_of/&quot;&gt;highly-upvoted post&lt;/a&gt; on the Reddit subreddit /r/dataisbeautiful by &lt;a href=&quot;https://www.reddit.com/user/nvvknvvk&quot;&gt;/u/nvvknvvk&lt;/a&gt; charts the Height vs. Weight of the original 151 Pokémon. Anh Le of Duke University posted a &lt;a href=&quot;http://people.duke.edu/%7Eaql3/gotta-plot-them-all/&quot;&gt;cluster analysis&lt;/a&gt; of the original 151 Pokémon using &lt;a href=&quot;https://en.wikipedia.org/wiki/Principal_component_analysis&quot;&gt;principal component analysis&lt;/a&gt; (PCA), by compressing the 6 primary Pokémon stats into 2 dimensions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/pokemon-3d/pokemon-2d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;However, those visualizations think too small, and only on a small subset of Pokémon. Why not capture &lt;em&gt;every single aspect&lt;/em&gt; of &lt;em&gt;every Pokémon&lt;/em&gt; and violently crush that data into &lt;em&gt;three&lt;/em&gt; dimensions?&lt;/p&gt;

&lt;h2&gt;Spark (30% chance of paralyzing the target)&lt;/h2&gt;

&lt;p&gt;Last week, &lt;a href=&quot;http://spark.apache.org&quot;&gt;Apache Spark 2.0.0&lt;/a&gt; was released, a major milestone in big data analysis. Spark 2.0 is potentially &lt;a href=&quot;https://databricks.com/blog/2016/05/11/apache-spark-2-0-technical-preview-easier-faster-and-smarter.html&quot;&gt;10x as fast&lt;/a&gt; as the previous 1.6 version, with much improved APIs and documentation (you can actually import CSVs now!). The Python interface (which I use for this post), &lt;a href=&quot;http://spark.apache.org/docs/latest/api/python/&quot;&gt;PySpark&lt;/a&gt;, is now almost as functionally capable as the leading &lt;a href=&quot;http://scikit-learn.org/stable/&quot;&gt;scikit-learn&lt;/a&gt; machine learning tool, but with the ability to scale to terabyte-size datasets. &lt;/p&gt;

&lt;p&gt;The data source of both visualizations above is the &lt;a href=&quot;https://pokeapi.co&quot;&gt;PokéAPI&lt;/a&gt;, whose data is open-source and &lt;a href=&quot;https://github.com/PokeAPI/pokeapi/tree/master/data/v2/csv&quot;&gt;available as CSVs&lt;/a&gt; on GitHub, and &lt;em&gt;unusually&lt;/em&gt; clean with proper normalization. The dump is thorough, with full coverage of all the up-to-date  Pokémon information available in the games up to the current generation.&lt;/p&gt;

&lt;p&gt;The PokéAPI data includes numerical variables representing each Pokémon, including the six primary Pokémon stats (HP, Attack, Defense, Special Attack, Special Defense, Speed) and Height/Weight. We can aggregate those variables for all Pokémon and normalize them so that they are within [&lt;strong&gt;0.0&lt;/strong&gt;, &lt;strong&gt;1.0&lt;/strong&gt;] for easier computation when the data is eventually reduced into 3 dimensions. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/pokemon-3d/height-weight.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;But a tool like Spark is overkill for just normalization. What Spark &lt;em&gt;isn&amp;rsquo;t&lt;/em&gt; overkill for is working with categorical variables. Something we can do is encode variables as &lt;a href=&quot;https://en.wikipedia.org/wiki/Dummy_variable_(statistics)&quot;&gt;dummy variables&lt;/a&gt;, as Spark has a few tools especially helpful for that workflow. For example, let&amp;rsquo;s say we want to encode a Pokémon&amp;rsquo;s type(s) as binary variables.&lt;/p&gt;

&lt;p&gt;There are currently 18 &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Type&quot;&gt;different types&lt;/a&gt; of Pokémon, and a Pokémon can have either 1 or 2 types. We can encode a Pokémon&amp;rsquo;s type(s) in the field by setting a &lt;strong&gt;1.0&lt;/strong&gt; in columns which represent a given&amp;rsquo;s Pokémon&amp;rsquo;s type, and &lt;strong&gt;0.0&lt;/strong&gt; in all other columns. Bulbasaur, for example, is a Grass/Poison type. We set &lt;strong&gt;1.0&lt;/strong&gt; to the column representing Grass for Bulbasaur, and &lt;strong&gt;1.0&lt;/strong&gt; to the column representing Poison, and 16 total &lt;strong&gt;0.0&lt;/strong&gt; for all other columns (in the end, the data representing a Pokémon&amp;rsquo;s type is a 721x18 matrix). This approach is similar to the &lt;a href=&quot;https://en.wikipedia.org/wiki/One-hot&quot;&gt;one-hot encoding&lt;/a&gt; technique used for high-level data analysis. Spark allows the use of sparse data structures, so Spark does not have to store each &lt;strong&gt;0.0&lt;/strong&gt; in memory; just the indices of each &lt;strong&gt;1.0&lt;/strong&gt; and the size of the vector itself. Printing the table confirms that data structure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/pokemon-3d/sparse.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Here are the other Pokémon attributes present in the PokéAPI data dump that we can encode as binary columns:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Pokémon &lt;strong&gt;moves&lt;/strong&gt;, including all moves the Pokémon is capable of learning via leveling up/TMs/egg moves in any version of the game. This variable results in 613 added columns.&lt;/li&gt;
&lt;li&gt;Pokémon &lt;strong&gt;abilities&lt;/strong&gt;, which are passive effects, and each Pokémon can have one of up to 3 unique abilities (adds 191 columns)&lt;/li&gt;
&lt;li&gt;Pokémon &lt;strong&gt;color&lt;/strong&gt;, which is just as it sounds (10 columns)&lt;/li&gt;
&lt;li&gt;Pokémon &lt;strong&gt;shape&lt;/strong&gt;, which apparently includes classifications such as &amp;ldquo;ball,&amp;rdquo; &amp;ldquo;quadruped,&amp;rdquo; and &amp;ldquo;squiggle&amp;rdquo;? (14 columns)&lt;/li&gt;
&lt;li&gt;Pokémon &lt;strong&gt;habitat&lt;/strong&gt; where the Pokémon can generally be found (or &lt;em&gt;not&lt;/em&gt; found in the case of Event Pokémon) (10 columns)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Combining all the sparse vectors with special Spark functions, we have a dataframe of 863 features. Using PCA, we reduce the dimensionality that data from 863 dimensions to 50 dimensions (we&amp;rsquo;re not going down to 3 dimensions &lt;em&gt;just&lt;/em&gt; yet)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/pokemon-3d/pca.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The top 3 principal components of this 50D model explain only 12.8% of the data variance in the 3D space, which means that clusters would likely not be apparent if plotted as-is. A smart thing to do would be to use a clustering algorithm. t-SNE is a &lt;a href=&quot;https://lvdmaaten.github.io/tsne/&quot;&gt;relatively new algorithm&lt;/a&gt; by Laurens van der Maaten that is surprisingly effective at clustering high-dimensional data into low-dimensional space, without causing high amounts of blending between points (unfortunately, it can be computationally intensive, which is one of the reason I reduced the dimensionality of the data to 50D first). Most academic papers focus on 2D representations of the data resulting from t-SNE, but there&amp;rsquo;s nothing preventing users from projecting the data to 3D!&lt;/p&gt;

&lt;p&gt;Running &lt;a href=&quot;https://github.com/danielfrg/tsne&quot;&gt;a Python wrapper&lt;/a&gt; of t-SNE on the PCA-reduced dataset results in magic.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/pokemon-3d/t-sne.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As you can see, the Pokémon along the same evolutionary track have very close [x,y,z] values, which indicates that the clustering algorithm accurately placed them close together. Notably, it classified the preevolutions of the common bug Pokémon all together (&lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Caterpie_(Pok%C3%A9mon)&quot;&gt;Caterpie&lt;/a&gt;/&lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Metapod_(Pok%C3%A9mon)&quot;&gt;Metapod&lt;/a&gt;/&lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Weedle_(Pok%C3%A9mon)&quot;&gt;Weedle&lt;/a&gt;/&lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Kakuna_(Pok%C3%A9mon)&quot;&gt;Kakuna&lt;/a&gt;) even though they are of different evolutionary lines, but have similar attributes/movesets. The final evolutions of these Bug Pokémon, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Butterfree_(Pok%C3%A9mon)&quot;&gt;Butterfree&lt;/a&gt; and &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Beedrill_(Pok%C3%A9mon)&quot;&gt;Beedrill&lt;/a&gt;, are clustered much differently than their pre-evolution stages, because the preevolutions are statistically useless while Butterfree/Beedrill are not as useless.&lt;/p&gt;

&lt;p&gt;How do you best visualize these clusters? That&amp;rsquo;s where Plotly comes in.&lt;/p&gt;

&lt;h2&gt;Nasty Plotly (Sharply raises Special Attack)&lt;/h2&gt;

&lt;p&gt;Plotly is a data visualization tool, now open-source, which allows users to create interactive visualizations with a robust API. I previously used it for &lt;a href=&quot;http://minimaxir.com/2016/06/interactive-reactions/&quot;&gt;visualizations with R&lt;/a&gt;, but as it turns out, the Python API to Plotly is much more powerful. Simply plotting a static 3D chart using something like &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; with the default settings is not insightful.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/pokemon-3d/pokemon_pca_test.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In this case, the ability to manipulate the perspective of the data is very important. And so with a little bit of Plotly documentation-delving, I managed to create the 3D chart that you  hopefully saw at the top of this page.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/pokemon-3d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Each dot is colored by the Pokémon&amp;rsquo;s type in the first slot for simplicity (one exception is Normal/Flying Pokémon like &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Pidgey_(Pok%C3%A9mon)&quot;&gt;Pidgey&lt;/a&gt;; I manually converted their displayed type to Flying because the omission was notable due to Game Freak&amp;rsquo;s addiction to that particular pairing in the early generations). This gives a surprisingly coherent visualization of the groups of Pokémon types present. But it&amp;rsquo;s also important to note the groups &lt;em&gt;outside&lt;/em&gt; the clusters, in order to identify incorrect clusters, or to identify Pokémon which have been clusters as &lt;em&gt;especially&lt;/em&gt; unique.&lt;/p&gt;

&lt;p&gt;A few interesting observations I&amp;rsquo;ve noted:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There are two far-away colocated clusters for Pokémon which are useless: gimmick Pokémon with limited movesets like &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Wobbuffet_(Pok%C3%A9mon)&quot;&gt;Wobbuffet&lt;/a&gt;, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Ditto_(Pok%C3%A9mon)&quot;&gt;Ditto&lt;/a&gt;, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Smeargle_(Pok%C3%A9mon)&quot;&gt;Smeargle&lt;/a&gt;, and &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Magikarp_(Pok%C3%A9mon)&quot;&gt;Magikarp&lt;/a&gt;, and &lt;em&gt;Bug&lt;/em&gt; Pokémon with limited movesets, as mentioned before, like &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Burmy_(Pok%C3%A9mon)&quot;&gt;Burmy&lt;/a&gt; and &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Kricketot_(Pok%C3%A9mon)&quot;&gt;Kricketot&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;There are often close clusters for Legendary Pokémon trios (&lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Articuno_(Pok%C3%A9mon)&quot;&gt;Articuno&lt;/a&gt;, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Zapdos_(Pok%C3%A9mon)&quot;&gt;Zapdos&lt;/a&gt;, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Moltres_(Pok%C3%A9mon)&quot;&gt;Moltres&lt;/a&gt;; the Pokémon which represent the teams in Pokémon GO) due to similar stats/moves.&lt;/li&gt;
&lt;li&gt;The Flying cluster is interesting due to the presence of other Types of Pokémon which have a different first type, but the location correctly implies that they are closer to their Flying secondary type (&lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Zubat_(Pok%C3%A9mon)&quot;&gt;Zubat&lt;/a&gt;, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Murkrow_(Pok%C3%A9mon)&quot;&gt;Murkrow&lt;/a&gt;, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Xatu_(Pok%C3%A9mon)&quot;&gt;Xatu&lt;/a&gt;, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Wingull_(Pok%C3%A9mon)&quot;&gt;Wingull&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Lastly, the Pokémon God &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Arceus_(Pok%C3%A9mon)&quot;&gt;Arceus&lt;/a&gt;, which has the highest stat total of the base Pokémon, is located in its own cluster alongside similarly-statistically-powerful Pokémon such as &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Dialga_(Pok%C3%A9mon)&quot;&gt;Dialga&lt;/a&gt;, &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Dragonite_(Pok%C3%A9mon)&quot;&gt;Dragonite&lt;/a&gt;, and &lt;a href=&quot;http://bulbapedia.bulbagarden.net/wiki/Gyarados_(Pok%C3%A9mon)&quot;&gt;Gyarados&lt;/a&gt;. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Interactive 3D was definitely a good idea for this type of visualization, as a 2D visualization would be difficult to read, and even more difficult to discern the clusters. And this project was a good reason to test out the capabilities of Spark 2.0 and prototype code for future data analysis projects (the next dataset I use will be &lt;em&gt;much&lt;/em&gt; larger, I promise). I do have a few ideas for improvements to the 3D chart in the pipeline, but maybe I&amp;rsquo;ll save them for when the seventh generation is fully released.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;The full code used to process the Pokémon data using Spark is available in &lt;a href=&quot;https://github.com/minimaxir/pokemon-3d/blob/master/pokemon_spark_pca.ipynb&quot;&gt;this Jupyter notebook&lt;/a&gt;, and the code used to generate the Plotly visualizations is available in &lt;a href=&quot;https://github.com/minimaxir/pokemon-3d/blob/master/pokemon_3d_plotly.ipynb&quot;&gt;this Jupyter notebook&lt;/a&gt;, both open-sourced &lt;a href=&quot;https://github.com/minimaxir/pokemon-3d&quot;&gt;on GitHub&lt;/a&gt;.  In the GitHub repository, you can download standalone, offline versions of the 3D chart; including an extra chart with cluster meshes, which was unused for this post due to performance issues.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 03 Aug 2016 06:30:00 -0700</pubDate>
        <link>http://minimaxir.com/2016/08/pokemon-3d/</link>
        <guid isPermaLink="true">http://minimaxir.com/2016/08/pokemon-3d/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
        <category>Interactive</category>
        
      </item>
    
      <item>
        <title>Visualizing How Developers Rate Their Own Programming Skills</title>
        <description>&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com&quot;&gt;Stack Overflow&lt;/a&gt;, the favorite destination for software developers when something breaks for no apparent reason, recently released their &lt;a href=&quot;http://stackoverflow.com/research/developer-survey-2016&quot;&gt;2016 Stack Overflow Survey Results&lt;/a&gt; with responses to the questions of &amp;ldquo;where they work, what they build, and who they are.&amp;rdquo; You can download the released dataset containing all 56,030 cleaned responses &lt;a href=&quot;http://stackoverflow.com/research&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One variable present in the dataset but surprisingly unaddressed in the official Stack Overflow analysis is the &lt;code&gt;programming_ability&lt;/code&gt; field — &lt;em&gt;On a scale of 1-10, how would you rate your programming ability?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I took a look at the 46,982 users who identified their programming ability in the survey. On average, developers rate themselves 7.09 / 10. And like most 1-10 rating scales, the distribution of self-assessments is unimodal around 7 and 8, with relatively rare 9&amp;rsquo;s and 10&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow/so-programming-0.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;We can aggregate the programming ability data by other relevant metrics in the Stack Overflow dataset, such as experience and commit activity, and hopefully find interesting trends.&lt;/p&gt;

&lt;h2&gt;Sanity Checking&lt;/h2&gt;

&lt;p&gt;I normally dislike working with survey data since there is a high possibility of &lt;a href=&quot;https://en.wikipedia.org/wiki/Selection_bias&quot;&gt;selection bias&lt;/a&gt; among the respondents. In Stack Overflow&amp;rsquo;s case, their marketing of the survey on Facebook and Twitter may cause a high proportion of social-media savvy respondents and discount the insight of developers who are not likely to use those services. For this reason, I will show &lt;a href=&quot;https://en.wikipedia.org/wiki/Confidence_interval&quot;&gt;confidence intervals&lt;/a&gt; whenever possible to reflect the proportionate uncertainty for groupings with insufficient data, and to also account for possibility that a minority of respondents may be dishonest and nudge their programming ability a few points higher than the truth.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s compare programming skill to the developer&amp;rsquo;s experience in the field. In the survey, the user could classify their IT / programming experience as a range, from &amp;ldquo;Less than 1 year&amp;rdquo;, &amp;ldquo;1 - 2 years&amp;rdquo;, &amp;ldquo;2 - 5 years&amp;rdquo;, &amp;ldquo;6 - 10 years&amp;rdquo;, and &amp;ldquo;11+ years.&amp;rdquo; Since we would expect a positive correlation between skill and experience, identifying such a positive correlation visually gives a quick indication that the analysis is on the right track.&lt;/p&gt;

&lt;p&gt;We can plot the average programming-ability rating for developers which fall into each of those five groups, and a confidence interval for that average. Additionally, we can make a &lt;a href=&quot;https://en.wikipedia.org/wiki/Violin_plot&quot;&gt;violin plot&lt;/a&gt; of each group to give a sense of the underlying distribution of ratings.&lt;/p&gt;

&lt;p&gt;Putting it all together:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow/so-programming-5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The color dot for each group represents the average rating from the sample which the developers in the group give to themselves. The black error bars on the dot represent a 95% confidence interval for the true value of the average, obtained via &lt;a href=&quot;http://minimaxir.com/2015/09/bootstrap-resample/&quot;&gt;percentile bootstrap&lt;/a&gt; with 10,000 resamples of the dataset with replacement (since there is a large amount of source data, the confidence intervals end up being very narrow in most cases; this is one legitimate advantage of big data).&lt;/p&gt;

&lt;p&gt;The violin plot for each group represents the normalized overall distribution of ratings. The narrowness of the per-value ratings reflect the amount of data available for that group: the more data available, the more narrow/precise the kernel smoothing is. Overall flat plots represent a wide selection of self-ratings, while an overall narrow plot represents a more-constrained selection (for the plot above, you can easily see the distribution shift to the right as the experience range increases).&lt;/p&gt;

&lt;p&gt;Also, keep in mind that these groupings alone do not imply a &lt;strong&gt;causal relationship&lt;/strong&gt; between the two variables. Employing traditional &lt;a href=&quot;https://en.wikipedia.org/wiki/Regression_analysis&quot;&gt;regression analysis&lt;/a&gt; to build a model for predicting programming ability would be tricky: does having more experience cause programming skill to improve, or does having strong innate technical skill cause developers to remain in the industry and grow?&lt;/p&gt;

&lt;p&gt;Back to the plot at hand. We can easily confirm that a positive correlation exists between programming activity and experience, with newbie developers rating their skills 5.02 / 10 on average, and extremely experienced developers rating their skills three whole ranks higher at 8.13 / 10. What&amp;rsquo;s also notable is the range of values selected: for developers with &lt;strong&gt;less than 1 years&lt;/strong&gt; of experience, the distribution is almost completely flat between 1-7, showing that they are more honest with the self-assessment of their programming skills. Inversely, developers with &lt;strong&gt;11+ years&lt;/strong&gt; of experience select 9 and 10 ratings almost as much as 7 and 8 ratings.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s a good start. We can also compare developer skill to their age, which by construction (older developers have more experience) should have parallel behavior to experience levels.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow/so-programming-4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Yes, the plot is indeed similar, with average ratings ranging from 6 to about 8. What&amp;rsquo;s interesting is the behavior for &lt;strong&gt;&amp;gt; 60&lt;/strong&gt; vs. &lt;strong&gt;50-59&lt;/strong&gt; is that the &amp;gt; 60 age programmers occasionally rate their skills at the low end of the scale, which is why the confidence interval is larger and the average is lower for that group.&lt;/p&gt;

&lt;p&gt;Lastly, we can look at the salary the developer is paid (in USD) as a validation of skill. This particular chart will only focus on developers in the United States (n = 13,539), so that the salary follows expected behavior with the specified currency and cost-of-living. In this case, there are many more groups, but that makes the distribution shift more apparent, and more interesting.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow/so-programming-6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The large amount of &amp;gt;$100k earners in the dataset shows how the Stack Overflow demographic can skew toward Silicon Valley engineers. The $90k—$100k group serves as a convenient inflection point on how the distribution of self-ratings becomes a &lt;a href=&quot;http://tvtropes.org/pmwiki/pmwiki.php/Main/FourPointScale&quot;&gt;Four Point Scale&lt;/a&gt; between 7 and 10 for those who earn more than $100k.&lt;/p&gt;

&lt;h2&gt;Do better developers rate themselves better?&lt;/h2&gt;

&lt;p&gt;So far, the data is internally consistent. There are a few other developer-relevant statistics are available in the dataset which can easily be aggregated. A good one is the &lt;em&gt;type&lt;/em&gt; of employment. For example, do &lt;strong&gt;freelance / contract&lt;/strong&gt; developers believe they are better programmers than &lt;strong&gt;full-time&lt;/strong&gt; developers?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow/so-programming-7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As it turns out, that guess is indeed the case, albeit it&amp;rsquo;s only a slight difference (7.53 / 10 for &lt;strong&gt;freelance / contract&lt;/strong&gt; vs. 7.29 / 10 for &lt;strong&gt;full-time&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;What about repository commit activity by developers? Are developers who commit more better? One could argue that a developer who commits code often is either vigilant with accounting for functional code changes, or polluting the codebase in an attempt to show productivity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow/so-programming-8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Yes, developers who commit lots of code rate themselves better.&lt;/p&gt;

&lt;p&gt;Lastly, let&amp;rsquo;s remember that the source of data is Stack Overflow. Are developers who use Stack Overflow as a resource better developers who know how to properly use external references in times of crisis, or are they developers who use it as a crutch to compensate for weak coding skills?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow/so-programming-9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As it turns out, there is &lt;strong&gt;no correlation between programming ability and and the frequency of Stack Overflow visits&lt;/strong&gt;, as the averages and distributions are virtually identical across all groups.&lt;/p&gt;

&lt;p&gt;There are many, many other answers available in the dataset; some allow multiple responses and are harder to parse, while others have zero correlation with programming ability as with the Stack Overflow visits, and therefore do not provide much additional insight. Although we cannot establish causal relationships with this methodology, there may be other important insights obtainable from aggregating programming ability data, but the charts presented in this post are a good start.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;As always, the full code used to process the comment data and generate the visualizations is available in &lt;a href=&quot;https://github.com/minimaxir/stack-overflow-survey/blob/master/stack_overflow_dev_survey.ipynb&quot;&gt;this Jupyter notebook&lt;/a&gt;, open-sourced &lt;a href=&quot;https://github.com/minimaxir/stack-overflow-survey&quot;&gt;on GitHub&lt;/a&gt;. The repository also contains a few unused bonus charts!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the charts from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 21 Jul 2016 06:30:00 -0700</pubDate>
        <link>http://minimaxir.com/2016/07/stack-overflow/</link>
        <guid isPermaLink="true">http://minimaxir.com/2016/07/stack-overflow/</guid>
        
        
        <category>Visualization</category>
        
        <category>Data</category>
        
      </item>
    
  </channel>
</rss>
