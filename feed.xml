<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>minimaxir | Max Woolf's Blog</title>
    <description>A blog by data scientist Max Woolf about startups, technology, and blogging.</description>
    <link>https://minimaxir.com/</link>
    <atom:link href="https://minimaxir.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 22 Oct 2018 09:14:47 -0700</pubDate>
    <lastBuildDate>Mon, 22 Oct 2018 09:14:47 -0700</lastBuildDate>
    <generator>Jekyll v3.8.4</generator>
    
      <item>
        <title>Things About Real-World Data Science Not Discussed In MOOCs and Thought Pieces</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Data_science&quot;&gt;Data science&lt;/a&gt; has been sweeping the tech world. With a large variety of powerful free open-sourced tools and now the computing power to utilize them to their full potential, data science is more accessible than ever and has become &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-05-18/-sexiest-job-ignites-talent-wars-as-demand-for-data-geeks-soars&quot;&gt;America&amp;rsquo;s hottest job&lt;/a&gt;. One problem: there&amp;rsquo;s no consensus on &lt;a href=&quot;https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists&quot;&gt;what data scientists &lt;em&gt;really&lt;/em&gt; do&lt;/a&gt; in a professional setting.&lt;/p&gt;

&lt;p&gt;There has been a rise in &lt;em&gt;romantic&lt;/em&gt; thought pieces lately (especially on &lt;a href=&quot;https://medium.com&quot;&gt;Medium&lt;/a&gt;) about how data scientists are wizards and can solve any problem (with bonus points if it cites AI). If you follow publications like &lt;a href=&quot;https://towardsdatascience.com&quot;&gt;Towards Data Science&lt;/a&gt;, you&amp;rsquo;ll notice persistent tropes in the more code-oriented posts: Python is the king programming language for data science, use &lt;a href=&quot;http://scikit-learn.org/stable/&quot;&gt;scikit-learn&lt;/a&gt;/&lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/&quot;&gt;XGBoost&lt;/a&gt; and logistic regression for predicting categorical variable(s), use &lt;a href=&quot;https://pandas.pydata.org&quot;&gt;pandas&lt;/a&gt; for processing tabular data, use &lt;a href=&quot;https://www.nltk.org&quot;&gt;NLTK&lt;/a&gt;/&lt;a href=&quot;https://en.wikipedia.org/wiki/Word2vec&quot;&gt;word2vec&lt;/a&gt; for processing text data, use &lt;a href=&quot;https://www.tensorflow.org&quot;&gt;TensorFlow&lt;/a&gt;/&lt;a href=&quot;https://keras.io&quot;&gt;Keras&lt;/a&gt;/convolutional neural networks for processing image data, use &lt;a href=&quot;https://en.wikipedia.org/wiki/K-means_clustering&quot;&gt;&lt;em&gt;k&lt;/em&gt;-means&lt;/a&gt; for clustering data, split the processed dataset into training and test datasets for model training, tweak hyperparameters/model features &lt;a href=&quot;https://xkcd.com/1838/&quot;&gt;until results on the test dataset are good&lt;/a&gt;, etc.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/data-science-protips/thought.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;These tropes aren&amp;rsquo;t inappropriate or misleading, but the analysis often doesn&amp;rsquo;t quantify the insight/value of the results. Modeling is just one small part (and often the &lt;em&gt;easiest&lt;/em&gt; part) of a very complex system.&lt;/p&gt;

&lt;p&gt;Data-oriented MOOCs (&lt;a href=&quot;https://en.wikipedia.org/wiki/Massive_open_online_course&quot;&gt;Massive Online Open Courses&lt;/a&gt;) like Andrew Ng&amp;rsquo;s &lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;Coursera course on Machine Learning&lt;/a&gt; and &lt;a href=&quot;http://course.fast.ai&quot;&gt;fast.ai&amp;rsquo;s course on Deep Learning&lt;/a&gt; are good academic introductions to the theory and terminology behind data science and other related fields. Although MOOCs have many practice problems for prospective data scientists to solve, they don&amp;rsquo;t make you an expert in the field capable of handling messier real-world problems, nor claim to do so.&lt;/p&gt;

&lt;p&gt;Modern data science isn&amp;rsquo;t about burying your head in a &lt;a href=&quot;http://jupyter.org&quot;&gt;Jupyter Notebook&lt;/a&gt; and staring at the screen watching training loss numbers trickle down (although it&amp;rsquo;s definitely fun!). There&amp;rsquo;s a lot more to it, some of which I&amp;rsquo;ve learned firsthand working as a Data Scientist at &lt;a href=&quot;https://www.buzzfeed.com&quot;&gt;BuzzFeed&lt;/a&gt; for over a year. To borrow a statistical term, MOOCs and thought pieces &lt;em&gt;overfit&lt;/em&gt; to a certain style of data science that is not robust to the vast uncertainties of the real world.&lt;/p&gt;

&lt;h2&gt;The Cost/Benefit Tradeoffs of Data Science&lt;/h2&gt;

&lt;p&gt;Data science often follows the &lt;a href=&quot;https://en.wikipedia.org/wiki/Pareto_principle&quot;&gt;Pareto principle&lt;/a&gt;: 80% of the work takes 20% of the effort. Thought pieces demonstrate that you can just toss data indiscriminately into scikit-learn or a deep learning framework and get neat-looking results. The value of a data scientist, however, is when and &lt;em&gt;if&lt;/em&gt; to further development on a model.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.kaggle.com/competitions&quot;&gt;Kaggle competitions&lt;/a&gt; are a popular and often-recommended way to get exposure to real-world data science problems. Many teams of statisticians compete to create the best model for a given dataset (where &amp;ldquo;best&amp;rdquo; usually means minimizing the predictive loss/error of the model), with prizes for the highest-performing models. Kaggle also encourages clever modeling techniques such as &lt;a href=&quot;http://scikit-learn.org/stable/modules/grid_search.html&quot;&gt;grid search&lt;/a&gt; of thousands of model hyperparameter combinations and ensembling disparate models to create a megamodel which results in &lt;em&gt;slightly&lt;/em&gt; better predictive performance, but just might give the edge to win.&lt;/p&gt;

&lt;p&gt;However, there are a few important differences between modeling in a Kaggle competition and modeling in a data science team. Kaggle competitions last for &lt;em&gt;weeks&lt;/em&gt; when a professional data scientist may need to spend time on other things. Ensembling gigantic machine learning models makes predictions very slow and the models themselves very large; both of which may cause difficulty deploying them into production (e.g. the &lt;a href=&quot;https://www.wired.com/2012/04/netflix-prize-costs/&quot;&gt;Netflix Prize&lt;/a&gt; movie recommendation models famously &amp;ldquo;did not seem to justify the engineering effort needed to bring them into a production environment&amp;rdquo;). And most importantly, there may not be a significant &lt;em&gt;practical&lt;/em&gt; performance difference between a 1st place Kaggle model that takes days/weeks to optimize and a simple scikit-learn/XGBoost baseline that can be built in a few hours.&lt;/p&gt;

&lt;p&gt;Counterintuitively, it may be better to trade performance for speed/memory with a weaker-but-faster model; in business cases, speed and scalability are important implementation constraints. But even with scikit-learn, the model is still a &lt;a href=&quot;https://en.wikipedia.org/wiki/Black_box&quot;&gt;black box&lt;/a&gt; with little idea to the data scientist how the model makes its decisions. One final option is to go back to basics altogether with a &amp;ldquo;boring&amp;rdquo; linear/logistic regression model, where the predictive performance may be even weaker and the model &lt;a href=&quot;http://statisticsbyjim.com/regression/ols-linear-regression-assumptions/&quot;&gt;must follow several statistical assumptions&lt;/a&gt;, but the model feature coefficients and statistical significance &lt;a href=&quot;http://blog.minitab.com/blog/adventures-in-statistics-2/how-to-interpret-regression-analysis-results-p-values-and-coefficients&quot;&gt;are easily interpretable&lt;/a&gt; to explain the importance of each input feature (if any) and make actionable, informed decisions for the business. Being a data scientist requires making educated judgments about these tradeoffs.&lt;/p&gt;

&lt;h2&gt;Data Scientists Still Use Business Intelligence Tools&lt;/h2&gt;

&lt;p&gt;A hobbyist data scientist without a budget may opt to build their own workflows and data pipelines using free tools. However, professional data scientists have a finite amount of free time (as do all engineers), so there&amp;rsquo;s a massive opportunity cost when reinventing the wheel unnecessarily. Enterprise BI tools such as &lt;a href=&quot;https://www.tableau.com&quot;&gt;Tableau&lt;/a&gt;, &lt;a href=&quot;https://looker.com&quot;&gt;Looker&lt;/a&gt;, and &lt;a href=&quot;https://modeanalytics.com&quot;&gt;Mode Analytics&lt;/a&gt; help retrieve and present data with easy-to-digest dashboards for anyone in the company. They&amp;rsquo;re never cheap, but they&amp;rsquo;re much cheaper to the company than having a data scientist spend valuable time to develop and maintain similar tooling over time. &lt;/p&gt;

&lt;p&gt;If a stakeholder wants a data report ASAP, there&amp;rsquo;s no problem falling back to using &lt;a href=&quot;https://en.wikipedia.org/wiki/SQL&quot;&gt;SQL&lt;/a&gt; to query a data warehouse and output results into an Excel spreadsheet (plus pretty data visualizations!) to quickly transport in an email. Part of being a data scientist is working out which tools are best appropriate at what time.&lt;/p&gt;

&lt;p&gt;Some might argue that using BI tools and SQL are not responsibilities for data scientists, but instead for Business Analysts or Data Analysts. That&amp;rsquo;s a &lt;a href=&quot;https://en.wikipedia.org/wiki/No_true_Scotsman&quot;&gt;No True Scotsman&lt;/a&gt; way of looking at it; there&amp;rsquo;s a lot of overlap in data science with other analytical fields, and there&amp;rsquo;s nothing wrong with that.&lt;/p&gt;

&lt;h2&gt;Data Scientists Are Software Engineers Too&lt;/h2&gt;

&lt;p&gt;Although MOOCs encourage &lt;em&gt;self&lt;/em&gt;-study, data science is a collaborative process. And not just with other data scientists on a team, but with other software engineers in the company. Version control tools like &lt;a href=&quot;https://git-scm.com&quot;&gt;Git&lt;/a&gt; are often used for data scientists to upload their portfolio projects publicly to &lt;a href=&quot;https://github.com&quot;&gt;GitHub&lt;/a&gt;, but there are many other important features for use in a company-wide collaborative environment such as branching a repository, making pull requests, and merging conflicts. Beyond that are modern development QA practices, such as test environments, consistent code style, and code reviews. The full process varies strongly by company: Airbnb has a &lt;a href=&quot;https://medium.com/airbnb-engineering/scaling-knowledge-at-airbnb-875d73eff091&quot;&gt;good thought piece&lt;/a&gt; about how they utilize their Knowledge Base for data science collaboration using Git.&lt;/p&gt;

&lt;p&gt;One of the very hard and surprisingly underdiscussed aspects of data science is &lt;a href=&quot;https://en.wikipedia.org/wiki/DevOps&quot;&gt;DevOps&lt;/a&gt;, and how to actually get a statistical model into production.  &lt;a href=&quot;https://www.docker.com/resources/what-container&quot;&gt;Docker containers&lt;/a&gt;, for example, are newer technology that&amp;rsquo;s hard to learn, but have many data science and DevOps benefits by mitigating Python dependency hell and ensuring a consistent environment for model deployment and execution. And once the model is in production, data scientists, data engineers, and dedicated DevOps personnel need to work together to figure out if the model has the expected output, if the model is performing with expected speed/memory overhead, how often to retrain the model on fresh data (plus the scheduling/data pipelining necessary to do so), and how to efficiently route predictions out of the system to the user.&lt;/p&gt;

&lt;h2&gt;Data Science Can&amp;rsquo;t Solve Everything&lt;/h2&gt;

&lt;p&gt;Data science experiments (even those utilizing magical AI) are allowed to fail, and not just in the fail-to-reject-the-null-hypothesis sense. Thought pieces typically discuss successful projects, which leads to a survivorship bias. Even with massive amounts of input data, it&amp;rsquo;s &lt;em&gt;likely&lt;/em&gt; for a model to fail to converge and offer zero insight, or an experiment fail to offer statistically significant results (common with &lt;a href=&quot;https://vwo.com/ab-testing/&quot;&gt;A/B testing&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;real world data science is an R&lt;sup&gt;2&lt;/sup&gt; of 0.10 &lt;a href=&quot;https://twitter.com/hashtag/GoogleNext18?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#GoogleNext18&lt;/a&gt; &lt;a href=&quot;https://t.co/qNsno2dscR&quot;&gt;pic.twitter.com/qNsno2dscR&lt;/a&gt;&lt;/p&gt;&amp;mdash; Max Woolf (@minimaxir) &lt;a href=&quot;https://twitter.com/minimaxir/status/1021885939361042432?ref_src=twsrc%5Etfw&quot;&gt;July 24, 2018&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; 
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The difficulty of real-world data science is recognizing if a given problem &lt;em&gt;can&lt;/em&gt; be solved, how much of your valuable time to spend iterating to &lt;em&gt;maybe&lt;/em&gt; solve it, how to report to stakeholders if it &lt;em&gt;can&amp;rsquo;t&lt;/em&gt; be solved, and what are the next steps if that&amp;rsquo;s the case.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t &lt;a href=&quot;https://www.buzzfeednews.com/article/stephaniemlee/brian-wansink-cornell-p-hacking&quot;&gt;&lt;em&gt;p&lt;/em&gt;-hack&lt;/a&gt;!&lt;/p&gt;

&lt;h2&gt;Data Science and Ethics&lt;/h2&gt;

&lt;p&gt;During the rise of the &amp;ldquo;data science/AI is magic!&amp;rdquo; era, massive algorithmic and statistical failures suggest that data science might not always make the world a better place. Amazon built a resume-reading model which &lt;a href=&quot;https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G&quot;&gt;accidentally learned to be sexist&lt;/a&gt;. Facebook overestimated &lt;a href=&quot;https://www.theverge.com/2018/10/17/17989712/facebook-inaccurate-video-metrics-inflation-lawsuit&quot;&gt;performance metrics on their videos&lt;/a&gt;, causing complete business pivots for media organizations in vain, indirectly &lt;a href=&quot;https://www.theatlantic.com/technology/archive/2018/10/facebook-driven-video-push-may-have-cost-483-journalists-their-jobs/573403/&quot;&gt;leading to hundreds of layoffs&lt;/a&gt;. YouTube&amp;rsquo;s recommended video algorithms &lt;a href=&quot;https://medium.com/@jamesbridle/something-is-wrong-on-the-internet-c39c471271d2&quot;&gt;drove children towards shocking and disturbing content&lt;/a&gt;. And these companies have some of the best data talent &lt;em&gt;in the entire world&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;qualitative&lt;/em&gt; output of a model or data analysis is just as important as the quantitative performance, if not more. Allowing dangerous model output to hit production and impact &lt;em&gt;millions&lt;/em&gt; of consumers is a failure of QA at all levels. In fairness these companies usually fix these issues, but only &lt;em&gt;after&lt;/em&gt; journalists &lt;a href=&quot;https://www.nytimes.com/2018/10/19/opinion/facebook-twitter-journalism-misinformation.html&quot;&gt;point them out&lt;/a&gt;. The problem with blindly chasing a performance metric (like Kaggle) is that it ignores collateral, unexpected effects. &lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Don’t be data-driven. Be data-informed. Metrics should never be in charge because they have no moral compass.&lt;/p&gt;&amp;mdash; Kim Goodwin (@kimgoodwin) &lt;a href=&quot;https://twitter.com/kimgoodwin/status/1051849805280948224?ref_src=twsrc%5Etfw&quot;&gt;October 15, 2018&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Maybe recommending shocking videos is what maximizes clickthrough rate or ad revenue per the models according to a business dashboard. Unfortunately, if the data justifies it and the business stakeholders encourage it, the company may &lt;em&gt;accept the consequences&lt;/em&gt; of a flawed algorithm if they don&amp;rsquo;t outweigh the benefits. It&amp;rsquo;s important for data scientists to be aware that they may be party to that.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I realize the irony of using a data science thought piece to argue against data science thought pieces. In fairness, some Medium thought pieces do apply data science in very &lt;em&gt;unique&lt;/em&gt; ways or touch on very obscure-but-impactful aspects of frameworks, and I enjoy reading those. The field is still very broadly defined, and your experiences may differ from this post, especially if you&amp;rsquo;re working for a more research-based institution. Unfortunately, I don’t have any new advice for &lt;em&gt;getting&lt;/em&gt; a data science job, which is &lt;a href=&quot;https://twitter.com/minimaxir/status/951117788835278848&quot;&gt;still very difficult&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;The popular idea that being a data scientist is a 40-hours-a-week Kaggle competition is &lt;strong&gt;incorrect&lt;/strong&gt;. There&amp;rsquo;s a lot more to it that&amp;rsquo;s not as sexy which, in my opinion, is the more interesting aspect of the data science field as a whole.&lt;/p&gt;
</description>
        <pubDate>Mon, 22 Oct 2018 09:15:00 -0700</pubDate>
        <link>https://minimaxir.com/2018/10/data-science-protips/</link>
        <guid isPermaLink="true">https://minimaxir.com/2018/10/data-science-protips/</guid>
        
        
        <category>Thought Piece</category>
        
      </item>
    
      <item>
        <title>Problems with Predicting Post Performance on Reddit and Other Link Aggregators</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.reddit.com&quot;&gt;Reddit&lt;/a&gt;, &amp;ldquo;the front page of the internet&amp;rdquo; is a link aggregator where anyone can submit links to cool happenings. Over the years, Reddit has expanded from just being a link aggregator, to allowing image and videos, and as of recently, hosting images and videos itself.&lt;/p&gt;

&lt;p&gt;Reddit is broken down into subreddits, where each subreddit represents each own community around a particular interest, like &lt;a href=&quot;https://www.reddit.com/r/aww&quot;&gt;/r/aww&lt;/a&gt; for pet photos and &lt;a href=&quot;https://www.reddit.com/r/politics/&quot;&gt;/r/politics&lt;/a&gt; for U.S. politics. The posts on each subreddit are ranked by some function of both time elapsed since the submission was made, and the &lt;em&gt;score&lt;/em&gt; of the submission as determined by upvotes and downvotes from other users.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/reddit_aww.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s also an intrinsic pride in having something you&amp;rsquo;re responsible for providing to the community get lots of upvotes (the submitter also earns karma based on received upvotes, although karma is meaningless and doesn&amp;rsquo;t provide any user benefits). But the reality is that even on the largest subreddits, submissions with 1 point (the default score for new submissions) are the most prominent, with some subreddits having &lt;em&gt;over half&lt;/em&gt; of their submissions with only 1 point.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/reddit_dist_facet.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The exposure from having a submission go viral on Reddit (especially on larger subreddits) can be valuable especially if its your own original content. As a result, there has been a lot of &lt;a href=&quot;https://www.brandwatch.com/blog/how-to-get-on-the-front-page-of-reddit/&quot;&gt;analysis&lt;/a&gt;/&lt;a href=&quot;https://www.reddit.com/r/starterpacks/comments/8rkfk9/reddit_front_page_starter_pack/&quot;&gt;stereotypes&lt;/a&gt; on what techniques to do to help your submission make it to the top of the front page. But almost all claims of &amp;ldquo;cracking&amp;rdquo; the Reddit algorithm are &lt;a href=&quot;https://en.wikipedia.org/wiki/Post_hoc_ergo_propter_hoc&quot;&gt;&lt;em&gt;post hoc&lt;/em&gt; rationalizations&lt;/a&gt;, attributing success to things like submission timing and title verbiage of a single submission after the fact. The nature of algorithmic feeds inherently leads to a &lt;a href=&quot;https://en.wikipedia.org/wiki/Survivorship_bias&quot;&gt;survivorship bias&lt;/a&gt;: although users may recognize certain types of posts that appear on the front page, there are many more which follow the same patterns but fail, which makes modeling a successful post very tricky.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve touched on analyzing Reddit post performance &lt;a href=&quot;https://minimaxir.com/2017/06/reddit-deep-learning/&quot;&gt;before&lt;/a&gt;, but let&amp;rsquo;s give it another look and see if we can drill down on why Reddit posts do and do not do well. &lt;/p&gt;

&lt;h2&gt;Submission Timing&lt;/h2&gt;

&lt;p&gt;As with many US-based websites, the majority of Reddit users are most active during work hours (9 AM — 5 PM Eastern time weekdays). Most subreddits have submission patterns which fit accordingly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/reddit_subreddit_prop.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;But what&amp;rsquo;s interesting are the subreddits which &lt;em&gt;deviate&lt;/em&gt; from that standard. Gaming subreddits (&lt;a href=&quot;https://www.reddit.com/r/DestinyTheGame&quot;&gt;/r/DestinyTheGame&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/Overwatch&quot;&gt;/r/Overwatch&lt;/a&gt;) have short activity after a Tuesday game update/patch, game &lt;em&gt;communication&lt;/em&gt; subreddits (&lt;a href=&quot;https://www.reddit.com/r/Fireteams&quot;&gt;/r/Fireteams&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/RocketLeagueExchange&quot;&gt;/r/RocketLeagueExchange&lt;/a&gt;) are more active &lt;em&gt;outside&lt;/em&gt; of work hours as they assume you are playing the game at the time, and Not-Safe-For-Work subreddits (/r/dirtykikpals, /r/gonewild) are incidentally less active during work hours and more active late-night than other subreddits.&lt;/p&gt;

&lt;p&gt;Whenever you make a submission to Reddit, the submission appears in the subreddit&amp;rsquo;s &lt;code&gt;/new&lt;/code&gt; queue of the most recent submissions, where hopefully kind souls will find your submission and upvote it if it&amp;rsquo;s good.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/reddit_new.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;However, if it falls off the first page of the &lt;code&gt;/new&lt;/code&gt; queue, your submission might be as good as dead. As a result, there&amp;rsquo;s an element of game theory to timing your submission if you want it to not become another 1-point submission. Is it better to submit during peak hours when more users may see the submission before it falls off of &lt;code&gt;/new&lt;/code&gt;? Is it better to submit &lt;em&gt;before&lt;/em&gt; peak usage since there will be less competition, then continue the momentum once it hits the front page?&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a look at the median post performance at each given time slot for top subreddits:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/reddit_subreddit_hr_doy.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As the earlier distribution chart implied, the median score is around 1-2 for most subreddits, and that&amp;rsquo;s consistent across all time slots. Some subreddits with higher medians like /r/me_irl do appear to have a &lt;em&gt;slight&lt;/em&gt; benefit when posting before peak activity. When focusing on subreddits with high overall median scores, the difference is more explicit.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/reddit_subreddit_highmedian.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Subreddits like /r/PrequelMemes and /r/The_Donald &lt;em&gt;definitely&lt;/em&gt; have better performance on average when made before peak activity! Posting before peak usage &lt;em&gt;does&lt;/em&gt; appear to be a viable strategy, however for the majority of subreddits it doesn&amp;rsquo;t make much of a difference.&lt;/p&gt;

&lt;h2&gt;Submission Titles&lt;/h2&gt;

&lt;p&gt;Each Reddit subreddit has their own vocabulary and topics of discussion. Let&amp;rsquo;s break down text by subreddit by looking at the 75th percentile for score on posts containing a given two-word phrase:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/reddit_subreddit_topbigrams.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The one trend consistent across all subreddits is the effectiveness of first-person pronouns (&lt;em&gt;I/my&lt;/em&gt;) and original content (&lt;em&gt;fan art&lt;/em&gt;). Other than that, the vocabulary and sentiment for successful posts is very specific to the subreddit and culture is represents; no universal guaranteed-success memes.&lt;/p&gt;

&lt;h2&gt;Can Deep Learning Predict Post Performance?&lt;/h2&gt;

&lt;p&gt;Some might think &amp;ldquo;oh hey, this is an arbitrary statistical problem, you can just build an AI to solve it!&amp;rdquo; So, for the sake of argument, I did.&lt;/p&gt;

&lt;p&gt;Instead of using Reddit data for building a deep learning model, we&amp;rsquo;ll use data from &lt;a href=&quot;https://news.ycombinator.com&quot;&gt;Hacker News&lt;/a&gt;, another link aggregator similar to Reddit with a strong focus on technology and startup entrepreneurship. The distribution of scores on posts, submission timings, upvoting, and front page ranking systems are all the same as on Reddit.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/hn.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The titles on Hacker News submissions are also shorter (80 characters max vs. Reddit&amp;rsquo;s 300 character max) and in concise English (no memes/shitposts allowed), which should help the model learn the title syntax and identify high-impact keywords easier. Like Reddit, the score data is super-skewed with most HN submissions at 1-2 points, and typical model training will quickly converge but try to predict that &lt;em&gt;every&lt;/em&gt; submission has a score of 1, which isn&amp;rsquo;t helpful!&lt;/p&gt;

&lt;p&gt;By constructing a model employing &lt;em&gt;many&lt;/em&gt; deep learning tricks with &lt;a href=&quot;https://keras.io&quot;&gt;Keras&lt;/a&gt;/&lt;a href=&quot;https://www.tensorflow.org&quot;&gt;TensorFlow&lt;/a&gt; to prevent model cheating and training on &lt;em&gt;hundreds of thousands&lt;/em&gt; of HN submissions (using post title, day-of-week, hour, and link domain like &lt;code&gt;github.com&lt;/code&gt; as model features), the model does converge and finds some signal among the noise (training R&lt;sup&gt;2&lt;/sup&gt; ~ 0.55 when trained for 50 epochs). However, it fails to offer any valuable predictions on new, unseen posts (test R&lt;sup&gt;2&lt;/sup&gt; &lt;em&gt;&amp;lt; 0.00&lt;/em&gt;) because it falls into the same exact human biases regarding titles: it saw submissions with titles that did very well during training, but can&amp;rsquo;t isolate the random chance why X and Y submissions are similar but X goes viral while Y does not.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/hn_test.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve made the Keras/TensorFlow model training code available in &lt;a href=&quot;https://www.kaggle.com/minimaxir/hacker-news-submission-score-predictor/notebook&quot;&gt;this Kaggle Notebook&lt;/a&gt; if you want to fork it and try to improve the model.&lt;/p&gt;

&lt;h2&gt;Other Potential Modeling Factors&lt;/h2&gt;

&lt;p&gt;The deep learning model above makes optimistic assumptions about the underlying data, including that each post behaves independently, and the included features are the sole features which determine the score. These assumptions are questionable.&lt;/p&gt;

&lt;p&gt;The simple model forgoes the content of the submission itself, which is hard to retrieve for hundreds of thousands of data points. On Hacker News that&amp;rsquo;s mostly OK since most submissions are links/articles which accurately correlate to the content, although occasionally there are idiosyncratic short titles which do the opposite. On Reddit, obviously looking at content is necessary for image/video-oriented subreddits, which is hard to gather and analyze at scale.&lt;/p&gt;

&lt;p&gt;A very important concept of post performance is &lt;em&gt;momentum&lt;/em&gt;. A post having a high score is a positive signal in itself, which begets more votes (a famous Reddit problem is brigading from /r/all which can cause submission scores to skyrocket). If the front page of a subreddit has a large number of high-performing posts, they might also suppress posts coming out of the &lt;code&gt;/new&lt;/code&gt; queue because the score threshold is much higher. A simple model may not be able to capture these impacts; the model would need to incorporate the &lt;em&gt;state of the front page&lt;/em&gt; at the time of posting.&lt;/p&gt;

&lt;p&gt;Some also try to manipulate upvotes. Reddit became famous for adding the rule &amp;ldquo;asking for upvotes is a violation of intergalactic law&amp;rdquo; to their &lt;a href=&quot;https://www.reddithelp.com/en/categories/rules-reporting/account-and-community-restrictions/what-constitutes-vote-cheating-or&quot;&gt;Content Policy&lt;/a&gt;, although some subreddits do it anyway &lt;a href=&quot;https://www.reddit.com/r/TheoryOfReddit/comments/5qqrod/for_years_reddit_told_us_that_saying_upvote_this/&quot;&gt;without consequence&lt;/a&gt;. On Reddit, obvious spam posts can be downvoted to immediately counteract illicit upvotes. Hacker News has a &lt;a href=&quot;https://news.ycombinator.com/newsfaq.html&quot;&gt;similar don&amp;rsquo;t-upvote rule&lt;/a&gt;, although there aren&amp;rsquo;t downvotes, just a flagging mechanism which quickly neutralizes spam/misleading posts. In general, there&amp;rsquo;s no &lt;em&gt;legitimate&lt;/em&gt; reason to highlight your own submission immediately after its posted (except for Reddit&amp;rsquo;s AMAs). Fortunately, gaming the system is less impactful on Reddit and Hacker News due to their sheer size and countermeasures, but it&amp;rsquo;s a good example of potential user behavior that makes modeling post performance difficult, and hopefully link aggregators of the future aren&amp;rsquo;t susceptible to such shenanigans.&lt;/p&gt;

&lt;h2&gt;Do We Really to Predict Post Score?&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s say you are submitting original content to Reddit or your own tech project to Hacker News. More points means a higher ranking means more exposure for your link, right? Not exactly. As noted from Reddit/HN screenshots above, the scores of popular submissions are all over the place ranking-wise, having been affected by age penalties.&lt;/p&gt;

&lt;p&gt;In practical terms, from my own purely anecdotal experience, submissions at a top ranking receive &lt;em&gt;substantially&lt;/em&gt; more clickthroughs despite being spatially close on the page to others.&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&amp;hellip;and now traffic at #3.&lt;br&gt;&lt;br&gt;Placement is absurdly important for search engines/social media sites. Difference between #1 and #3 is dramatic. &lt;a href=&quot;https://t.co/nGjWJBx6dU&quot;&gt;pic.twitter.com/nGjWJBx6dU&lt;/a&gt;&lt;/p&gt;&amp;mdash; Max Woolf (@minimaxir) &lt;a href=&quot;https://twitter.com/minimaxir/status/877219784907149316?ref_src=twsrc%5Etfw&quot;&gt;June 20, 2017&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;https://twitter.com/minimaxir/status/877219784907149316&quot;&gt;that case&lt;/a&gt;, falling from #1 to #3 &lt;em&gt;immediately halved&lt;/em&gt; the referral traffic coming from Hacker News.&lt;/p&gt;

&lt;p&gt;Therefore, an ideal link aggregator predictive model to maximize  clicks should try to predict the &lt;em&gt;rank&lt;/em&gt; of a submission (max rank, average rank over &lt;em&gt;n&lt;/em&gt; period, etc.), not necessarily the score it receives. You could theoretically create a model by making a snapshot of a Reddit subreddit/front page of Hacker News every minute or so which includes the post position at the time of the snapshot. As mentioned earlier, the snapshots can also be used as a model feature to identify whether the front page is active or stale. Unfortunately, snapshots can&amp;rsquo;t be retrieved retroactively, and both storing, processing, and analyzing snapshots at scale is a difficult and &lt;em&gt;expensive&lt;/em&gt; feat of data engineering.&lt;/p&gt;

&lt;p&gt;Presumably Reddit&amp;rsquo;s data scientists would be incorporating submission position as a part of their data analytics and modeling, but after inspecting what&amp;rsquo;s sent to Reddit&amp;rsquo;s servers when you perform an action like upvoting, I wasn&amp;rsquo;t able to find a sent position value when upvoting from the feed: only the post score and post upvote percentage at the time of the action were sent.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/modeling-link-aggregators/chrome.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In this example, I upvoted the &lt;code&gt;Fact are facts&lt;/code&gt; submission at position #5: we&amp;rsquo;d expect a value between &lt;code&gt;3&lt;/code&gt; and &lt;code&gt;5&lt;/code&gt; be sent with the post metadata within the analytics payload, but that&amp;rsquo;s not the case.&lt;/p&gt;

&lt;p&gt;Optimizing ranking instead of a tangible metric or classification accuracy is a relatively underdiscussed field of modern data science (besides &lt;a href=&quot;https://en.wikipedia.org/wiki/Search_engine_optimization&quot;&gt;SEO&lt;/a&gt; for getting the top spot on a Google search), and it would be interesting to dive deeper into it for other applications.&lt;/p&gt;

&lt;h2&gt;In the future&lt;/h2&gt;

&lt;p&gt;The moral of this post is that you should not take it personally if a submission fails to hit the front page. It doesn&amp;rsquo;t necessarily mean it&amp;rsquo;s bad. Conversely, if a post does well, don’t assume that similar posts will do just as well. There&amp;rsquo;s a lot of quality content that falls through the cracks due to dumb luck. Fortunately, both Reddit and Hacker News allow reposts, which helps alleviate this particular problem.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s still a lot that can be done to more deterministically predict the behavior of these algorithmic feeds. There&amp;rsquo;s also room to help make these link aggregators more &lt;em&gt;fair&lt;/em&gt;. Unfortunately, there&amp;rsquo;s even more undiscovered ways to game these algorithms, and we&amp;rsquo;ll see how things play out.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view the BigQuery queries used to get the Reddit and Hacker News data, plus the R and ggplot2 used to create the data visualizations, in &lt;a href=&quot;http://minimaxir.com/notebooks/modeling-link-aggregators/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/code used for this post in &lt;a href=&quot;https://github.com/minimaxir/modeling-link-aggregators&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Sep 2018 09:15:00 -0700</pubDate>
        <link>https://minimaxir.com/2018/09/modeling-link-aggregators/</link>
        <guid isPermaLink="true">https://minimaxir.com/2018/09/modeling-link-aggregators/</guid>
        
        
        <category>Data Visualization</category>
        
      </item>
    
      <item>
        <title>Analyzing IMDb Data The Intended Way, with R and ggplot2</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.imdb.com&quot;&gt;IMDb&lt;/a&gt;, the Internet Movie Database, has been a popular source for data analysis and visualizations over the years. The combination of user ratings for movies and detailed movie metadata have always been fun to &lt;a href=&quot;http://minimaxir.com/2016/01/movie-revenue-ratings/&quot;&gt;play with&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/movie-revenue-ratings/box-office-rating-5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;There are a number of tools to help get IMDb data, such as &lt;a href=&quot;https://github.com/alberanid/imdbpy&quot;&gt;IMDbPY&lt;/a&gt;, which makes it easy to programmatically scrape IMDb by pretending it&amp;rsquo;s a website user and extracting the relevant data from the page&amp;rsquo;s HTML output. While it &lt;em&gt;works&lt;/em&gt;, web scraping public data is a gray area in terms of legality; many large websites have a Terms of Service which forbids scraping, and can potentially send a DMCA take-down notice to websites redistributing scraped data.&lt;/p&gt;

&lt;p&gt;IMDb has &lt;a href=&quot;https://help.imdb.com/article/imdb/general-information/can-i-use-imdb-data-in-my-software/G5JTRESSHJBBHTGX#&quot;&gt;data licensing terms&lt;/a&gt; which forbid scraping and require an attribution in the form of a &lt;strong&gt;Information courtesy of IMDb (http://www.imdb.com). Used with permission.&lt;/strong&gt; statement, and has also &lt;a href=&quot;https://www.kaggle.com/tmdb/tmdb-movie-metadata/home&quot;&gt;DMCAed a Kaggle IMDb dataset&lt;/a&gt; to hone the point. &lt;/p&gt;

&lt;p&gt;However, there is good news! IMDb publishes an &lt;a href=&quot;https://www.imdb.com/interfaces/&quot;&gt;official dataset&lt;/a&gt; for casual data analysis! And it&amp;rsquo;s now very accessible, just choose a dataset and download (now with no hoops to jump through), and the files are in the standard &lt;a href=&quot;https://en.wikipedia.org/wiki/Tab-separated_values&quot;&gt;TSV format&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/datasets.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The uncompressed files are pretty large; not &amp;ldquo;big data&amp;rdquo; large (it fits into computer memory), but Excel will explode if you try to open them in it. You have to play with the data &lt;em&gt;smartly&lt;/em&gt;, and both &lt;a href=&quot;https://www.r-project.org&quot;&gt;R&lt;/a&gt; and &lt;a href=&quot;https://ggplot2.tidyverse.org/reference/index.html&quot;&gt;ggplot2&lt;/a&gt; have neat tricks to do just that.&lt;/p&gt;

&lt;h2&gt;First Steps&lt;/h2&gt;

&lt;p&gt;R is a popular programming language for statistical analysis. One of the most popular series of external packages is the &lt;code&gt;tidyverse&lt;/code&gt; package, which automatically imports the &lt;code&gt;ggplot2&lt;/code&gt; data visualization library and other useful packages which we&amp;rsquo;ll get to one-by-one. We&amp;rsquo;ll also use &lt;code&gt;scales&lt;/code&gt; which we&amp;rsquo;ll use later for prettier number formatting. First we&amp;rsquo;ll load these packages:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tidyverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And now we can load a TSV downloaded from IMDb using the &lt;code&gt;read_tsv&lt;/code&gt; function from &lt;code&gt;readr&lt;/code&gt; (a tidyverse package), which does what the name implies, at a much faster speed than base R (+ a couple other parameters to handle data encoding). Let&amp;rsquo;s start with the &lt;code&gt;ratings&lt;/code&gt; file:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'title.ratings.tsv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\\N&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quote&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can preview what&amp;rsquo;s in the loaded data using &lt;code&gt;dplyr&lt;/code&gt; (a tidyverse package), which is what we&amp;rsquo;ll be using to manipulate data for this analysis. dplyr allows you to pipe commands, making it easy to create a sequence of manipulation commands. For now, we&amp;rsquo;ll use &lt;code&gt;head()&lt;/code&gt;, which displays the top few rows of the data frame.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/ratings.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Each of the &lt;strong&gt;873k rows&lt;/strong&gt; corresponds to a single movie, an ID for the movie, its average rating (from 1 to 10), and the number of votes which contribute to that average. Since we have two numeric variables, why not test out ggplot2 by creating a scatterplot mapping them? ggplot2 takes in a data frame and names of columns as aesthetics, then you specify what type of shape to plot (a &amp;ldquo;geom&amp;rdquo;). Passing the plot to &lt;code&gt;ggsave&lt;/code&gt; saves it as a standalone, high-quality data visualization.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numVotes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;averageRating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggsave&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;imdb-0.png&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/imdb-0.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Here is nearly &lt;em&gt;1 million&lt;/em&gt; points on a single chart; definitely don&amp;rsquo;t try to do that in Excel! However, it&amp;rsquo;s not a &lt;em&gt;useful&lt;/em&gt; chart since all the points are opaque and we&amp;rsquo;re not sure what the spatial density of points is. One approach to fix this issue is to create a heat map of points, which ggplot can do natively with &lt;code&gt;geom_bin2d&lt;/code&gt;. We can color the heat map with the &lt;a href=&quot;https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html&quot;&gt;viridis&lt;/a&gt; colorblind-friendly palettes &lt;a href=&quot;https://ggplot2.tidyverse.org/reference/scale_viridis.html&quot;&gt;just introduced&lt;/a&gt; into ggplot2. We should also tweak the axes; the x-axis should be scaled logarithmically with &lt;code&gt;scale_x_log10&lt;/code&gt; since there are many movies with high numbers of votes and we can format those numbers with the &lt;code&gt;comma&lt;/code&gt; function from the &lt;code&gt;scales&lt;/code&gt; package (we can format the scale with &lt;code&gt;comma&lt;/code&gt; too). For the y-axis, we can add explicit number breaks for each rating; R can do this neatly by setting the breaks to &lt;code&gt;1:10&lt;/code&gt;. Putting it all together: &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numVotes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;averageRating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_bin2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_x_log10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;comma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;breaks&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_fill_viridis_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;comma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/imdb-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Not bad, although it unfortunately confirms that IMDb follows a &lt;a href=&quot;https://tvtropes.org/pmwiki/pmwiki.php/Main/FourPointScale&quot;&gt;Four Point Scale&lt;/a&gt; where average ratings tend to fall between 6 — 9.&lt;/p&gt;

&lt;h2&gt;Mapping Movies to Ratings&lt;/h2&gt;

&lt;p&gt;You may be asking &amp;ldquo;which ratings correspond to which movies?&amp;rdquo; That&amp;rsquo;s what the &lt;code&gt;tconst&lt;/code&gt; field is for. But first, let&amp;rsquo;s load the  title data from &lt;code&gt;title.basics.tsv&lt;/code&gt; into &lt;code&gt;df_basics&lt;/code&gt; and take a look as before.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_basics&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'title.basics.tsv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\\N&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quote&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/basics1.png&quot; alt=&quot;&quot;&gt;
&lt;img src=&quot;/img/imdb-data-analysis/basics2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;We have some neat movie metadata. Notably, this table has a &lt;code&gt;tconst&lt;/code&gt; field as well. Therefore, we can &lt;em&gt;join&lt;/em&gt; the two tables together, adding the movie information to the corresponding row in the rating table (in this case, a left join is more appropriate than an inner/full join)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_basics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Runtime minutes sounds interesting. Could there be a relationship between the length of a movie and its average rating on IMDb? Let&amp;rsquo;s make a heat map plot again, but with a few tweaks. With the new metadata, we can &lt;code&gt;filter&lt;/code&gt; the table to remove bad points; let&amp;rsquo;s keep movies only (as IMDb data also contains &lt;em&gt;television show data&lt;/em&gt;), with a runtime &amp;lt; 3 hours, and which have received atleast 10 votes by users to remove extraneous movies). X-axis should be tweaked to display the minutes-values in hours. The fill viridis palette can be changed to another one in the family (I personally like &lt;code&gt;inferno&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;More importantly, let&amp;rsquo;s discuss plot theming. If you want a minimalistic theme, add a &lt;code&gt;theme_minimal&lt;/code&gt; to the plot, and you can pass a &lt;code&gt;base_family&lt;/code&gt; to change the default font on the plot and a &lt;code&gt;base_size&lt;/code&gt; to change the font size. The &lt;code&gt;labs&lt;/code&gt; function lets you add labels to the plot (which you should &lt;em&gt;always&lt;/em&gt; do); you have your &lt;code&gt;title&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt;, and &lt;code&gt;y&lt;/code&gt; parameters, but you can also add a &lt;code&gt;subtitle&lt;/code&gt;, a &lt;code&gt;caption&lt;/code&gt; for attribution, and a &lt;code&gt;color&lt;/code&gt;/&lt;code&gt;fill&lt;/code&gt; to name the scale. Putting it all together:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runtimeMinutes&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;180&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titleType&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;movie&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numVotes&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runtimeMinutes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;averageRating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_bin2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_x_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;breaks&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;180&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;breaks&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_fill_viridis_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;inferno&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;comma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme_minimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_family&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Source Sans Pro&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_size&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Relationship between Movie Runtime and Average Mobie Rating&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
               &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subtitle&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Data from IMDb retrieved July 4th, 2018&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
               &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Runtime (Hours)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
               &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Average User Rating&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
               &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;caption&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Max Woolf — minimaxir.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
               &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;# Movies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/imdb-2b.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Now that&amp;rsquo;s pretty nice-looking for only a few lines of code! Albeit unhelpful, as there doesn&amp;rsquo;t appear to be a correlation.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(Note: for the rest of this post, the theming/labels code will be omitted for convenience)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;How about movie ratings vs. the year the movie was made? It&amp;rsquo;s a similar plot code-wise to the one above (one perk about &lt;code&gt;ggplot2&lt;/code&gt; is that there&amp;rsquo;s no shame in reusing chart code!), but we can add a &lt;code&gt;geom_smooth&lt;/code&gt;, which adds a nonparametric trendline with confidence bands for the trend; since we have a large amount of data, the bands are very tight. We can also fix the problem of &amp;ldquo;empty&amp;rdquo; bins by setting the color fill scale to logarithmic scaling. And since we&amp;rsquo;re adding a black trendline, let&amp;rsquo;s change the viridis palette to &lt;code&gt;plasma&lt;/code&gt; for better contrast.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titleType&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;movie&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numVotes&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;averageRating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_bin2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;black&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_x_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_y_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;breaks&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_fill_viridis_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;plasma&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;comma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trans&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'log10'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/imdb-4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, this trend hasn&amp;rsquo;t changed much either, although the presence of average ratings outside the Four Point Scale has increased over time.&lt;/p&gt;

&lt;h2&gt;Mapping Lead Actors to Movies&lt;/h2&gt;

&lt;p&gt;Now that we have a handle on working with the IMDb data, let&amp;rsquo;s try playing with the larger datasets. Since they take up a lot of computer memory, we only want to persist data we actually might use. After looking at the schema provided with the official datasets, the only really useful metadata about the actors is their birth year, so let&amp;rsquo;s load that, but only keep both actors/actresses (using the fast &lt;code&gt;str_detect&lt;/code&gt; function from &lt;code&gt;stringr&lt;/code&gt;, another tidyverse package) and the relevant fields.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_actors&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'name.basics.tsv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\\N&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quote&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_detect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;primaryProfession&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;actor|actress&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nconst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;primaryName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birthYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/actor.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The principals dataset, the large 1.28GB TSV, is the most interesting. It&amp;rsquo;s an unnested list of the credited persons in each movie, with an &lt;code&gt;ordering&lt;/code&gt; indicating their rank (where &lt;code&gt;1&lt;/code&gt; means first, &lt;code&gt;2&lt;/code&gt; means second, etc.).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/principals.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;For this analysis, let&amp;rsquo;s only look at the &lt;strong&gt;lead actors/actresses&lt;/strong&gt;; specifically, for each movie (identified by the &lt;code&gt;tconst&lt;/code&gt; value), filter the dataset to where the &lt;code&gt;ordering&lt;/code&gt; value is the lowest (in this case, the person at rank &lt;code&gt;1&lt;/code&gt; may not necessarily be an actor/actress).  &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_principals&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_tsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'title.principals.tsv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;\\N&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quote&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str_detect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;actor|actress&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tconst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nconst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tconst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordering&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ordering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Both datasets have a &lt;code&gt;nconst&lt;/code&gt; field, so let&amp;rsquo;s join them together. And then join &lt;em&gt;that&lt;/em&gt; to the ratings table earlier via &lt;code&gt;tconst&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_principals&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_principals&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_actors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left_join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_principals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we have a fully denormalized dataset in &lt;code&gt;df_ratings&lt;/code&gt;. Since we now have the movie release year and the birth year of the lead actor, we can now infer &lt;em&gt;the age of the lead actor at the movie release&lt;/em&gt;. With that goal, filter out the data on the criteria we&amp;rsquo;ve used for earlier data visualizations, plus only keeping rows which have an actor&amp;rsquo;s birth year.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_ratings_movies&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titleType&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;movie&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;is.na&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birthYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numVotes&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_lead&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;birthYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/denorm1.png&quot; alt=&quot;&quot;&gt;
&lt;img src=&quot;/img/imdb-data-analysis/denorm2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Plotting Ages&lt;/h2&gt;

&lt;p&gt;Age discrimination in movie casting has been a recurring issue in Hollywood; in fact, in 2017 &lt;a href=&quot;https://www.hollywoodreporter.com/thr-esq/judge-pauses-enforcement-imdb-age-censorship-law-978797&quot;&gt;a law was signed&lt;/a&gt; to force IMDb to remove an actor&amp;rsquo;s age upon request, which in February 2018 was &lt;a href=&quot;https://www.hollywoodreporter.com/thr-esq/californias-imdb-age-censorship-law-declared-unconstitutional-1086540&quot;&gt;ruled to be unconstitutional&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Have the ages of movie leads changed over time? For this example,  we&amp;rsquo;ll use a &lt;a href=&quot;https://ggplot2.tidyverse.org/reference/geom_ribbon.html&quot;&gt;ribbon plot&lt;/a&gt; to plot the ranges of ages of movie leads. A simple way to do that is, for each year, calculate the 25th &lt;a href=&quot;https://en.wikipedia.org/wiki/Percentile&quot;&gt;percentile&lt;/a&gt; of the ages, the 50th percentile (i.e. the median), and the 75th percentile, where the 25th and 75th percentiles are the ribbon bounds and the line represents the median.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_actor_ages&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings_movies&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low_age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;med_age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;high_age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Plotting it with ggplot2 is surprisingly simple, although you need to use different y aesthetics for the ribbon and the overlapping line.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_actor_ages&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1920&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_ribbon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;high_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;med_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/imdb-8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Turns out that in the 2000&amp;rsquo;s, the median age of lead actors  started to &lt;em&gt;increase&lt;/em&gt;? Both the upper and lower bounds increased too. That doesn&amp;rsquo;t coalesce with the age discrimination complaints.&lt;/p&gt;

&lt;p&gt;Another aspect of these complaints is gender, as female actresses tend to be younger than male actors. Thanks to the magic of ggplot2 and dplyr, separating actors/actresses is relatively simple: add gender (encoded in &lt;code&gt;category&lt;/code&gt;) as a grouping variable, add it as a color/fill aesthetic in ggplot, and set colors appropriately (I recommend the &lt;a href=&quot;http://colorbrewer2.org/&quot;&gt;ColorBrewer&lt;/a&gt; qualitative palettes for categorical variables).&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_actor_ages_lead&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings_movies&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summarize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low_age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;med_age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;high_age&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;age_lead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;na.rm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_actor_ages_lead&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1920&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_ribbon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;high_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;med_age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_fill_brewer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Set1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_color_brewer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Set1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/imdb-9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s about a 10-year gap between the ages of male and female leads, and the gap doesn&amp;rsquo;t change overtime. But both start to rise at the same time.&lt;/p&gt;

&lt;p&gt;One possible explanation for this behavior is actor reuse: if Hollywood keeps casting the same actor/actresses, by construction the ages of the leads will start to steadily increase. Let&amp;rsquo;s verify that: with our list of movies and their lead actors, for each lead actor, order all their movies by release year, and add a ranking for the #th time that actor has been a lead actor. This is possible through the use of &lt;code&gt;row_number&lt;/code&gt; in dplyr, and &lt;a href=&quot;https://cran.r-project.org/web/packages/dplyr/vignettes/window-functions.html&quot;&gt;window functions&lt;/a&gt; like &lt;code&gt;row_number&lt;/code&gt; are data science&amp;rsquo;s most useful secret.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;df_ratings_movies_nth&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_ratings_movies&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nconst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startYear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mutate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nth_lead&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/row_number.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;One more ribbon plot later (w/ same code as above + custom y-axis breaks):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/imdb-data-analysis/imdb-12.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Huh. The median and upper-bound #th time has &lt;em&gt;dropped&lt;/em&gt; over time? Hollywood has been promoting more newcomers as leads? That&amp;rsquo;s not what I expected!&lt;/p&gt;

&lt;p&gt;More work definitely needs to be done in this area. In the meantime, the official IMDb datasets are a lot more robust than I thought they would be! And I only used a fraction of the datasets; the rest tie into TV shows, which are a bit messier. Hopefully you&amp;rsquo;ve seen a good taste of the power of R and ggplot2 for playing with big-but-not-big data!&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view the R and ggplot used to create the data visualizations in &lt;a href=&quot;http://minimaxir.com/notebooks/imdb-data-analysis/&quot;&gt;this R Notebook&lt;/a&gt;, which includes many visualizations not used in this post. You can also view the images/code used for this post in &lt;a href=&quot;https://github.com/minimaxir/imdb-data-analysis&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 16 Jul 2018 09:45:00 -0700</pubDate>
        <link>https://minimaxir.com/2018/07/imdb-data-analysis/</link>
        <guid isPermaLink="true">https://minimaxir.com/2018/07/imdb-data-analysis/</guid>
        
        
        <category>Data Visualization</category>
        
      </item>
    
      <item>
        <title>How to Quickly Train a Text-Generating Neural Network for Free</title>
        <description>&lt;p&gt;One of the more interesting applications of the neural network revolution is text generation. Most popular approaches are based off of Andrej Karpathy&amp;rsquo;s &lt;a href=&quot;https://github.com/karpathy/char-rnn&quot;&gt;char-rnn architecture&lt;/a&gt;/&lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;blog post&lt;/a&gt;, which teaches a recurrent neural network to be able to predict the next character in a sequence based on the previous &lt;em&gt;n&lt;/em&gt; characters. As a result, a sufficiently trained network can theoretically reproduce its input source material, but since properly-trained neural networks aren&amp;rsquo;t &lt;em&gt;perfect&lt;/em&gt;, the output can fall into a weird-but-good uncanny valley.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/text-neural-networks/textgenrnn_console.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Many internet tutorials for text-generation neural networks simply copy an existing char-rnn implementation while changing the input dataset. It&amp;rsquo;s one approach, but there&amp;rsquo;s an opportunity for improvement with modern deep learning tooling. Thanks to frameworks like &lt;a href=&quot;https://www.tensorflow.org&quot;&gt;TensorFlow&lt;/a&gt; and &lt;a href=&quot;https://github.com/keras-team/keras&quot;&gt;Keras&lt;/a&gt;, I built &lt;a href=&quot;https://github.com/minimaxir/textgenrnn&quot;&gt;textgenrnn&lt;/a&gt;, a &lt;a href=&quot;https://pypi.org/project/textgenrnn/#description&quot;&gt;Python package&lt;/a&gt; which abstracts the process of creating and training such char-rnns to a &lt;em&gt;few lines of code&lt;/em&gt;, with numerous model architecture and training improvements such as &lt;a href=&quot;http://minimaxir.com/2017/04/char-embeddings/&quot;&gt;character embeddings&lt;/a&gt;, attention-weighted averaging, and a decaying learning rate.&lt;/p&gt;

&lt;p&gt;A neat benefit of textgenrnn is that it can be easily used to train neural networks on a GPU very quickly, &lt;em&gt;for free&lt;/em&gt; using &lt;a href=&quot;https://colab.research.google.com/notebooks/welcome.ipynb&quot;&gt;Google Colaboratory&lt;/a&gt;. I&amp;rsquo;ve &lt;a href=&quot;https://drive.google.com/file/d/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK/view?usp=sharing&quot;&gt;created a notebook&lt;/a&gt; which lets you train your own network and generate text whenever you want with just a few clicks!&lt;/p&gt;

&lt;h2&gt;Your First Text-Generating Neural Network&lt;/h2&gt;

&lt;p&gt;Colaboratory is a notebook environment similar to &lt;a href=&quot;http://jupyter.org&quot;&gt;Jupyter Notebooks&lt;/a&gt; used in other data science projects. However, Colaboratory notebooks are hosted in a short term virtual machine, with 2 vCPUs, 13GB memory, and a K80 GPU attached. For free. Normally, this configuration would &lt;a href=&quot;https://cloud.google.com/compute/pricing&quot;&gt;cost&lt;/a&gt; $0.57/hr on Google Compute Engine; it sounds low, but adds up when you need to train model(s) for hours to get good results.&lt;/p&gt;

&lt;p&gt;First, I recommend copying the notebook to your own Drive so it&amp;rsquo;ll always be there (and switch to using Google Chrome if you aren&amp;rsquo;t). The Colaboratory VM contains Python 3 and common Python packages for machine learning such as TensorFlow. But you can install more packages directly in the notebook. Like textgenrnn! Just run this cell by clicking into the cell and click the &amp;ldquo;play&amp;rdquo; button (or use Shift + Enter) and it&amp;rsquo;ll take care of the rest:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/text-neural-networks/pip.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;When training a new model, textgenrnn allows you to specify the size and complexity of the neural network with a wide variety of parameters:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/text-neural-networks/config.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s keep these default parameters for now, so run that cell to load them into memory. Run the next cell, which prompts you to upload a file. &lt;em&gt;Any text file should work&lt;/em&gt;, even large text files! For this example, we&amp;rsquo;ll use a 1.1MB text file of Shakespeare plays also &lt;a href=&quot;https://github.com/karpathy/char-rnn/tree/master/data/tinyshakespeare&quot;&gt;used in the char-rnn demos&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/text-neural-networks/upload.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The next cell initializes an instance of textgenrnn and begins training a custom new text-generating neural network!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/text-neural-networks/train.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;textgenrnn automatically processes the input text into character sequences ready to train the network. After every 2 epochs (a full pass through the data), the network will generate sample text at different temperatures, which represent the &amp;ldquo;creativity&amp;rdquo; of the text (i.e. it allows the model to make increasingly suboptimal predictions, which can cause hilarity to ensue). I typically like generating text at a temperature of 0.5, but for very well-trained models, you can go up to 1.0.&lt;/p&gt;

&lt;p&gt;The quick model training speed comes from the VM&amp;rsquo;s GPU, which can perform the necessary mathematical operations much faster than with a CPU. However, in the case of recurrent neural networks, Keras recently added a &lt;a href=&quot;https://keras.io/layers/recurrent/#cudnnlstm&quot;&gt;CuDNN implementation of RNNs&lt;/a&gt; like LSTMs, which can easily tap into the GPU-native code more easily and gain a &lt;em&gt;massive&lt;/em&gt; speed boost (&lt;a href=&quot;http://minimaxir.com/2017/11/benchmark-gpus/&quot;&gt;about &lt;em&gt;7x as fast&lt;/em&gt;&lt;/a&gt;) compared to previous implementations! In all, for this example dataset and model architecture, training on a GPU took 5-6 minutes an epoch, while on a modern CPU, training took &lt;em&gt;1 hour and 24 minutes&lt;/em&gt; an epoch, a &lt;strong&gt;14x speedup&lt;/strong&gt; on the GPU!&lt;/p&gt;

&lt;p&gt;After training is complete, running the next cell will download three files: a &lt;code&gt;weights&lt;/code&gt; file, a &lt;code&gt;vocabulary&lt;/code&gt; file, and a &lt;code&gt;config&lt;/code&gt; file that are all needed to regenerate your model elsewhere.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/text-neural-networks/download.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;For example, on your own personal computer. Just install textgenrnn + TensorFlow by inputting &lt;code&gt;pip3 install textgenrnn tensorflow&lt;/code&gt; into a terminal, change to the directory where the downloaded files are located, run &lt;code&gt;python3&lt;/code&gt;, and load the model using:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;textgenrnn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textgenrnn&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;textgen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;textgenrnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'colaboratory_weights.hdf5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;vocab_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'colaboratory_vocab.json'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;config_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'colaboratory_config.json'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that&amp;rsquo;s that! No GPU necessary if you&amp;rsquo;re just generating text. You can generate samples (like during training) using &lt;code&gt;textgen.generate_samples()&lt;/code&gt;, generate a ton of samples at any temperature you like to a file using &lt;code&gt;textgen.generate_to_file()&lt;/code&gt;, or incorporate a generated text into a Python script (e.g. a Twitter bot) using &lt;code&gt;textgen.generate(1, return_as_list=True)[0]&lt;/code&gt; to store a text as a variable. You can view more of textgenrnn&amp;rsquo;s functions and capabilities in &lt;a href=&quot;https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb&quot;&gt;this demo Jupyter Notebook&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s some Shakespeare generated with a 50-minute-trained model at a temperature of 0.5:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;LUCENTIO:
And then shall good grave to my wife thee;
Thou would the cause the brieved to me,
And let the place and then receives:
The rest you the foren to my ways him child,
And marry that will be a parties and so set me that be deeds
And then the heart and be so shall make the most as he and stand of seat.

GLOUCESTER:
Your father and madam, or shall for the people
And dead to make the truth, or a business
As we brother to the place her great the truth;
And that which to the smaster and her father,
I am I was see the sun have to the royal true.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Not too bad, and it&amp;rsquo;s even close to &lt;a href=&quot;https://en.wikipedia.org/wiki/Iambic_pentameter&quot;&gt;iambic pentameter&lt;/a&gt;!&lt;/p&gt;

&lt;h2&gt;Tweaking the Model&lt;/h2&gt;

&lt;p&gt;The most important model configuration options above are &lt;code&gt;rnn_size&lt;/code&gt; and &lt;code&gt;rnn_layers&lt;/code&gt;: these determine the complexity of the network. Typically, you&amp;rsquo;ll see networks in tutorials be a single 128-cell or 256-cell network. However, textgenrnn&amp;rsquo;s architecture is slightly different as it has an attention layer which incorporates &lt;em&gt;all&lt;/em&gt; the preceding model layers. As a result, it&amp;rsquo;s  much better to go deeper than wider (e.g. 4x128 is better than 1x512) unless you have a very large amount of text (&amp;gt;10MB). &lt;code&gt;rnn_bidirectional&lt;/code&gt; controls whether the recurrent neural network is bidirectional, that is, it processes  the previous characters both forward &lt;em&gt;and&lt;/em&gt; backward (which works great if text follows specific rules, like Shakespeare&amp;rsquo;s character headings). &lt;code&gt;max_length&lt;/code&gt; determines the maximum number of characters for the network to use to predict the next character, which should be increased to let the network learn longer sequences, or decrease for shorter sequences.&lt;/p&gt;

&lt;p&gt;Training has a few helpful options as well. &lt;code&gt;num_epochs&lt;/code&gt; determines the number of full passes of the data; this can be tweaked if you want to train the model even more. &lt;code&gt;batch_size&lt;/code&gt; determines the number of model sequences to train in a step: typically, batch size for deep learning models is 32 or 128, but with a GPU, you can get a speed increase by saturating it with the given 1024 default. &lt;code&gt;train_size&lt;/code&gt; determines the proportion of character samples to train; setting it &lt;code&gt;&amp;lt; 1.0&lt;/code&gt; both speeds up each epoch, and prevents the model from cheating and being able to learn sequences verbatim. (You can set &lt;code&gt;&amp;#39;validation&amp;#39;: True&lt;/code&gt; to run the model on the unused data after each epoch to see if the model is overfitting).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s try playing with the parameters more on a new text dataset.&lt;/p&gt;

&lt;h2&gt;Word-Level Text Generation With Reddit Data&lt;/h2&gt;

&lt;p&gt;You might be asking &amp;ldquo;how do you obtain text data&amp;rdquo;? The popular text-generation use cases like lyric generation and movie scripts are copyright-protected so they&amp;rsquo;re harder to find, and even then, it might not be enough text data to train a new model upon (you typically want atleast 100,000 characters).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.reddit.com&quot;&gt;Reddit&lt;/a&gt;, however, has &lt;em&gt;millions&lt;/em&gt; of submission titles which would be great to train for a model. I wrote a &lt;a href=&quot;https://github.com/minimaxir/subreddit-generator&quot;&gt;helper script&lt;/a&gt; to automatically download the top &lt;em&gt;n&lt;/em&gt; Reddit submissions from a given subreddit over a given period of time. If you choose subreddits with similar linguistic styles in their titles, the subreddits will even blend together! Let&amp;rsquo;s play with the Top 20,000 Submissions in 2017 from each of &lt;a href=&quot;https://www.reddit.com/r/politics/&quot;&gt;/r/politics&lt;/a&gt; and &lt;a href=&quot;https://www.reddit.com/r/technology/&quot;&gt;/r/technology&lt;/a&gt;, which results in a 3.3MB file: about 3x as much data as the Shakespeare plays.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/text-neural-networks/reddit_data.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;One last thing that textgenrnn can do that most char-rnn implementations can&amp;rsquo;t is generate a &lt;em&gt;word level&lt;/em&gt; model (thanks to Keras&amp;rsquo;s tokenizers), where the model uses the &lt;em&gt;n&lt;/em&gt; previous words/punctuation to predict the next word/punctuation. On the plus side, using only words prevents crazy typoes and since it predicts multiple &amp;ldquo;characters&amp;rdquo; at a time, &lt;code&gt;max_length&lt;/code&gt; can be reduced proportionally, dramatically speeding up training. There&amp;rsquo;s two downsides with this approach; since words are all lowercase and punctuation is its own token, the generated text cannot be immediately used without manual editing. Additionally, the model weights will be substantially larger than a character-level model since the word-level model has to store an embedding for each word (up to &lt;code&gt;max_words&lt;/code&gt;, which is 10,000 by default when the vocabulary size for a char-level model is 200-300).&lt;/p&gt;

&lt;p&gt;Another advantage of the Colaboratory notebook is that you can quickly adjust model parameters, upload a new file, and immediately start training it. We&amp;rsquo;ll set &lt;code&gt;&amp;#39;line_delimited&amp;#39;: True&lt;/code&gt; and &lt;code&gt;&amp;#39;rnn_bidirectional&amp;#39;: False&lt;/code&gt; since there aren&amp;rsquo;t specific rules. For word level training, let&amp;rsquo;s set &lt;code&gt;&amp;#39;word_level&amp;#39;: True&lt;/code&gt; and &lt;code&gt;&amp;#39;max_length&amp;#39;: 8&lt;/code&gt; to reflect the new training architecture. Since training length has been reduced to 1/5th, we can set &lt;code&gt;&amp;#39;num_epochs&amp;#39;: 50&lt;/code&gt; and &lt;code&gt;&amp;#39;gen_epoch&amp;#39;: 10&lt;/code&gt; to balance it out. Rerun the config cell to update parameters, upload the Reddit data file, and rerun training.&lt;/p&gt;

&lt;p&gt;The resulting model is much more well trained than the Shakespeare model, and here&amp;rsquo;s a few Reddit submission titles generated at a temperature of 1.0:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;report : 49 % of americans now believe all of the country ’ s effective

people like facebook like it ' s 650 of 1 %

uber accused of secretly - security popular service ( likely oklahoma )

equifax breach fallout : your salary is dead

sanders uses texas shooter ' s iphone sales

adobe videos will be used to sell the web

apple to hold cash for $ 500 service

fitbit just targeting solar energy

george bush ' s concept car ‘ goes for all the biggest controversy .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Those look pretty good, although they may need a little editing before posting on social media.&lt;/p&gt;

&lt;h2&gt;Followup&lt;/h2&gt;

&lt;p&gt;These examples only train the model for little time as a demo of textgenrnn&amp;rsquo;s fast learning; there&amp;rsquo;s nothing stopping you from increasing &lt;code&gt;num_epochs&lt;/code&gt; even more to further refine a model. However, from my experience, the training cell times out after &lt;strong&gt;4 hours&lt;/strong&gt;; set &lt;code&gt;num_epochs&lt;/code&gt; accordingly, although in my experience that&amp;rsquo;s all you need before the network converges.&lt;/p&gt;

&lt;p&gt;In practice, I used this Colaboratory notebook to train &lt;em&gt;many&lt;/em&gt; models for &lt;a href=&quot;https://www.reddit.com/r/SubredditNN/&quot;&gt;/r/SubredditNN&lt;/a&gt;, a Reddit subreddit where only text-generating neural network bots trained on other subreddits. And the results are very funny:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/text-neural-networks/subredditnn.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Although text generating neural networks aren&amp;rsquo;t at the point where they can &lt;a href=&quot;https://www.bloomberg.com/news/features/2018-05-17/i-tried-to-get-an-ai-to-write-this-story-paul-ford&quot;&gt;write entire articles by themselves&lt;/a&gt;, there are still many opportunities to use it just for fun! And thanks to textgenrnn, it&amp;rsquo;s easy, fast, and cost-effective for anyone to do! Let me know if you make any interesting neural networks with textgenrnn and this Notebook!&lt;/p&gt;
</description>
        <pubDate>Fri, 18 May 2018 09:00:00 -0700</pubDate>
        <link>https://minimaxir.com/2018/05/text-neural-networks/</link>
        <guid isPermaLink="true">https://minimaxir.com/2018/05/text-neural-networks/</guid>
        
        
        <category>Projects</category>
        
      </item>
    
      <item>
        <title>Visualizing One Million NCAA Basketball Shots</title>
        <description>&lt;p&gt;So &lt;a href=&quot;https://www.ncaa.com/march-madness&quot;&gt;March Madness&lt;/a&gt; is happing right now. In celebration, &lt;a href=&quot;https://www.google.com&quot;&gt;Google&lt;/a&gt; uploaded &lt;a href=&quot;https://console.cloud.google.com/launcher/details/ncaa-bb-public/ncaa-basketball&quot;&gt;massive basketball datasets&lt;/a&gt; from the &lt;a href=&quot;https://www.ncaa.com&quot;&gt;NCAA&lt;/a&gt; and &lt;a href=&quot;https://www.sportradar.com/&quot;&gt;Sportradar&lt;/a&gt; to &lt;a href=&quot;https://cloud.google.com/bigquery/&quot;&gt;BigQuery&lt;/a&gt; for anyone to query and experiment. After learning that the &lt;a href=&quot;https://www.reddit.com/r/bigquery/comments/82nz17/dataset_statistics_for_ncaa_mens_and_womens/&quot;&gt;dataset had location data&lt;/a&gt; on where basketball shots were made on the court, I played with it and a couple hours later, I created a decent heat map data visualization. The next day, I &lt;a href=&quot;https://www.reddit.com/r/dataisbeautiful/comments/837qnu/heat_map_of_1058383_basketball_shots_from_ncaa/&quot;&gt;posted it&lt;/a&gt; to Reddit&amp;rsquo;s &lt;a href=&quot;https://www.reddit.com/r/dataisbeautiful&quot;&gt;/r/dataisbeautiful subreddit&lt;/a&gt; where it earned about &lt;strong&gt;40,000 upvotes&lt;/strong&gt;. (!?)&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s dig a little deeper. Although visualizing basketball shots has been &lt;a href=&quot;http://www.slate.com/blogs/browbeat/2012/03/06/mapping_the_nba_how_geography_can_teach_players_where_to_shoot.html&quot;&gt;done&lt;/a&gt; &lt;a href=&quot;http://toddwschneider.com/posts/ballr-interactive-nba-shot-charts-with-r-and-shiny/&quot;&gt;before&lt;/a&gt;, this time we have access to an order of magnitude more public data to do some really cool stuff.&lt;/p&gt;

&lt;h2&gt;Full Court&lt;/h2&gt;

&lt;p&gt;The Sportradar play-by-play table on BigQuery &lt;code&gt;mbb_pbp_sr&lt;/code&gt; has more than 1 million NCAA men&amp;rsquo;s basketball shots since the 2013-2014 season, with more being added now during March Madness. Here&amp;rsquo;s a heat map of the locations where those shots were made on the full basketball court:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_count_attempts_unlog.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;We can clearly see at a glance that the majority of shots are made right in front of the basket. For 3-point shots, the center and the corners have higher numbers of shot attempts than the other areas. But not much else since the data is so spatially skewed: setting the bin color scale to logarithmic makes trends more apparent and helps things go viral on Reddit.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_count_attempts.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Now there&amp;rsquo;s more going on here: shot behavior is clearly symmetric on each side of the court, and there&amp;rsquo;s a small gap between the 3-point line and where 3-pt shots are typically made, likely to ensure that it it&amp;rsquo;s not accidentally ruled as a 2-pt shot.&lt;/p&gt;

&lt;p&gt;How likely is it to score a shot from a given spot? Are certain spots better than others?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_count_perc_success.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Surprisingly, shot accuracy is about &lt;em&gt;equal&lt;/em&gt; from anywhere within typical shooting distance, except directly in front of the basket where it&amp;rsquo;s much higher. What is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Expected_value&quot;&gt;expected value&lt;/a&gt; of a shot at a given position: that is, how many points on average will they earn for their team?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_count_avg_points.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The average points earned for 3-pt shots is about 1.5x higher than many 2-pt shot locations in the inner court due to the equal accuracy, but locations next to the basket have an even higher expected value. Perhaps the accuracy of shots close to the basket is higher (&amp;gt;1.5x) than 3-pt shots and outweighs the lower point value? &lt;/p&gt;

&lt;p&gt;Since both sides of the court are indeed the same, we can combine the two sides and just plot a half-court instead. (Cross-court shots, which many Redditors &lt;a href=&quot;https://www.reddit.com/r/dataisugly/comments/839rax/basketball_heat_map_shows_an_impressive_number_of/&quot;&gt;argued&lt;/a&gt; that they invalidated my visualizations above, constitute only &lt;em&gt;0.16%&lt;/em&gt; of the basketball shots in the dataset, so they can be safely removed as outliers).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_count_attempts_half_log.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;There are still a few oddities, such as shots being made &lt;em&gt;behind&lt;/em&gt; the basket. Let&amp;rsquo;s drill down a bit.&lt;/p&gt;

&lt;h2&gt;Focusing on Basketball Shot Type&lt;/h2&gt;

&lt;p&gt;The Sportradar dataset classifies a shot as one of 5 major types: a &lt;strong&gt;jump shot&lt;/strong&gt; where the player jumps-and-throws the basketball, a &lt;strong&gt;layup&lt;/strong&gt; where the player runs down the field toward the basket and throws a one-handed shot, a &lt;strong&gt;dunk&lt;/strong&gt; where the player slams the ball into the basket (looking cool in the process), a &lt;strong&gt;hook shot&lt;/strong&gt; where the player close to the basket throws the ball with a hook motion, and a &lt;strong&gt;tip shot&lt;/strong&gt; where the player intercepts a basket rebound at the tip of the basket and pushes it in.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_types_prop_attempts.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;However, the most frequent types of shots are the less flashy, more practical jump shots and layups. But is a certain type of shot &amp;ldquo;better?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_types_perc.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Layups are safer than jump shots, but dunks are the most accurate of all the types (however, players likely wouldn&amp;rsquo;t attempt a dunk unless they knew it would be successful). The accuracy of layups  and other close-to-basket shots is indeed more than 1.5x better than the jump shots of 3-pt shots, which explains the expected value behavior above.&lt;/p&gt;

&lt;p&gt;Plotting the heat maps for each type of shot offers more insight into how they work:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_count_attempts_half_types_log.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;They&amp;rsquo;re wildly different heat maps which match the shot type descriptions above, but show we&amp;rsquo;ll need to separate data visualizations by type to accurately see trends.&lt;/p&gt;

&lt;h2&gt;Impact of Game Elapsed Time At Time of Shot&lt;/h2&gt;

&lt;p&gt;A NCAA basketball game lasts for 40 minutes total (2 halves of 20 minutes each), with the possibility of overtime. The &lt;a href=&quot;https://bigquery.cloud.google.com/savedquery/4194148158:3359d86507814fb19a5997a770456baa&quot;&gt;example BigQuery&lt;/a&gt; for the NCAA-provided data compares the percentage of 3-point shots made during the first 35 minutes of the game versus the last 5 minutes: at the end of the game, accuracy was lower by 4 percentage points (31.2% vs. 35.1%). It might be interesting to facet these visualizations by the elapsed time of the game to see if there are any behavioral changes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_types_prop_type_elapsed.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;There isn&amp;rsquo;t much difference between the proportions within a given half, but there is a difference between the first half and the second half, where the second half has fewer jump shots and more aggressive layups and dunks. After looking at shot success percentage:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_types_perc_success_type_elapsed.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The jump shot accuracy loss at the end of the game with Sportradar data is similar to that of the NCAA data, which is a good sanity check (but it&amp;rsquo;s odd that the accuracy drop only happens in the last 5 minutes and not elsewhere in the 2nd half). Layup accuracy increases in the second half with the number of layups.&lt;/p&gt;

&lt;p&gt;We can also visualize heat maps for each combo of shot type with time elapsed bucket, but given the results above, the changes in behavior over time may not be very perceptible.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_count_attempts_half_interval_log.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Impact of Winning/Losing Before Shot&lt;/h2&gt;

&lt;p&gt;Another theory worth exploring is determining if there is any difference whether a team is winning or losing when they make their shot (technically, when the delta between the team score and the other team score is positive for winning teams, negative for losing teams, or 0 if tied). Are players more relaxed when they have a lead? Are players more prone to making mistakes when losing?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_types_prop_type_score.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Layups are the same across all buckets, but for teams that are winning, there are fewer jump shots and &lt;strong&gt;more dunkin&amp;rsquo; action&lt;/strong&gt; (nearly double the dunks!). However, the accuracy chart illustrates an issue:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/basketball-shots/ncaa_types_perc_success_type_score.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Accuracy for most types of shots is much better for teams that are winning&amp;hellip;which may be the &lt;em&gt;reason&lt;/em&gt; they&amp;rsquo;re winning. More research can be done in this area.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I fully admit I am not a basketball expert. But playing around with this data was a fun way to get a new perspective on how collegiate basketball games work. There&amp;rsquo;s a lot more work that can be done with big basketball data and game strategy; the NCAA-provided data doesn&amp;rsquo;t have location data, but it does have &lt;strong&gt;6x more shots&lt;/strong&gt;, which will be very helpful for further fun in this area.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view the R code, ggplot2 code, and BigQueries used to create the data visualizations in &lt;a href=&quot;http://minimaxir.com/notebooks/basketball-shots/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/code used for this post in &lt;a href=&quot;https://github.com/minimaxir/ncaa-basketball&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Special thanks to Ewen Gallic for his implementation of a &lt;a href=&quot;http://egallic.fr/en/drawing-a-basketball-court-with-r/&quot;&gt;basketball court in ggplot2&lt;/a&gt;, which saved me a lot of time!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Mar 2018 09:20:00 -0700</pubDate>
        <link>https://minimaxir.com/2018/03/basketball-shots/</link>
        <guid isPermaLink="true">https://minimaxir.com/2018/03/basketball-shots/</guid>
        
        
        <category>Cool Stuff</category>
        
        <category>Visualization</category>
        
      </item>
    
      <item>
        <title>A Visual Overview of Stack Overflow's Question Tags</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com&quot;&gt;Stack Overflow&lt;/a&gt; is the most popular contemporary knowledge base for programming questions. But most interact with the site by Googling a programming question and getting a top result that links to SO. There isn&amp;rsquo;t as much discussion about actually &lt;em&gt;asking&lt;/em&gt; questions on the site.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/python_last_list.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;I &lt;em&gt;could&lt;/em&gt; use &lt;a href=&quot;https://stackoverflow.com/users/9314418/minimaxir?tab=profile&quot;&gt;my Stack Overflow account&lt;/a&gt; and test out the process of creating a question, but &lt;del&gt;I already know everything about programming&lt;/del&gt; there may be another way to learn how SO works. Stack Overflow &lt;a href=&quot;https://archive.org/details/stackexchange&quot;&gt;releases an archive&lt;/a&gt; of all questions on the site every 3 months, and this archive is &lt;a href=&quot;https://cloud.google.com/bigquery/public-data/stackoverflow&quot;&gt;syndicated to BigQuery&lt;/a&gt;, making it trivial to retrieve and analyze the millions of SO questions over the years. Even though (now-former) Stack Overflow data scientist &lt;a href=&quot;https://twitter.com/drob&quot;&gt;David Robinson&lt;/a&gt; has written &lt;a href=&quot;https://stackoverflow.blog/2017/09/06/incredible-growth-python/&quot;&gt;many&lt;/a&gt; &lt;a href=&quot;https://stackoverflow.blog/2017/04/19/programming-languages-used-late-night/&quot;&gt;interesting&lt;/a&gt; blog posts for Stack Overflow with their data, I figured why not give it a try.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/python_last_list_answer.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Overview&lt;/h2&gt;

&lt;p&gt;Unlike social media sites like &lt;a href=&quot;https://twitter.com&quot;&gt;Twitter&lt;/a&gt; and &lt;a href=&quot;https://www.reddit.com&quot;&gt;Reddit&lt;/a&gt; where the majority of traffic is driven within the first days after something is posted, posts on evergreen content sources like Stack Overflow are still relevant many years later. In fact, the traffic to Stack Overflow for most of 2017 (derived by finding the difference between question view counts from archive snapshots) is approximately uniform across question age, with a slight bias toward older content.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/so_overview.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In 2017, Stack Overflow received about 40k-50k new questions each week, an impressive feat:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/weekly_count.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;For the rest of this post, we&amp;rsquo;ll only look at questions made in 2017 (until December; about 2.3 million questions total) in order to get a sense of the current development landscape, and what&amp;rsquo;s to come in the future. But what types of questions are they?&lt;/p&gt;

&lt;h2&gt;Tag Breakdown&lt;/h2&gt;

&lt;p&gt;All questions on Stack Overflow are required to have atleast 1 tag indicating the programming language/technologies involved with the question, and can have up to 5 tags. In the example &amp;ldquo;how do you get the last element of a list in Python&amp;rdquo; &lt;a href=&quot;https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python&quot;&gt;question&lt;/a&gt; above, the tags are &lt;code&gt;python&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt;, and &lt;code&gt;indexing&lt;/code&gt;. In 2017, most of new questions had 2-3 tags. (i.e. people aren&amp;rsquo;t &lt;a href=&quot;http://minimaxir.com/2014/03/hashtag-tag/&quot;&gt;tag spamming&lt;/a&gt; like on &lt;a href=&quot;https://www.instagram.com/?hl=en&quot;&gt;Instagram&lt;/a&gt; for maximum exposure).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/so_tag_breakdown.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In theory, tag spamming might make a question more likely to be answered; however for all tag counts, the proportion of questions with accepted answer (the green checkmark) is &lt;strong&gt;36-39%&lt;/strong&gt;, so there&amp;rsquo;s not much practical benefit from minmaxing tag counts. Which types of tagged questions are most likely to be answered?&lt;/p&gt;

&lt;p&gt;First, here&amp;rsquo;s the breakdown of the top 40 tags on Stack Overflow, by the number of new questions containing that tag for each month throughout 2017. This can give a sense of each technology&amp;rsquo;s growth/decline throughout the year.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/monthly_count_tag.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Both new web development technologies like &lt;code&gt;reactjs&lt;/code&gt; and &lt;code&gt;typescript&lt;/code&gt; and data science tools like &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;r&lt;/code&gt; are trending upward.&lt;/p&gt;

&lt;p&gt;For the Top 1,000 tags, here are the top 30 tags by the proportion of questions which received an acceptable answer:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/acceptable_answer_top_30.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In contrast, here are the bottom 30 out of the Top 1,000:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/acceptable_answer_bottom_30.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;The top tags are newer, sexier technologies like &lt;code&gt;rust&lt;/code&gt; and &lt;code&gt;dart&lt;/code&gt;, with another strong hint of data science tooling with &lt;code&gt;dplyr&lt;/code&gt; (which I used to aggregate the data for this post!) and &lt;code&gt;data.table&lt;/code&gt;. In contrast, the bottom tags are less sexy and more corporate like &lt;code&gt;salesforce&lt;/code&gt;, &lt;code&gt;drupal&lt;/code&gt;, and &lt;code&gt;sharepoint-2013&lt;/code&gt; (that&amp;rsquo;s why consultants who specialize in these technologies can get paid very well!).&lt;/p&gt;

&lt;p&gt;It should be noted these two charts do not necessarily imply that one technology is &amp;ldquo;better&amp;rdquo; than another, and the difference in answer rates may be due to question difficulty and the number of people skilled in the tech available that can answer it effectively.&lt;/p&gt;

&lt;p&gt;The timing when questions are asked might vary by tag. Per &lt;a href=&quot;https://stackoverflow.blog/2017/04/19/programming-languages-used-late-night/&quot;&gt;a Stack Overflow analysis&lt;/a&gt;, people typically ask questions during the 9 AM - 5 PM work hours (although in my case, I cannot easily adjust for the time zone of the asker). How does this data fare?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/monthly_count_hr_doy.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;This visualization is a bit weird. I adjusted the times to the Eastern time since internet activity for U.S.-based websites tends to revolve around that time zone. But for most technologies, the peak question-asking times are well before 9 AM to 5 PM: do those technologies correspond more to greater use in Europe and Asia? (In contrast, data-oriented technologies like &lt;code&gt;r&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;excel&lt;/code&gt; &lt;em&gt;do&lt;/em&gt; peak during the 9-5 block).&lt;/p&gt;

&lt;h2&gt;How easy is it to get an answer by tag?&lt;/h2&gt;

&lt;p&gt;Stack Overflow caters the homepage toward the logged-in user&amp;rsquo;s recommended tags. Therefore, it&amp;rsquo;s not a surprise that the distribution of view counts on 2017 questions for each tag are very similar, although there is a slight edge toward the new &amp;ldquo;hip&amp;rdquo; technologies like &lt;code&gt;typescript&lt;/code&gt;, &lt;code&gt;spring&lt;/code&gt;, and &lt;code&gt;swift&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/views_boxplot_tag.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;At the least, the distribution ensures that atleast 10 people see your question for these popular topics, which is nifty when you consider posts on Twitter and Reddit can die without any visibility at all. But will they provide an acceptable answer?&lt;/p&gt;

&lt;p&gt;The time it takes to get an acceptable answer also varies significantly by tag:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/acceptable_answer_density.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;A median time of &lt;em&gt;15 minutes&lt;/em&gt; for tags like &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;arrays&lt;/code&gt; is pretty impressive! And even in the worst case scenario for these popular tags, the median is only a couple hours, much lower than I thought it would be.&lt;/p&gt;

&lt;h2&gt;The Relationship Between Tags&lt;/h2&gt;

&lt;p&gt;As one would expect, the types of questions asked for each tag are much different. Here&amp;rsquo;s a wordcloud for each of the tags, quantifying the words most frequently used in the questions on those tags:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/so_tag_wordcloud.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Notably, each word cloud is significantly different from reach other, even when technologies are related (also surprisingly true in the case of &lt;code&gt;angular&lt;/code&gt; and &lt;code&gt;angularjs&lt;/code&gt;!).&lt;/p&gt;

&lt;p&gt;How are the tags related anyways? We can calculate an &lt;a href=&quot;https://en.wikipedia.org/wiki/Adjacency_matrix&quot;&gt;adjacency matrix&lt;/a&gt; of the tag pairs in the questions to see which tags are related:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/so_tag_adjacency.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Looking down a given row/column, you can see which technologies have a lot of questions in common with another (for example, &lt;code&gt;javascript&lt;/code&gt; and &lt;code&gt;json&lt;/code&gt; are frequently asked in conjunction with other tags).&lt;/p&gt;

&lt;p&gt;Going back earlier to talking about tag abuse, do the presence of certain pairs of tags lead to notably different answer rates?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/stack-overflow-tags/so_tag_adjacency_percent.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Tag pairs which don&amp;rsquo;t make much sense (e.g. &lt;code&gt;ios&lt;/code&gt;+&lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;+&lt;code&gt;javascript&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;+&lt;code&gt;php&lt;/code&gt;) tend to have very low answer rates (20%-30%). But tags with already high answer rates like &lt;code&gt;regex&lt;/code&gt; don&amp;rsquo;t get much higher or much lower at a given pair.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s a lot more than can be done looking at question tags on Stack Overflow. I was surprised to see that all types of programming languages have quick answer times and a high probability of receiving an acceptable answer! I&amp;rsquo;ll definitely keep an eye on the SO archives as they are released, and I&amp;rsquo;m excited to see how trends change in the future.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view the R and ggplot2 code used to create the data visualizations in &lt;a href=&quot;http://minimaxir.com/notebooks/stack-overflow-questions/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&quot;https://github.com/minimaxir/stack-overflow-questions&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 09 Feb 2018 09:00:00 -0800</pubDate>
        <link>https://minimaxir.com/2018/02/stack-overflow-questions/</link>
        <guid isPermaLink="true">https://minimaxir.com/2018/02/stack-overflow-questions/</guid>
        
        
        <category>Cool Stuff</category>
        
        <category>Visualization</category>
        
      </item>
    
      <item>
        <title>Benchmarking Modern GPUs for Maximum Cloud Cost Efficiency in Deep Learning</title>
        <description>&lt;p&gt;A few months ago, I &lt;a href=&quot;http://minimaxir.com/2017/06/keras-cntk/&quot;&gt;performed benchmarks&lt;/a&gt; of deep learning frameworks in the cloud, with a &lt;a href=&quot;http://minimaxir.com/2017/07/cpu-or-gpu/&quot;&gt;followup&lt;/a&gt; focusing on the cost difference between using GPUs and CPUs. And just a few months later, the landscape has changed, with significant updates to the low-level &lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;NVIDIA cuDNN&lt;/a&gt; library which powers the raw learning on the GPU, the &lt;a href=&quot;https://www.tensorflow.org&quot;&gt;TensorFlow&lt;/a&gt; and &lt;a href=&quot;https://github.com/Microsoft/CNTK&quot;&gt;CNTK&lt;/a&gt; deep learning frameworks, and the higher-level &lt;a href=&quot;https://github.com/fchollet/keras&quot;&gt;Keras&lt;/a&gt; framework which uses TensorFlow/CNTK as backends for easy deep learning model training.&lt;/p&gt;

&lt;p&gt;As a bonus to the framework updates, Google &lt;a href=&quot;https://cloudplatform.googleblog.com/2017/09/introducing-faster-GPUs-for-Google-Compute-Engine.html&quot;&gt;recently released&lt;/a&gt; the newest generation of NVIDIA cloud GPUs, the Pascal-based P100, onto &lt;a href=&quot;https://cloud.google.com/compute/&quot;&gt;Google Compute Engine&lt;/a&gt; which touts an up-to-10x performance increase to the current K80 GPUs used in cloud computing. As a bonus bonus, Google recently &lt;a href=&quot;https://cloudplatform.googleblog.com/2017/11/new-lower-prices-for-GPUs-and-preemptible-Local-SSDs.html&quot;&gt;cut the prices&lt;/a&gt; of both K80 and P100 GPU instances by up to 36%.&lt;/p&gt;

&lt;p&gt;The results of my earlier benchmarks favored &lt;a href=&quot;https://cloud.google.com/preemptible-vms/&quot;&gt;preemptible&lt;/a&gt; instances with many CPUs as the most cost efficient option (where a preemptable instance can only last for up to 24 hours and could end prematurely). A 36% price cut to GPU instances, in addition to the potential new benefits offered by software and GPU updates, however, might be enough to tip the cost-efficiency scales back in favor of GPUs. It&amp;rsquo;s a good idea to rerun the experiment with updated VMs and see what happens.&lt;/p&gt;

&lt;h2&gt;Benchmark Setup&lt;/h2&gt;

&lt;p&gt;As with the original benchmark, I set up a &lt;a href=&quot;https://github.com/minimaxir/keras-cntk-docker&quot;&gt;Docker container&lt;/a&gt; containing the deep learning frameworks (based on cuDNN 6, the latest version of cuDNN natively supported by the frameworks) that can be used to train each model independently. The &lt;a href=&quot;https://github.com/minimaxir/keras-cntk-benchmark/tree/master/v2/test_files&quot;&gt;Keras benchmark scripts&lt;/a&gt; run on the containers are based off of &lt;em&gt;real world&lt;/em&gt; use cases of deep learning.&lt;/p&gt;

&lt;p&gt;The 6 hardware/software configurations and Google Compute Engine &lt;a href=&quot;https://cloud.google.com/compute/pricing&quot;&gt;pricings&lt;/a&gt; for the tests are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A K80 GPU (attached to a &lt;code&gt;n1-standard-1&lt;/code&gt; instance), tested with both TensorFlow (1.4) and CNTK (2.2): &lt;strong&gt;$0.4975 / hour&lt;/strong&gt;. &lt;/li&gt;
&lt;li&gt;A P100 GPU (attached to a &lt;code&gt;n1-standard-1&lt;/code&gt; instance), tested with both TensorFlow and CNTK: &lt;strong&gt;$1.5075 / hour&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;A preemptable &lt;code&gt;n1-highcpu-32&lt;/code&gt; instance, with 32 vCPUs based on the Intel Skylake architecture, tested with TensorFlow only: &lt;strong&gt;$0.2400 / hour&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;A preemptable &lt;code&gt;n1-highcpu-16&lt;/code&gt; instance, with 16 vCPUs based on the Intel Skylake architecture, tested with TensorFlow only: &lt;strong&gt;$0.1200 / hour&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A single K80 GPU uses &amp;frac12; a GPU board while a single P100 uses a full GPU board, which in an ideal world would suggest that the P100 is twice as fast at the K80 at minimum. But even so, the P100 configuration is about 3 times as expensive, so even if a model is trained in half the time, it may not necessarily be cheaper with the P100.&lt;/p&gt;

&lt;p&gt;Also, the CPU tests use TensorFlow &lt;em&gt;as installed via the recommended method&lt;/em&gt; through pip, since compiling the TensorFlow binary from scratch to take advantage of CPU instructions as &lt;a href=&quot;http://minimaxir.com/2017/07/cpu-or-gpu/&quot;&gt;with my previous test&lt;/a&gt; is not a pragmatic workflow for casual use.&lt;/p&gt;

&lt;h2&gt;Benchmark Results&lt;/h2&gt;

&lt;p&gt;When a fresh-out-of-a-AI-MOOC engineer wants to experiment with deep learning in the cloud, typically they use a K80 + TensorFlow setup, so we&amp;rsquo;ll use that as the &lt;em&gt;base configuration&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;For each model architecture and software/hardware configuration, I calculate the &lt;strong&gt;total training time relative to the base configuration instance training&lt;/strong&gt; for running the model training for the provided test script. In all cases, the P100 GPU &lt;em&gt;should&lt;/em&gt; perform better than the K80, and 32 vCPUs &lt;em&gt;should&lt;/em&gt; train faster than 16 vCPUs. The question is how &lt;em&gt;much&lt;/em&gt; faster?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start using the &lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot;&gt;MNIST dataset&lt;/a&gt; of handwritten digits plus the common multilayer perceptron (MLP) architecture, with dense fully-connected layers. Lower training time is better.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;For this task, CNTK appears to be more effective than TensorFlow. Indeed, the P100 is faster than the K80 for the corresponding framework, although it&amp;rsquo;s not a dramatic difference. However, since the task is simple, the CPU performance is close to that of the GPU, which implies that the GPU is not as cost effective for a simple architecture.&lt;/p&gt;

&lt;p&gt;For each model architecture and configuration, I calculate a &lt;strong&gt;normalized training cost relative to the cost of the base configuration training&lt;/strong&gt;. Because GCE instance costs are prorated, we can simply calculate experiment cost by multiplying the total number of seconds the experiment runs by the cost of the instance (per second).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Unsurprisingly, CPUs are more cost effective. However, the P100 is more cost &lt;em&gt;ineffective&lt;/em&gt; for this task than the K80.&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s look at the same dataset with a convolutional neural network (CNN) approach for digit classification. Since CNNs are typically used for computer vision tasks, new graphic card architectures are optimized for CNN workflows, so it will be interesting to see how the P100 performs compared to the K80:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Indeed, the P100 is twice as fast and the K80, but due to the huge cost premium, it&amp;rsquo;s not cost effective for this simple task. However, CPUs do not perform well on this task either, so notably the base configuration is the best configuration.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s go deeper with CNNs and look at the &lt;a href=&quot;https://www.cs.toronto.edu/%7Ekriz/cifar.html&quot;&gt;CIFAR-10&lt;/a&gt; image classification dataset, and a model which utilizes a deep covnet + a multilayer perceptron and ideal for image classification (similar to the &lt;a href=&quot;https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3&quot;&gt;VGG-16&lt;/a&gt; architecture).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Similar results to that of a normal MLP. Nothing fancy.&lt;/p&gt;

&lt;p&gt;The Bidirectional long-short-term memory (LSTM) architecture is great for working with text data like IMDb reviews. When I did &lt;a href=&quot;http://minimaxir.com/2017/06/keras-cntk/&quot;&gt;my first benchmark article&lt;/a&gt;, I noticed that CNTK performed significantly better than TensorFlow, as &lt;a href=&quot;https://news.ycombinator.com/item?id=14538086&quot;&gt;commenters on Hacker News&lt;/a&gt; noted that TensorFlow uses an inefficient implementation of the LSTM on the GPU.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/cntk-old.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;However, with Keras&amp;rsquo;s &lt;a href=&quot;https://keras.io/layers/recurrent/#cudnnlstm&quot;&gt;new CuDNNRNN layers&lt;/a&gt; which leverage cuDNN, this inefficiency may be fixed, so for the K80/P100 TensorFlow GPU configs, I use a CuDNNLSTM layer instead of a normal LSTM layer. So let&amp;rsquo;s take another look:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;WOAH.&lt;/em&gt; TensorFlow is now more than &lt;em&gt;three times as fast&lt;/em&gt; than CNTK! (And compared against my previous benchmark, TensorFlow on the K80 w/ the CuDNNLSTM is about &lt;em&gt;7x as fast&lt;/em&gt; as it once was!) Even the CPU-only versions of TensorFlow are faster than CNTK on the GPU now, which implies significant improvements in the ecosystem outside of the CuDNNLSTM layer itself. (And as a result, CPUs are still more cost efficient)&lt;/p&gt;

&lt;p&gt;Lastly, LSTM text generation of &lt;a href=&quot;https://en.wikipedia.org/wiki/Friedrich_Nietzsche&quot;&gt;Nietzsche&amp;rsquo;s&lt;/a&gt; &lt;a href=&quot;https://s3.amazonaws.com/text-datasets/nietzsche.txt&quot;&gt;writings&lt;/a&gt; follows similar patterns to the other architectures, but without the drastic hit to the GPU.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/dl-cpu-gpu-12.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;The biggest surprise of these new benchmarks is that there is no configuration where the P100 is the most cost-effective option, even though the P100 is indeed faster than the K80 in all tests.  Although per &lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;the cuDNN website&lt;/a&gt;, there is apparently only a 2x speed increase between the performance of the K80 and P100 using cuDNN 6, which is mostly consistent with the results of my benchmarks:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/benchmark-gpus/cudnn.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;I did not include a multi-GPU configuration in the benchmark data visualizations above using Keras&amp;rsquo;s new &lt;code&gt;multi_gpu_model&lt;/code&gt; &lt;a href=&quot;https://keras.io/utils/#multi_gpu_model&quot;&gt;function&lt;/a&gt; because in my testing, the multi-GPU training &lt;em&gt;was equal to or worse than a single GPU&lt;/em&gt; in all tests.&lt;/p&gt;

&lt;p&gt;Taking these together, it&amp;rsquo;s possible that the overhead introduced by parallel, advanced architectures &lt;em&gt;eliminates the benefits&lt;/em&gt; for &amp;ldquo;normal&amp;rdquo; deep learning workloads which do not fully saturate the GPU. Rarely do people talk about diminishing returns in GPU performance with deep learning.&lt;/p&gt;

&lt;p&gt;In the future, I want to benchmark deep learning performance against more advanced deep learning use cases such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Reinforcement_learning&quot;&gt;reinforcement learning&lt;/a&gt; and deep CNNs like &lt;a href=&quot;https://github.com/tensorflow/models/tree/master/research/inception&quot;&gt;Inception&lt;/a&gt;. But that doesn&amp;rsquo;t mean these benchmarks are not relevant; as stated during the benchmark setup, the GPUs were tested against typical deep learning use cases, and now we see the tradeoffs that result.&lt;/p&gt;

&lt;p&gt;In all, with the price cuts on GPU instances, cost-performance is often &lt;em&gt;on par&lt;/em&gt; with preemptable CPU instances, which is an advantage if you want to train models faster and not risk the instance being killed unexpectedly. And there is still a lot of competition in this space: &lt;a href=&quot;https://www.amazon.com&quot;&gt;Amazon&lt;/a&gt; offers a &lt;code&gt;p2.xlarge&lt;/code&gt; &lt;a href=&quot;https://aws.amazon.com/ec2/spot/&quot;&gt;Spot Instance&lt;/a&gt; with a K80 GPU for $0.15-$0.20 an hour, less than half of the corresponding Google Compute Engine K80 GPU instance, although with &lt;a href=&quot;https://aws.amazon.com/ec2/spot/details/&quot;&gt;a few bidding caveats&lt;/a&gt; which I haven&amp;rsquo;t fully explored yet. Competition will drive GPU prices down even further, and training deep learning models will become even easier.&lt;/p&gt;

&lt;p&gt;And as the cuDNN chart above shows, things will get &lt;em&gt;very&lt;/em&gt; interesting once Volta-based GPUs like the V100 are generally available and the deep learning frameworks support cuDNN 7 by default.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UPDATE 12/17&lt;/strong&gt;: &lt;em&gt;As pointed out by &lt;a href=&quot;https://news.ycombinator.com/item?id=15941682&quot;&gt;dantiberian on Hacker News&lt;/a&gt;, Google  Compute Engine now supports &lt;a href=&quot;https://cloud.google.com/compute/docs/instances/preemptible#preemptible_with_gpu&quot;&gt;preemptible GPUs&lt;/a&gt;, which was apparently added after this post went live. Preemptable GPUs are exactly half the price of normal GPUs (for both K80s and P100s; $0.73/hr and $0.22/hr respectively), so they&amp;rsquo;re about double the cost efficiency (when factoring in the cost of the base preemptable instance), which would put them squarely ahead of CPUs in all cases. (and since the CPU instances used here were also preemptable, it&amp;rsquo;s apples-to-apples)&lt;/em&gt;&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;All scripts for running the benchmark are available in &lt;a href=&quot;https://github.com/minimaxir/keras-cntk-benchmark/tree/master/v2&quot;&gt;this GitHub repo&lt;/a&gt;. You can view the R/ggplot2 code used to process the logs and create the visualizations in &lt;a href=&quot;http://minimaxir.com/notebooks/benchmark-gpus/&quot;&gt;this R Notebook&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 28 Nov 2017 08:30:00 -0800</pubDate>
        <link>https://minimaxir.com/2017/11/benchmark-gpus/</link>
        <guid isPermaLink="true">https://minimaxir.com/2017/11/benchmark-gpus/</guid>
        
        
        <category>Cool Stuff</category>
        
      </item>
    
      <item>
        <title>Making Magic: the GIFening</title>
        <description>&lt;p&gt;After working at &lt;a href=&quot;https://www.buzzfeed.com/&quot;&gt;BuzzFeed&lt;/a&gt; for a few months, I&amp;rsquo;m now an expert in the proper usage of GIFs. My favorite GIF tool is the &lt;a href=&quot;https://giphy.com&quot;&gt;/giphy&lt;/a&gt; command in &lt;a href=&quot;https://slack.com&quot;&gt;Slack&lt;/a&gt;, which &lt;a href=&quot;https://get.slack.help/hc/en-us/articles/204714258-Add-Giphy-search-to-Slack&quot;&gt;puts a random GIF&lt;/a&gt; according to a given phrase into the chat, with better-than-expected appropriateness of the phrase to the GIF.&lt;/p&gt;

&lt;p&gt;Completely unrelated, I recently rediscovered &lt;a href=&quot;https://github.com/Zulko/moviepy&quot;&gt;MoviePy&lt;/a&gt;, a Python library for programmatically editing videos and GIFs without requiring an expensive and slow video editing program. I had played with MoviePy a bit in 2014 when it was &lt;a href=&quot;http://zulko.github.io/blog/2014/01/23/making-animated-gifs-from-video-files-with-python/#&quot;&gt;first released&lt;/a&gt; and &lt;a href=&quot;https://news.ycombinator.com/item?id=7121104&quot;&gt;became viral&lt;/a&gt;, but couldn&amp;rsquo;t think of a creative application for the library at the time.&lt;/p&gt;

&lt;p&gt;On a boring weekend I had a silly idea: why not create a program to superimpose appropriate GIFs onto &lt;a href=&quot;https://magic.wizards.com/en&quot;&gt;Magic: the Gathering&lt;/a&gt; cards using these two tools? And even better, why not &lt;em&gt;automate&lt;/em&gt; both the creation of the card GIFs and the tweeting of a new GIF every few hours?&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;und&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://t.co/sxqKUYHmfv&quot;&gt;pic.twitter.com/sxqKUYHmfv&lt;/a&gt;&lt;/p&gt;&amp;mdash; Magic: The GIFening (@MTGIFening) &lt;a href=&quot;https://twitter.com/MTGIFening/status/913993793052880897?ref_src=twsrc%5Etfw&quot;&gt;September 30, 2017&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;As it turns out, creating a Twitter bot to tweet Magic card GIFs is &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening&quot;&gt;easy to implement&lt;/a&gt;, but with a few interesting caveats. The end result is &lt;a href=&quot;https://twitter.com/MTGIFening&quot;&gt;@MTGIFening&lt;/a&gt;. Here&amp;rsquo;s how I typically create my crazy apps, step by step.&lt;/p&gt;

&lt;h2&gt;Feasibility Analysis&lt;/h2&gt;

&lt;p&gt;Like all my data analysis projects, I checked if it&amp;rsquo;s possible to complete the project in a way that won&amp;rsquo;t suck up a lot of free time hacking out convoluted solutions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Can I easily get a list of all Magic cards?&lt;/strong&gt; Yes, via &lt;a href=&quot;https://mtgjson.com&quot;&gt;MTG JSON&lt;/a&gt;, which has a downloadable JSON dump of all Magic cards.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Can I easily get random GIFs from GIPHY?&lt;/strong&gt; Yes, there is a /random endpoint in the &lt;a href=&quot;https://developers.giphy.com&quot;&gt;GIPHY API&lt;/a&gt; which returns a random GIF for a specified phrase, like the /giphy Slack command. The GIPHY API requires registration, but has generous rate limits (10k requests/day).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Can I easily composite a GIF onto an image with MoviePy?&lt;/strong&gt; Yes, compositing is a &lt;em&gt;primary use case&lt;/em&gt; for the library, with many tutorials in the documentation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Can I easily get an image for a specified Magic card?&lt;/strong&gt; Unsure. The official tool for viewing Magic card images is &lt;a href=&quot;http://gatherer.wizards.com/Pages/Default.aspx&quot;&gt;Gatherer&lt;/a&gt;. After checking the image source for the cards, each card image in Gatherer has a URL that follows this schema: &lt;code&gt;http://gatherer.wizards.com/Handlers/Image.ashx?multiverseid=XXXXX&amp;amp;type=card&lt;/code&gt;. That&amp;rsquo;s easy to understand, but what&amp;rsquo;s a multiverseid?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Is there a mapping of multiverseid to Magic cards from MTG JSON?&lt;/strong&gt; Yes, the multiverseid for each Magic card is &lt;a href=&quot;https://mtgjson.com/documentation.html&quot;&gt;present as a field&lt;/a&gt; in the &amp;ldquo;All Sets&amp;rdquo; dataset (but not the &amp;ldquo;All Cards&amp;rdquo; dataset oddly). A quick manual check showed that using the multiverseid from the MTG JSON dataset results in the correct image from Gatherer.&lt;/p&gt;

&lt;p&gt;Everything looked good to me. Let&amp;rsquo;s dive right in, &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening/commits/master&quot;&gt;commit by commit&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Implementing Magic: The GIFening&lt;/h2&gt;

&lt;p&gt;The first thing I did was process the Magic card data, although for this project I limit the type of cards to Instants and Sorceries, which in Magic game mechanics represent &amp;ldquo;actions&amp;rdquo; and are more suitable for GIFs. &lt;em&gt;For each set, retrieve the cards in the set; for each card, if it&amp;rsquo;s an Instant/Sorcery, log its name and multiverseid&lt;/em&gt;. Thanks to the magic of Python, this pseudocode is close to the &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening/commit/3f626ae5d49a567322c6237210ab554281d462f4&quot;&gt;actual code&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The next objective was to implement the GIPHY API to get a GIF. The very first thing I did is add a local secrets file containing my personal API key for GIPHY, and &lt;em&gt;immediately&lt;/em&gt; log the secrets file in a &lt;code&gt;.gitignore&lt;/code&gt; so I don&amp;rsquo;t accidentally leak it. GIPHY has an &lt;a href=&quot;https://developers.giphy.com/explorer/&quot;&gt;API Explorer&lt;/a&gt; which allows developers to quickly test an example input phrase and see corresponding output from the API. For example, here&amp;rsquo;s part of what the API returns for &lt;a href=&quot;http://gatherer.wizards.com/Pages/Card/Details.aspx?multiverseid=151108&quot;&gt;Invert the Skies&lt;/a&gt; (although since it&amp;rsquo;s the /random endpoint, your results may vary):&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;s2&quot;&gt;&quot;image_url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://media1.giphy.com/media/plbsEwLwQvzLa/giphy.gif&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;image_mp4_url&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;https://media1.giphy.com/media/plbsEwLwQvzLa/giphy.mp4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;image_frames&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;31&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;image_width&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;480&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;image_height&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;270&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;image_url&lt;/code&gt; corresponds to the &lt;a href=&quot;https://media1.giphy.com/media/plbsEwLwQvzLa/giphy.gif&quot;&gt;raw GIF&lt;/a&gt; unsurprisingly, but as a bonus, GIPHY also includes a link to a &lt;a href=&quot;https://media1.giphy.com/media/plbsEwLwQvzLa/giphy.mp4&quot;&gt;MP4 video&lt;/a&gt; of the GIF, which has a much smaller file size and is better to use for compositing. The API output also includes the width and height (in pixels) of the GIF. The art in a Magic card follows a 4:3 &lt;a href=&quot;https://en.wikipedia.org/wiki/Aspect_ratio_(image)&quot;&gt;aspect ratio&lt;/a&gt;, i.e. the width divided by the height equals 1.33. If the dimensions of the GIF are too far outside that ratio, resizing the GIFs to fit the Magic art frame will result in noticeable distortion. I minimized this distortion by checking and seeing if the random GIF has a width:height ratio between 1.2 and 1.6 before accepting it. Since there&amp;rsquo;s a chance for failure (along with potential unknown bugs that the random GIF could hit), I added a limit to the number of attempts to retrieve an appropriate GIF. All done in &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening/commit/c2e4b6b9d58d1aa360f6f67a049ec962d0430b91&quot;&gt;one commit&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Getting the card image from Gatherer is &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening/commit/c92440cd459640da9346cf31a79e768ac8641ea9&quot;&gt;trivial&lt;/a&gt;, so then I worked on combining the GIF and the card image. MoviePy has a &lt;a href=&quot;http://zulko.github.io/moviepy/getting_started/compositing.html&quot;&gt;good tutorial&lt;/a&gt; for specifying the position of one clip onto another by specifying the upper-left corner of the bottom-image where the GIF will be placed, while simultaneously resizing the GIF to a given width and height.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/magic-the-gifening/videoWH.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;I manually zoomed into the card image using a photo editor (&lt;a href=&quot;http://www.pixelmator.com/mac/&quot;&gt;Pixelmator&lt;/a&gt;) to find the upper-left corner of the card art:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/magic-the-gifening/zoomin.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In this case, the pixel coordinates for the upper-left corner of the card art is &lt;code&gt;(17,35)&lt;/code&gt; The upper-right and bottom-left corners can be used to determine the target width and height of the GIF respectively, and can be found the same way. Simply composite the Magic card with the resized-and-positioned GIF, set the duration of the &amp;ldquo;new&amp;rdquo; GIF to that of the source GIF, and &lt;code&gt;write_gif&lt;/code&gt;. &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening/commit/55a52ddfc7f43d128c08c8a243254e08a171de5e&quot;&gt;That&amp;rsquo;s that&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;To finish things up, I wrote a script to load all the cards from the processed card list into memory, select a card at random, use the helper functions to retrieve a GIPHY GIF and composite it with the card, then upload the resulting GIF to Twitter. I haven&amp;rsquo;t worked with the Twitter API in awhile; a quick Google search for a modern Twitter API client in Python returns &lt;a href=&quot;https://github.com/ryanmcgrath/twython&quot;&gt;Twython&lt;/a&gt;, which conveniently includes an example on &lt;a href=&quot;https://twython.readthedocs.io/en/latest/usage/advanced_usage.html#updating-status-with-image&quot;&gt;how to upload an image to Twitter&lt;/a&gt;! And after running the script a few times, the full workflow indeed works!&lt;/p&gt;

&lt;p&gt;Not bad for a couple hours of scripting. But I was not close to finished.&lt;/p&gt;

&lt;h2&gt;The Endless Fun of QA&lt;/h2&gt;

&lt;p&gt;One of the reasons I enjoy doing silly projects (especially silly data projects) is because I tend to hit unsexy edge cases which typical development blogs and tutorials rarely discuss. In this case, I quickly found that the Twitter API has a &lt;a href=&quot;https://developer.twitter.com/en/docs/media/upload-media/overview&quot;&gt;5 MB limit&lt;/a&gt; on image uploads, which is a problem as the resulting GIFs are huge and often randomly exceed that limit (looking back on it, there is a different endpoint intended for GIF uploads, counterintuitively).&lt;/p&gt;

&lt;p&gt;In actuality, GIFs on Twitter are actually displayed as videos, in order to save bandwidth. Since Twitter transcodes uploaded GIFs anyways, it makes more sense to upload &lt;em&gt;audioless videos&lt;/em&gt; instead of GIFs (and as a bonus, after the death of Vine, Twitter will auto-loop videos less than 6 seconds).&lt;/p&gt;

&lt;p&gt;Creating videos is easy to do with MoviePy, just do a &lt;code&gt;write_videofile&lt;/code&gt; instead of &lt;code&gt;write_gif&lt;/code&gt;, and use Twython&amp;rsquo;s video uploading example to upload. The result is an &amp;ldquo;unknown&amp;rdquo; error on upload. I verify by uploading the video manually to Twitter&amp;hellip;and the Twitter UI fails to recognize it as a video. But the video itself plays fine in QuickTime. This is the annoying type of coding problem that&amp;rsquo;s too specific for &lt;a href=&quot;https://stackoverflow.com&quot;&gt;Stack Overflow&lt;/a&gt; to provide help. After a bit of trial and error involving video codecs and settings, the solution was to pass a &lt;code&gt;-pix_fmt yuv420p&lt;/code&gt; parameter to the video encoder because Twitter apparently only likes legacy video container formats. Oh well. It worked, and both Twitter manual and API uploads worked successfully.&lt;/p&gt;

&lt;p&gt;I also ran into an issue where Twitter refused to accept supershort video, where the source GIF was only a couple frames. A solution is to loop the GIF to atleast 2 seconds if it&amp;rsquo;s shorter, which somehow fixed that problem.&lt;/p&gt;

&lt;p&gt;(As I was writing this post a month later, I discovered that both of these video upload constraints &lt;a href=&quot;https://developer.twitter.com/en/docs/media/upload-media/uploading-media/media-best-practices&quot;&gt;are indeed covered in the Twitter documentation&lt;/a&gt;, which makes me look very silly in retrospect!)&lt;/p&gt;

&lt;p&gt;These changes fixed most of the upload issues. However, when writing the initial script, I forgot that the borders of Magic cards have &lt;a href=&quot;https://mtg.gamepedia.com/Card_frame&quot;&gt;changed over the years&lt;/a&gt;, which also changed the position and size of the card art. &lt;strong&gt;Is there a way to check when a card was printed?&lt;/strong&gt; Yes, the &amp;ldquo;All Sets&amp;rdquo; dataset contains the release date of the set, so with that, I can &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening/commit/0dfb678f1955f50b54b632e57087df847ec16f05&quot;&gt;hard code&lt;/a&gt; the dates of sets where the borders changed, and note the border type at printing time. I then used Pixelmator again to note the new art dimensions for that type of border, and used conditional statements to retrieve the correct dimensions for the type of border when compositing.&lt;/p&gt;

&lt;p&gt;Lastly, I added general &lt;code&gt;try/catch&lt;/code&gt; error handling to prevent the script from breaking fatally and to try again with a different card if it does. That covers most of the edge cases!&lt;/p&gt;

&lt;h2&gt;Results&lt;/h2&gt;

&lt;p&gt;After running the script many times after all the fixes in place, I felt the Twitter account was good to go. The initial results showed a lot of promise:&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;und&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://t.co/BsZ7eIcunl&quot;&gt;pic.twitter.com/BsZ7eIcunl&lt;/a&gt;&lt;/p&gt;&amp;mdash; Magic: The GIFening (@MTGIFening) &lt;a href=&quot;https://twitter.com/MTGIFening/status/913981726182981632?ref_src=twsrc%5Etfw&quot;&gt;September 30, 2017&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;und&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://t.co/picJJk6mBm&quot;&gt;pic.twitter.com/picJJk6mBm&lt;/a&gt;&lt;/p&gt;&amp;mdash; Magic: The GIFening (@MTGIFening) &lt;a href=&quot;https://twitter.com/MTGIFening/status/912525635632775168?ref_src=twsrc%5Etfw&quot;&gt;September 26, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Surprisingly, the script was able to generate &lt;em&gt;visual puns&lt;/em&gt; in cards, completely by chance!&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;und&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://t.co/AnpzU8xVho&quot;&gt;pic.twitter.com/AnpzU8xVho&lt;/a&gt;&lt;/p&gt;&amp;mdash; Magic: The GIFening (@MTGIFening) &lt;a href=&quot;https://twitter.com/MTGIFening/status/913972922330497024?ref_src=twsrc%5Etfw&quot;&gt;September 30, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;und&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://t.co/01vGRcq2Mj&quot;&gt;pic.twitter.com/01vGRcq2Mj&lt;/a&gt;&lt;/p&gt;&amp;mdash; Magic: The GIFening (@MTGIFening) &lt;a href=&quot;https://twitter.com/MTGIFening/status/913987002235740160?ref_src=twsrc%5Etfw&quot;&gt;September 30, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The next step was to automate the script to run and post Tweets at a specific time interval. After experimenting a bit, I found that &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening/commit/f355d5e80503c67c6e1a0e5fd1b744faf3cf8223&quot;&gt;the best solution&lt;/a&gt; was to use a &lt;a href=&quot;https://en.wikipedia.org/wiki/Cron&quot;&gt;cron job&lt;/a&gt; in a &lt;a href=&quot;https://www.docker.com/what-docker&quot;&gt;Docker container&lt;/a&gt; containing the script and its dependencies, for complicated reasons which will require another blog post to explain. &lt;/p&gt;

&lt;p&gt;After letting Magic: the GIFening run for a few days without fatal issues, I decided to publicize the Twitter account and posted it to the &lt;a href=&quot;https://www.reddit.com/r/magicTCG/comments/7598g5/i_made_a_twitter_bot_which_tweets_magic_cards/&quot;&gt;/r/MagicTCG subreddit&lt;/a&gt; and &lt;a href=&quot;https://news.ycombinator.com/item?id=15449955&quot;&gt;Hacker News&lt;/a&gt;. To my surprise, the project performed extremely well on both with 100+ upvotes on each, and the &lt;a href=&quot;https://github.com/minimaxir/magic-the-gifening&quot;&gt;GitHub repo&lt;/a&gt; itself received 100+ Stars.&lt;/p&gt;

&lt;p&gt;In all, making Magic: the GIFening was a fun project. In retrospect, talking though the commits made me realize I performed many bad coding practices in a haste to get the project done ASAP (specifically, checking to see if certain edge cases are documented, violating &lt;a href=&quot;https://en.wikipedia.org/wiki/Don%27t_repeat_yourself&quot;&gt;DRY&lt;/a&gt;, and forgetting to remove specific types of cards like &lt;a href=&quot;https://twitter.com/MTGIFening/status/924969160307744769&quot;&gt;split cards&lt;/a&gt;). Obviously there isn&amp;rsquo;t a multimillion-dollar startup opportunity in creating random GIFs of Magic cards, but I&amp;rsquo;ll fix a few remaining issues and keep the Twitter bot running.&lt;/p&gt;
</description>
        <pubDate>Tue, 07 Nov 2017 08:10:00 -0800</pubDate>
        <link>https://minimaxir.com/2017/11/magic-the-gifening/</link>
        <guid isPermaLink="true">https://minimaxir.com/2017/11/magic-the-gifening/</guid>
        
        
        <category>Cool Stuff</category>
        
      </item>
    
      <item>
        <title>How to Make High Quality Data Visualizations for Websites With R and ggplot2</title>
        <description>&lt;p&gt;If you&amp;rsquo;ve been following my blog, I like to use &lt;a href=&quot;https://cran.r-project.org&quot;&gt;R&lt;/a&gt; and &lt;a href=&quot;http://ggplot2.tidyverse.org/reference/&quot;&gt;ggplot2&lt;/a&gt; for data visualization. A lot.&lt;/p&gt;

&lt;p&gt;One of my older blog posts, &lt;a href=&quot;http://minimaxir.com/2015/02/ggplot-tutorial/&quot;&gt;An Introduction on How to Make Beautiful Charts With R and ggplot2&lt;/a&gt;, is still one of my most-trafficked posts years later, and even today I see techniques from that particular post incorporated into modern data visualizations on sites such as &lt;a href=&quot;https://www.reddit.com&quot;&gt;Reddit&amp;rsquo;s&lt;/a&gt; &lt;a href=&quot;https://www.reddit.com/r/dataisbeautiful/&quot;&gt;/r/dataisbeautiful&lt;/a&gt; subreddit.&lt;/p&gt;

&lt;p&gt;However, that post is a little outdated. Thanks to a few updates to ggplot2 since then and other advances in data visualization best-practices, making pretty charts for websites/blogs using R and ggplot2 is even more easy, quick, &lt;em&gt;and&lt;/em&gt; fun!&lt;/p&gt;

&lt;h2&gt;Quick Introduction to ggplot2&lt;/h2&gt;

&lt;p&gt;ggplot2 uses a more concise setup toward creating charts as opposed to the more declarative style of Python&amp;rsquo;s &lt;a href=&quot;https://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; and base R. And it also includes a few example datasets for practicing ggplot2 functionality; for example, the &lt;code&gt;mpg&lt;/code&gt; dataset is a &lt;a href=&quot;http://ggplot2.tidyverse.org/reference/mpg.html&quot;&gt;dataset&lt;/a&gt; of the performance of popular models of cars in 1998 and 2008.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/mpg.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s say you want to create a &lt;a href=&quot;https://en.wikipedia.org/wiki/Scatter_plot&quot;&gt;scatter plot&lt;/a&gt;. Following &lt;a href=&quot;http://ggplot2.tidyverse.org/reference/geom_smooth.html&quot;&gt;a great example&lt;/a&gt; from the ggplot2 documentation, let&amp;rsquo;s plot the highway mileage of the car vs. the &lt;a href=&quot;https://en.wikipedia.org/wiki/Engine_displacement&quot;&gt;volume displacement&lt;/a&gt; of the engine. In ggplot2, first you instantiate the chart with the &lt;code&gt;ggplot()&lt;/code&gt; function, specifying the source dataset and the core aesthetics you want to plot, such as x, y, color, and fill. In this case, we set the core aesthetics to x = displacement and y = mileage, and add a &lt;code&gt;geom_point()&lt;/code&gt; layer to make a scatter plot:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;displ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hwy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/plot1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;As we can see, there is a negative correlation between the two metrics. I&amp;rsquo;m sure you&amp;rsquo;ve seen plots like these around the internet before. But with only a couple of lines of codes, you can make them look more contemporary.&lt;/p&gt;

&lt;p&gt;ggplot2 lets you add a well-designed theme with just one line of code. Relatively new to &lt;code&gt;ggplot2&lt;/code&gt; is &lt;code&gt;theme_minimal()&lt;/code&gt;, which &lt;a href=&quot;http://ggplot2.tidyverse.org/reference/ggtheme.html&quot;&gt;generates&lt;/a&gt; a muted style similar to &lt;a href=&quot;http://fivethirtyeight.com&quot;&gt;FiveThirtyEight&lt;/a&gt;&amp;lsquo;s modern data visualizations:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme_minimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/plot2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;But we can still add color. Setting a color aesthetic on a character/categorical variable will set the colors of the corresponding points, making it easy to differentiate at a glance.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;displ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hwy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme_minimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/plot3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Adding the color aesthetic certainly makes things much prettier. ggplot2 automatically adds a legend for the colors as well. 
However, for this particular visualization, it is difficult to see trends in the points for each class. A easy way around this is to add a &lt;a href=&quot;https://en.wikipedia.org/wiki/Least_squares&quot;&gt;least squares regression&lt;/a&gt; trendline for each class &lt;a href=&quot;http://ggplot2.tidyverse.org/reference/geom_smooth.html&quot;&gt;using&lt;/a&gt; &lt;code&gt;geom_smooth()&lt;/code&gt; (which normally adds a smoothed line, but since there isn&amp;rsquo;t a lot of data for each group, we force it to a linear model and do not plot confidence intervals)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;lm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;se&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/plot4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Pretty neat, and now comparative trends are much more apparent! For example, pickups and SUVs have similar efficiency, which makes intuitive sense.&lt;/p&gt;

&lt;p&gt;The chart axes should be labeled (&lt;em&gt;always&lt;/em&gt; label your charts!). All the typical labels, like &lt;code&gt;title&lt;/code&gt;, &lt;code&gt;x&lt;/code&gt;-axis, and &lt;code&gt;y&lt;/code&gt;-axis can be done with the &lt;code&gt;labs()&lt;/code&gt; function. But relatively new to ggplot2 are the &lt;code&gt;subtitle&lt;/code&gt; and &lt;code&gt;caption&lt;/code&gt; fields, both of do what you expect:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Efficiency of Popular Models of Cars&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subtitle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;By Class of Car&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Engine Displacement (liters)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Highway Miles per Gallon&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;caption&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;by Max Woolf — minimaxir.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/plot5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s a pretty good start. Now let&amp;rsquo;s take it to the next level.&lt;/p&gt;

&lt;h2&gt;How to Save A ggplot2 chart For Web&lt;/h2&gt;

&lt;p&gt;Something surprisingly undiscussed in the field of data visualization is how to &lt;em&gt;save&lt;/em&gt; a chart as a high quality image file. For example, with &lt;a href=&quot;https://products.office.com/en-us/excel&quot;&gt;Excel&lt;/a&gt; charts, Microsoft &lt;a href=&quot;https://support.office.com/en-us/article/Save-a-chart-as-a-picture-in-Excel-for-Windows-254bbf9a-1ce1-459f-914a-4902e8ca9217&quot;&gt;officially recommends&lt;/a&gt; to copy the chart, &lt;em&gt;paste it as an image back into Excel&lt;/em&gt;, then save the pasted image, without having any control over image quality and size in the browser (the &lt;em&gt;real&lt;/em&gt; best way to save an Excel/&lt;a href=&quot;https://www.apple.com/numbers/&quot;&gt;Numbers&lt;/a&gt; chart as an image for a webpage is to copy/paste the chart object into a &lt;a href=&quot;https://products.office.com/en-us/powerpoint&quot;&gt;PowerPoint&lt;/a&gt;/&lt;a href=&quot;https://www.apple.com/keynote/&quot;&gt;Keynote&lt;/a&gt; slide, and export &lt;em&gt;the slide&lt;/em&gt; as an image. This also makes it extremely easy to annotate/brand said chart beforehand in PowerPoint/Keynote).&lt;/p&gt;

&lt;p&gt;R IDEs such as &lt;a href=&quot;https://www.rstudio.com&quot;&gt;RStudio&lt;/a&gt; have a chart-saving UI with the typical size/filetype options. But if you save an image from this UI, the shapes and texts of the resulting image will be heavily aliased (R &lt;a href=&quot;https://danieljhocking.wordpress.com/2013/03/12/high-resolution-figures-in-r/&quot;&gt;renders images at 72 dpi&lt;/a&gt; by default, which is much lower than that of modern HiDPI/Retina displays).&lt;/p&gt;

&lt;p&gt;The data visualizations used earlier in this post were generated in-line as a part of an &lt;a href=&quot;http://rmarkdown.rstudio.com/r_notebooks.html&quot;&gt;R Notebook&lt;/a&gt;, but it is surprisingly difficult to extract the generated chart as a separate file. But ggplot2 also has &lt;code&gt;ggsave()&lt;/code&gt;, which saves the image to disk using antialiasing and makes the fonts/shapes in the chart look much better, and assumes a default dpi of 300. Saving charts using &lt;code&gt;ggsave()&lt;/code&gt;, and adjusting the sizes of the text and geoms to compensate for the higher dpi, makes the charts look very presentable. A width of 4 and a height of 3 results in a 1200x900px image, which if posted on a blog with a content width of ~600px (like mine), will render at full resolution on HiDPI/Retina displays, or downsample appropriately otherwise. Due to modern PNG compression, the file size/bandwidth cost for using larger images is minimal.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;displ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hwy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_smooth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;lm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;se&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme_minimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Efficiency of Popular Models of Cars&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subtitle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;By Class of Car&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Engine Displacement (liters)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Highway Miles per Gallon&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
         &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;caption&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;by Max Woolf — minimaxir.com&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggsave&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;tutorial-0.png&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-0.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Compare to the previous non-ggsave chart, which is more blurry around text/shapes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/plot5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;For posterity, here&amp;rsquo;s the same chart saved at 1200x900px using the RStudio image-saving UI:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/plot-1200-900.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Note that the antialiasing optimizations assume that you are &lt;em&gt;not&lt;/em&gt; uploading the final chart to a service like &lt;a href=&quot;https://medium.com&quot;&gt;Medium&lt;/a&gt; or &lt;a href=&quot;https://wordpress.com&quot;&gt;WordPress.com&lt;/a&gt;, which will compress the images and reduce the quality anyways. But if you are uploading it to Reddit or self-hosting your own blog, it&amp;rsquo;s definitely worth it.&lt;/p&gt;

&lt;h2&gt;Fancy Fonts&lt;/h2&gt;

&lt;p&gt;Changing the chart font is another way to add a personal flair.
Theme functions like &lt;code&gt;theme_minimal()&lt;/code&gt; accept a &lt;code&gt;base_family&lt;/code&gt; parameter. With that, you can specify any font family as the default instead of the base sans-serif. (On Windows, you may need to install the &lt;code&gt;extrafont&lt;/code&gt; package first). Fonts from &lt;a href=&quot;https://fonts.google.com&quot;&gt;Google Fonts&lt;/a&gt; are free and work easily with ggplot2 once installed. For example, we can use &lt;a href=&quot;https://fonts.google.com/specimen/Roboto&quot;&gt;Roboto&lt;/a&gt;, Google&amp;rsquo;s modern font which has also been getting a lot of usage on &lt;a href=&quot;https://stackoverflow.com&quot;&gt;Stack Overflow&lt;/a&gt;&amp;rsquo;s great ggplot2 &lt;a href=&quot;https://stackoverflow.blog/2017/06/15/developers-use-spaces-make-money-use-tabs/&quot;&gt;data visualizations&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme_minimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_family&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Roboto&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;A general text design guideline is to use fonts of different weights/widths for different hierarchies of content. In this case, we can use a bolder condensed font for the title, and deemphasize the subtitle and caption using lighter colors, all done using the &lt;code&gt;theme()&lt;/code&gt; &lt;a href=&quot;http://ggplot2.tidyverse.org/reference/theme.html&quot;&gt;function&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot.subtitle&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;element_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#666666&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot.title&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;element_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;family&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Roboto Condensed Bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
          &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot.caption&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;element_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;#AAAAAA&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth nothing that data visualizations posted on websites should be easily &lt;em&gt;legible&lt;/em&gt; for mobile-device users as well, hence the intentional use of larger fonts relative to charts typically produced in the desktop-oriented Excel.&lt;/p&gt;

&lt;p&gt;Additionally, all theming options can be set as a session default at the beginning of a script using &lt;code&gt;theme_set()&lt;/code&gt;, saving even more time instead of having to recreate the theme for each chart.&lt;/p&gt;

&lt;h2&gt;The &amp;ldquo;ggplot2 colors&amp;rdquo;&lt;/h2&gt;

&lt;p&gt;The &amp;ldquo;ggplot2 colors&amp;rdquo; for categorical variables are infamous for being the primary indicator of a chart being made with ggplot2. But there is a science to it; ggplot2 by default selects colors using the &lt;code&gt;scale_color_hue()&lt;/code&gt; &lt;a href=&quot;http://ggplot2.tidyverse.org/reference/scale_hue.html&quot;&gt;function&lt;/a&gt;, which selects colors in the HSL space by changing the hue [H] between 0 and 360, keeping saturation [S] and lightness [L] constant. As a result, ggplot2 selects the most &lt;em&gt;distinct&lt;/em&gt; colors possible while keeping lightness constant. For example, if you have 2 different categories, ggplot2 chooses the colors with h = 0 and h = 180; if 3 colors, h = 0, h = 120, h = 240, etc.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s smart, but does make a given chart lose distinctness when many other ggplot2 charts use the same selection methodology. A quick way to take advantage of this hue dispersion while still making the colors unique is to change the lightness; by default, &lt;code&gt;l = 65&lt;/code&gt;, but setting it slightly lower will make the charts look more professional/&lt;a href=&quot;https://www.bloomberg.com&quot;&gt;Bloomberg&lt;/a&gt;-esque.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p_color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_color_hue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;RColorBrewer&lt;/h2&gt;

&lt;p&gt;Another coloring option for ggplot2 charts are the &lt;a href=&quot;http://colorbrewer2.org/#type=sequential&amp;scheme=BuGn&amp;n=3&quot;&gt;ColorBrewer&lt;/a&gt; palettes implemented with the &lt;code&gt;RColorBrewer&lt;/code&gt; package, which are supported natively in ggplot2 with functions such as &lt;code&gt;scale_color_brewer()&lt;/code&gt;. The sequential palettes like &amp;ldquo;Blues&amp;rdquo; and &amp;ldquo;Greens&amp;rdquo; do what the name implies:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p_color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_color_brewer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Blues&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;A famous diverging palette for visualizations on /r/dataisbeautiful is the &amp;ldquo;Spectral&amp;rdquo; palette, which is a lighter rainbow (recommended for dark backgrounds)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;However, while the charts look pretty, it&amp;rsquo;s difficult to tell the categories apart. The qualitative palettes fix this problem, and have more distinct possibilities than the &lt;code&gt;scale_color_hue()&lt;/code&gt; approach mentioned earlier.&lt;/p&gt;

&lt;p&gt;Here are 3 examples of qualitative palettes, &amp;ldquo;Set1&amp;rdquo;, &amp;ldquo;Set2&amp;rdquo;, and &amp;ldquo;Set3,&amp;rdquo; whichever fit your preference.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-7.png&quot; alt=&quot;&quot;&gt;
&lt;img src=&quot;/img/ggplot2-web/tutorial-8.png&quot; alt=&quot;&quot;&gt;
&lt;img src=&quot;/img/ggplot2-web/tutorial-9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Viridis and Accessibility&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s mix up the visualization a bit. A rarely-used-but-very-useful ggplot2 geom is &lt;code&gt;geom2d_bin()&lt;/code&gt;, which counts the number of points in a given 2d spatial area:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;displ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hwy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geom_bin2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;...theming&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-tile.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;We see that the largest number of points are centered around (2,30). However, the default ggplot2 color palette for continuous variables is &lt;em&gt;boring&lt;/em&gt;. Yes, we can use the RColorBrewer sequential palettes above, but as noted, they aren&amp;rsquo;t perceptually distinct, and could cause issues for readers who are colorblind.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html&quot;&gt;viridis R package&lt;/a&gt; provides a set of 4 high-contrast palettes which are very colorblind friendly, and works easily with ggplot2 by extending a &lt;code&gt;scale_fill_viridis()/scale_color_viridis()&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;The default &amp;ldquo;viridis&amp;rdquo; palette has been increasingly popular on the web lately:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;p_color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale_fill_viridis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;viridis&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;magma&amp;rdquo; and &amp;ldquo;inferno&amp;rdquo; are similar, and give the data visualization a fiery edge:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-12.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Lastly, &amp;ldquo;plasma&amp;rdquo; is a mix between the 3 palettes above:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ggplot2-web/tutorial-13.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;FiveThirtyEight actually uses ggplot2 for their data journalism workflow &lt;a href=&quot;https://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/FiveThirtyEights-data-journalism-workflow-with-R?ocid=player&quot;&gt;in an interesting way&lt;/a&gt;; they render the base chart using ggplot2, but export it as as a SVG/PDF vector file which can scale to any size, and then the design team annotates/customizes the data visualization in &lt;a href=&quot;http://www.adobe.com/products/illustrator.html&quot;&gt;Adobe Illustrator&lt;/a&gt; before exporting it as a static PNG for the article (in general, I recommend using an external image editor to add text annotations to a data visualization because doing it manually in ggplot2 is inefficient).&lt;/p&gt;

&lt;p&gt;For general use cases, ggplot2 has very strong defaults for beautiful data visualizations. And certainly there is a lot &lt;em&gt;more&lt;/em&gt; you can do to make a visualization beautiful than what&amp;rsquo;s listed in this post, such as using facets and tweaking parameters of geoms for further distinction, but those are more specific to a given data visualization. In general, it takes little additional effort to make something &lt;em&gt;unique&lt;/em&gt; with ggplot2, and the effort is well worth it. And prettier charts are more persuasive, which is a good return-on-investment.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;You can view the R and ggplot2 code used to create the data visualizations in &lt;a href=&quot;http://minimaxir.com/notebooks/ggplot2-web/&quot;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&quot;https://github.com/minimaxir/ggplot2-web&quot;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 14 Aug 2017 09:00:00 -0700</pubDate>
        <link>https://minimaxir.com/2017/08/ggplot2-web/</link>
        <guid isPermaLink="true">https://minimaxir.com/2017/08/ggplot2-web/</guid>
        
        
        <category>Data</category>
        
        <category>Visualization</category>
        
      </item>
    
      <item>
        <title>Benchmarking TensorFlow on Cloud CPUs: Cheaper Deep Learning than Cloud GPUs</title>
        <description>&lt;p&gt;I&amp;rsquo;ve been working on a few personal deep learning projects with &lt;a href=&quot;https://github.com/fchollet/keras&quot;&gt;Keras&lt;/a&gt; and &lt;a href=&quot;https://www.tensorflow.org&quot;&gt;TensorFlow&lt;/a&gt;. However, training models for deep learning with cloud services such as &lt;a href=&quot;https://aws.amazon.com/ec2/&quot;&gt;Amazon EC2&lt;/a&gt; and &lt;a href=&quot;https://cloud.google.com/compute/&quot;&gt;Google Compute Engine&lt;/a&gt; isn&amp;rsquo;t free, and as someone who is currently unemployed, I have to keep an eye on extraneous spending and be as cost-efficient as possible (please support my work on &lt;a href=&quot;https://www.patreon.com/minimaxir&quot;&gt;Patreon&lt;/a&gt;!). I tried deep learning on the cheaper CPU instances instead of GPU instances to save money, and to my surprise, my model training was only slightly slower. As a result, I took a deeper look at the pricing mechanisms of these two types of instances to see if CPUs are more useful for my needs.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://cloud.google.com/compute/pricing#gpus&quot;&gt;pricing of GPU instances&lt;/a&gt; on Google Compute Engine starts at &lt;strong&gt;$0.745/hr&lt;/strong&gt; (by attaching a $0.700/hr GPU die to a $0.045/hr n1-standard-1 instance). A couple months ago, Google &lt;a href=&quot;https://cloudplatform.googleblog.com/2017/05/Compute-Engine-machine-types-with-up-to-64-vCPUs-now-ready-for-your-production-workloads.html&quot;&gt;announced&lt;/a&gt; CPU instances with up to 64 vCPUs on the modern Intel &lt;a href=&quot;https://en.wikipedia.org/wiki/Skylake_(microarchitecture)&quot;&gt;Skylake&lt;/a&gt; CPU architecture. More importantly, they can also be used in &lt;a href=&quot;https://cloud.google.com/compute/docs/instances/preemptible&quot;&gt;preemptible CPU instances&lt;/a&gt;, which live at most for 24 hours on GCE and can be terminated at any time (very rarely), but cost about &lt;em&gt;20%&lt;/em&gt; of the price of a standard instance. A preemptible n1-highcpu-64 instance with 64 vCPUs and 57.6GB RAM plus the premium for using Skylake CPUs is &lt;strong&gt;$0.509/hr&lt;/strong&gt;, about 2/3rds of the cost of the GPU instance.&lt;/p&gt;

&lt;p&gt;If the model training speed of 64 vCPUs is comparable to that of a GPU (or even slightly slower), it would be more cost-effective to use the CPUs instead. But that&amp;rsquo;s assuming the deep learning software and the GCE platform hardware operate at 100% efficiency; if they don&amp;rsquo;t (and they likely don&amp;rsquo;t), there may be &lt;em&gt;even more savings&lt;/em&gt; by scaling down the number of vCPUs and cost accordingly (a 32 vCPU instance with same parameters is half the price at &lt;strong&gt;$0.254/hr&lt;/strong&gt;, 16 vCPU at &lt;strong&gt;$0.127/hr&lt;/strong&gt;, etc).&lt;/p&gt;

&lt;p&gt;There aren&amp;rsquo;t any benchmarks for deep learning libraries with tons and tons of CPUs since there&amp;rsquo;s no demand, as GPUs are the &lt;a href=&quot;https://en.wikipedia.org/wiki/Occam%27s_razor&quot;&gt;Occam&amp;rsquo;s razor&lt;/a&gt; solution to deep learning hardware. But what might make counterintuitive but economical sense is to use CPUs instead of GPUs for deep learning training because of the massive cost differential afforded by preemptible instances, thanks to Google&amp;rsquo;s &lt;a href=&quot;https://en.wikipedia.org/wiki/Economies_of_scale&quot;&gt;economies of scale&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;Setup&lt;/h2&gt;

&lt;p&gt;I already have &lt;a href=&quot;https://github.com/minimaxir/deep-learning-cpu-gpu-benchmark&quot;&gt;benchmarking scripts&lt;/a&gt; of real-world deep learning use cases, &lt;a href=&quot;https://github.com/minimaxir/keras-cntk-docker&quot;&gt;Docker container environments&lt;/a&gt;, and results logging from my &lt;a href=&quot;http://minimaxir.com/2017/06/keras-cntk/&quot;&gt;TensorFlow vs. CNTK article&lt;/a&gt;. A few minor tweaks allow the scripts to be utilized for both CPU and GPU instances by setting CLI arguments. I also rebuilt &lt;a href=&quot;https://github.com/minimaxir/keras-cntk-docker/blob/master/Dockerfile&quot;&gt;the Docker container&lt;/a&gt; to support the latest version of TensorFlow (1.2.1), and created a &lt;a href=&quot;https://github.com/minimaxir/keras-cntk-docker/blob/master/Dockerfile-cpu&quot;&gt;CPU version&lt;/a&gt; of the container which installs the CPU-appropriate TensorFlow library instead.&lt;/p&gt;

&lt;p&gt;There is a notable CPU-specific TensorFlow behavior; if you install from &lt;code&gt;pip&lt;/code&gt; (as the&lt;a href=&quot;https://www.tensorflow.org/install/&quot;&gt; official instructions&lt;/a&gt; and tutorials recommend) and begin training a model in TensorFlow, you&amp;rsquo;ll see these warnings in the console:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/tensorflow-console.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In order to fix the warnings and benefit from these &lt;a href=&quot;https://en.wikipedia.org/wiki/SSE4#SSE4.2&quot;&gt;SSE4.2&lt;/a&gt;/&lt;a href=&quot;https://en.wikipedia.org/wiki/Advanced_Vector_Extensions&quot;&gt;AVX&lt;/a&gt;/&lt;a href=&quot;https://en.wikipedia.org/wiki/FMA_instruction_set&quot;&gt;FMA&lt;/a&gt; optimizations, we &lt;a href=&quot;https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions&quot;&gt;compile TensorFlow from source&lt;/a&gt;, and I created a &lt;a href=&quot;https://github.com/minimaxir/keras-cntk-docker/blob/master/Dockerfile-cpu-compiled&quot;&gt;third Docker container&lt;/a&gt; to do just that. When training models in the new container, &lt;a href=&quot;https://github.com/tensorflow/tensorflow/issues/10689&quot;&gt;most&lt;/a&gt; of the warnings no longer show, and (spoiler alert) there is indeed a speed boost in training time.&lt;/p&gt;

&lt;p&gt;Therefore, we can test three major cases with Google Compute Engine:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A Tesla K80 GPU instance.&lt;/li&gt;
&lt;li&gt;A 64 Skylake vCPU instance where TensorFlow is installed via &lt;code&gt;pip&lt;/code&gt; (along with testings at 8/16/32 vCPUs).&lt;/li&gt;
&lt;li&gt;A 64 Skylake vCPU instance where TensorFlow is compiled (&lt;code&gt;cmp&lt;/code&gt;) with CPU instructions (+ 8/16/32 vCPUs).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Results&lt;/h2&gt;

&lt;p&gt;For each model architecture and software/hardware configuration, I calculate the &lt;strong&gt;total training time relative to the GPU instance training&lt;/strong&gt; for running the model training for the provided test script. In all cases, the GPU &lt;em&gt;should&lt;/em&gt; be the fastest training configuration, and systems with more processors should train faster than those with fewer processors.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start using the &lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot;&gt;MNIST dataset&lt;/a&gt; of handwritten digits plus the common multilayer perceptron (MLP) architecture, with dense fully-connected layers. Lower training time is better. All configurations below the horizontal dotted line are better than GPUs; all configurations above the dotted line are worse than GPUs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-5.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Here, the GPU is the fastest out of all the platform configurations, but there are other curious trends: the performance between 32 vCPUs and 64 vCPUs is similar, and the compiled TensorFlow library is indeed a significant improvement in training speed &lt;em&gt;but only for 8 and 16 vCPUs&lt;/em&gt;. Perhaps there are overheads negotiating information between vCPUs that eliminate the performance advantages of more vCPUs, and perhaps these overheads are &lt;em&gt;different&lt;/em&gt; with the CPU instructions of the compiled TensorFlow. In the end, it&amp;rsquo;s a &lt;a href=&quot;https://en.wikipedia.org/wiki/Black_box&quot;&gt;black box&lt;/a&gt;, which is why I prefer black box benchmarking all configurations of hardware instead of theorycrafting.&lt;/p&gt;

&lt;p&gt;Since the difference between training speeds of different vCPU counts is minimal, there is definitely an advantage by scaling down. For each model architecture and configuration, I calculate a &lt;strong&gt;normalized training cost relative to the cost of GPU instance training&lt;/strong&gt;. Because GCE instance costs are prorated (unlike Amazon EC2), we can simply calculate experiment cost by multiplying the total number of seconds the experiment runs by the cost of the instance (per second). Ideally, we want to &lt;em&gt;minimize&lt;/em&gt; cost.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Lower CPU counts are &lt;em&gt;much&lt;/em&gt; more cost-effective for this problem, when going as low as possible is better.&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s look at the same dataset with a convolutional neural network (CNN) approach for digit classification:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-7.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-8.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;GPUs are unsurprisingly more than twice as fast as any CPU approach at CNNs, but cost structures are still the same, except that 64 vCPUs are &lt;em&gt;worse&lt;/em&gt; than GPUs cost-wise, with 32 vCPUs training even faster than with 64 vCPUs.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s go deeper with CNNs and look at the &lt;a href=&quot;https://www.cs.toronto.edu/%7Ekriz/cifar.html&quot;&gt;CIFAR-10&lt;/a&gt; image classification dataset, and a model which utilizes a deep covnet + a multilayer perceptron and ideal for image classification (similar to the &lt;a href=&quot;https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3&quot;&gt;VGG-16&lt;/a&gt; architecture).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-9.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-10.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Similar behaviors as in the simple CNN case, although in this instance all CPUs perform better with the compiled TensorFlow library.&lt;/p&gt;

&lt;p&gt;The fasttext algorithm, used here on the &lt;a href=&quot;http://ai.stanford.edu/%7Eamaas/data/sentiment/&quot;&gt;IMDb reviews dataset&lt;/a&gt; to determine whether a review is positive or negative, classifies text extremely quickly relative to other methods. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-3.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;In this case, GPUs are much, much faster than CPUs. The benefit of lower numbers of CPU isn&amp;rsquo;t as dramatic; although as an aside, the &lt;a href=&quot;https://github.com/facebookresearch/fastText&quot;&gt;official fasttext implementation&lt;/a&gt; is &lt;em&gt;designed&lt;/em&gt; for large amounts of CPUs and handles parallelization much better.&lt;/p&gt;

&lt;p&gt;The Bidirectional long-short-term memory (LSTM) architecture is great for working with text data like IMDb reviews, but after my previous benchmark article, &lt;a href=&quot;https://news.ycombinator.com/item?id=14538086&quot;&gt;commenters on Hacker News&lt;/a&gt; noted that TensorFlow uses an inefficient implementation of the LSTM on the GPU, so perhaps the difference will be more notable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;Wait, what? GPU training of Bidirectional LSTMs is &lt;em&gt;twice as slow&lt;/em&gt; as any CPU configuration? Wow. (In fairness, the benchmark uses the Keras LSTM default of &lt;code&gt;implementation=0&lt;/code&gt; which is better on CPUs while &lt;code&gt;implementation=2&lt;/code&gt; is better on GPUs, but it shouldn&amp;rsquo;t result in that much of a differential)&lt;/p&gt;

&lt;p&gt;Lastly, LSTM text generation of &lt;a href=&quot;https://en.wikipedia.org/wiki/Friedrich_Nietzsche&quot;&gt;Nietzsche&amp;rsquo;s&lt;/a&gt; &lt;a href=&quot;https://s3.amazonaws.com/text-datasets/nietzsche.txt&quot;&gt;writings&lt;/a&gt; follows similar patterns to the other architectures, but without the drastic hit to the GPU.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-11.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cpu-or-gpu/dl-cpu-gpu-12.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;As it turns out, using 64 vCPUs is &lt;em&gt;bad&lt;/em&gt; for deep learning as current software/hardware architectures can&amp;rsquo;t fully utilize all of them, and it often results in the exact same performance (or &lt;em&gt;worse&lt;/em&gt;) than with 32 vCPUs. In terms balancing both training speed and cost, training models with &lt;strong&gt;16 vCPUs + compiled TensorFlow&lt;/strong&gt; seems like the winner. The 30%-40% speed boost of the compiled TensorFlow library was an unexpected surprise, and I&amp;rsquo;m shocked Google doesn&amp;rsquo;t offer a precompiled version of TensorFlow with these CPU speedups since the gains are nontrivial.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth nothing that the cost advantages shown here are &lt;em&gt;only&lt;/em&gt; possible with preemptible instances; regular high-CPU instances on Google Compute Engine are about 5x as expensive, and as a result eliminate the cost benefits completely. Hooray for economies of scale!&lt;/p&gt;

&lt;p&gt;A major implicit assumption with the cloud CPU training approach is that you don&amp;rsquo;t need a trained model ASAP. In professional use cases, time may be too valuable to waste, but in personal use cases where someone can just leave a model training overnight, it&amp;rsquo;s a very, very good and cost-effective option, and one that I&amp;rsquo;ll now utilize.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;&lt;em&gt;All scripts for running the benchmark are available in &lt;a href=&quot;https://github.com/minimaxir/deep-learning-cpu-gpu-benchmark&quot;&gt;this GitHub repo&lt;/a&gt;. You can view the R/ggplot2 code used to process the logs and create the visualizations in &lt;a href=&quot;http://minimaxir.com/notebooks/deep-learning-cpu-gpu/&quot;&gt;this R Notebook&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 05 Jul 2017 09:00:00 -0700</pubDate>
        <link>https://minimaxir.com/2017/07/cpu-or-gpu/</link>
        <guid isPermaLink="true">https://minimaxir.com/2017/07/cpu-or-gpu/</guid>
        
        
        <category>Data</category>
        
        <category>Visualization</category>
        
      </item>
    
  </channel>
</rss>
