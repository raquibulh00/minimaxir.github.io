<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Reddit on Max Woolf&#39;s Blog</title><link>/tags/reddit/</link><description>Recent content in Reddit on Max Woolf&#39;s Blog</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Copyright Max Woolf &amp;copy; {year}</copyright><lastBuildDate>Tue, 20 Jun 2017 08:00:00 +0000</lastBuildDate><atom:link href="/tags/reddit/index.xml" rel="self" type="application/rss+xml"/><item><title>The Decline of Imgur on Reddit and the Rise of Reddit&#39;s Native Image Hosting</title><link>/2017/06/imgur-decline/</link><pubDate>Tue, 20 Jun 2017 08:00:00 +0000</pubDate><guid>/2017/06/imgur-decline/</guid><description>
&lt;p&gt;Last week, Bloomberg &lt;a href=&#34;https://www.bloomberg.com/news/articles/2017-06-17/reddit-said-to-be-raising-funds-valuing-startup-at-1-7-billion&#34; target=&#34;_blank&#34;&gt;reported&lt;/a&gt; that Reddit was raising about $150 Million in venture capital at a valuation of $1.7 billion. Since Reddit&amp;rsquo;s data is &lt;a href=&#34;http://minimaxir.com/2015/10/reddit-bigquery/&#34; target=&#34;_blank&#34;&gt;public on BigQuery&lt;/a&gt;, I quickly checked if there were any recent user engagement growth spurts which could justify such a high worth. Here&amp;rsquo;s an example BigQuery which aggregates the total number of Reddit submissions made for each month until the end of April 2017:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;#standardSQL
SELECT DATE_TRUNC(DATE(TIMESTAMP_SECONDS(created_utc)), MONTH) as mon,
COUNT(*) as num_submissions,
FROM `fh-bigquery.reddit_posts.*`
WHERE (_TABLE_SUFFIX BETWEEN &#39;2016_01&#39; AND &#39;2017_04&#39; OR _TABLE_SUFFIX = &#39;full_corpus_201512&#39;)
GROUP BY mon
ORDER BY mon
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/imgur-decline/reddit-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As it turns out, Reddit did indeed get a large boost in activity toward the end of 2016, likely due to the &lt;em&gt;heated&lt;/em&gt; discussions and events around the &lt;a href=&#34;https://en.wikipedia.org/wiki/United_States_presidential_election,_2016&#34; target=&#34;_blank&#34;&gt;U.S. Presidential Election&lt;/a&gt;. But Reddit has maintained the growth rate since then, which is very appealing to potential investors.&lt;/p&gt;
&lt;p&gt;How are other sites benefiting from Reddit&amp;rsquo;s growth? &lt;a href=&#34;http://imgur.com&#34; target=&#34;_blank&#34;&gt;Imgur&lt;/a&gt;, an image-host developed to be the &lt;em&gt;de facto&lt;/em&gt; image hosting service for Reddit, shared in Reddit&amp;rsquo;s continual growth&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/imgur-decline/reddit-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;hellip;until mid-2016, when Imgur submission activity abruptly dropped. What happened?&lt;/p&gt;
&lt;p&gt;Coincidentally in mid-2016, Reddit &lt;a href=&#34;https://techcrunch.com/2016/05/25/reddit-image-uploads/&#34; target=&#34;_blank&#34;&gt;made itself&lt;/a&gt; an image host for submissions to the site. Initially limited to uploads via the iOS/Android apps, Reddit then allowed desktop users to upload images through a &lt;a href=&#34;https://www.reddit.com/r/changelog/comments/4kuk2j/reddit_change_introducing_image_uploading_beta/&#34; target=&#34;_blank&#34;&gt;beta rollout&lt;/a&gt; starting May 24th, and a full &lt;a href=&#34;https://www.reddit.com/r/announcements/comments/4p5dm9/image_hosting_on_reddit/&#34; target=&#34;_blank&#34;&gt;sitewide release&lt;/a&gt; on June 21st.&lt;/p&gt;
&lt;p&gt;How many Reddit-hosted image submissions are there compared to the number of Imgur submissions?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/imgur-decline/reddit-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wow, native Reddit images caught on.&lt;/p&gt;
&lt;h2 id=&#34;market-share&#34;&gt;Market Share&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/img/imgur-decline/pics.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Did the rise of Reddit-hosted images cause the decline of Imgur on Reddit? Let&amp;rsquo;s look at the daily number of Imgur submissions and Reddit-hosted Image submissions from December 2015 to April 2017, normalized by the total number of sitewide submissions on that day. This gives us a Reddit &amp;ldquo;market share&amp;rdquo; metric for both services.&lt;/p&gt;
&lt;p&gt;Additionally, we can plot vertical lines representing the dates when Reddit-hosted images rolled out in the limited beta release and the full sitewide release to see if there is a link between those events and submission behavior.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/imgur-decline/reddit-4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Before Reddit added native image hosting, Imgur accounted for 15% of all submissions to Reddit. Now it&amp;rsquo;s below 9%. More Reddit-hosted images are being shared on Reddit than images from Imgur.&lt;/p&gt;
&lt;p&gt;Instead of looking at all of Reddit, where spam subreddits could skew the results, we can also look at the largest image-only subreddits: &lt;a href=&#34;https://www.reddit.com/r/pics/&#34; target=&#34;_blank&#34;&gt;/r/pics&lt;/a&gt; and &lt;a href=&#34;https://www.reddit.com/r/gifs/&#34; target=&#34;_blank&#34;&gt;/r/gifs&lt;/a&gt;, both of which were a part of the beta rollout.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/imgur-decline/reddit-5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here, the impact of the two rollouts is much noticeable, with immediate increases in Reddit-hosted image market share after each rollout, and proportional decreases in Imgur market share. The growth rate after the beta release is flat for both services, but when Reddit image hosting becomes sitewide, the market shares of Reddit-hosted/Imgur images increase/decrease linearly over time once users officially learn that the native image upload functionality exists. And these trends do not appear to be slowing down.&lt;/p&gt;
&lt;h2 id=&#34;a-silver-lining&#34;&gt;A Silver Lining?&lt;/h2&gt;
&lt;p&gt;Obviously Imgur does not like losing a &lt;em&gt;large&lt;/em&gt; chunk of traffic, but there&amp;rsquo;s a possibility that this outcome will be better for the business than what&amp;rsquo;s implied from the charts above.&lt;/p&gt;
&lt;p&gt;Hosting images on the internet isn&amp;rsquo;t free, and bandwidth costs are the primary reason dedicated image hosts have died off over the years. Direct image links which show the user only the image and nothing else are convenient, but they are pure loss for the service. That&amp;rsquo;s why image hosts encourage linking to the image on a landing page of the website, filled with ads which generate an expected revenue greater than the cost of serving the image.&lt;/p&gt;
&lt;p&gt;After a user uploads an image to Imgur on the desktop, the user is given two share links that can be submitted to sites like Reddit: an image link that goes to the image + ads, and a direct link to the image.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/imgur-decline/imgur_direct.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Recently, Imgur has &lt;a href=&#34;https://www.reddit.com/r/assholedesign/comments/5gs96k/just_show_me_the_fucking_image_imgur/&#34; target=&#34;_blank&#34;&gt;pushed app downloads&lt;/a&gt; when visiting the site on an iOS/Android device, including &lt;a href=&#34;https://www.reddit.com/r/assholedesign/comments/695efj/upload_image_on_imgur_mobile_has_been_replaced_by/&#34; target=&#34;_blank&#34;&gt;disabling uploads&lt;/a&gt; in the mobile browser. When sharing an image from the Imgur app, the &lt;em&gt;only&lt;/em&gt; way to share an image is through the image link, which could lead to an increase in the proportion of ad-filled Imgur image links on Reddit. Said increase could counteract the decrease in total Imgur submissions, and Imgur could actually come out ahead.&lt;/p&gt;
&lt;p&gt;With BigQuery, we can check the percentage of all Imgur submissions to Reddit which are direct links and the percentage which are indirect/lead to a landing page, and see if the ratio changes along the same time horizon used above:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/imgur-decline/reddit-6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Welp. No significant change in the ratio over time, eliminating that possible silver lining.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Note that the decline of Imgur on Reddit says nothing about Imgur as a business; it&amp;rsquo;s entirely possible that Imgur&amp;rsquo;s traffic on the main site itself is sufficient for growth. But the loss of Reddit traffic certainly can&amp;rsquo;t be ignored, and it&amp;rsquo;s interesting to visualize how quickly a service can be replaced when there&amp;rsquo;s an equivalent native feature.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s worth nothing that new competitors in the image space such as &lt;a href=&#34;https://giphy.com&#34; target=&#34;_blank&#34;&gt;Giphy&lt;/a&gt; utilize image hosting as a &lt;em&gt;secondary&lt;/em&gt; service. Instead, they focus on building a repository of images which can be licensed and accessed programmatically by other services like Slack, Facebook, and Twitter. And Giphy has raised &lt;a href=&#34;https://www.crunchbase.com/organization/giphy#/entity&#34; target=&#34;_blank&#34;&gt;$150 Million&lt;/a&gt; total with this approach, so perhaps the image hosting market itself has indeed changed.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;You can view the R, ggplot2 code, and BigQueries used to visualize the Reddit data in &lt;a href=&#34;http://minimaxir.com/notebooks/imgur-decline/&#34; target=&#34;_blank&#34;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&#34;https://github.com/minimaxir/imgur-decline&#34; target=&#34;_blank&#34;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;</description></item><item><title>What Percent of the Top-Voted Comments in Reddit Threads Were Also 1st Comment?</title><link>/2016/11/first-comment/</link><pubDate>Mon, 07 Nov 2016 06:30:00 +0000</pubDate><guid>/2016/11/first-comment/</guid><description>
&lt;p&gt;&lt;a href=&#34;https://www.reddit.com&#34; target=&#34;_blank&#34;&gt;Reddit&lt;/a&gt; threads can be a crowded place. In popular subreddits such as &lt;a href=&#34;https://www.reddit.com/r/AskReddit/&#34; target=&#34;_blank&#34;&gt;/r/AskReddit&lt;/a&gt; and &lt;a href=&#34;https://www.reddit.com/r/pics/&#34; target=&#34;_blank&#34;&gt;/r/pics&lt;/a&gt;, Reddit submissions can receive hundreds, even &lt;em&gt;thousands&lt;/em&gt; of unique comments. Some comments inevitably become lost in the noise. Reddit&amp;rsquo;s &lt;a href=&#34;https://redditblog.com/2009/10/15/reddits-new-comment-sorting-system/&#34; target=&#34;_blank&#34;&gt;ranking algorithm&lt;/a&gt; attempts to rectify this by determining comment ranking using both time and community voting; comments in a thread, by default, are ordered based on the &lt;strong&gt;points score&lt;/strong&gt; (upvotes - downvotes) the comment receives, subject to a rank decay based on the age of the comment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/reddit_askreddit.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In theory, this system should allow comments that posted later in the thread&amp;rsquo;s lifetime to rank much higher temporarily, then Redditors can vote on the new comment; if the new comment is good, it can now rise to the top and therefore the content which would otherwise be buried is now surfaced. Anecdotally, that doesn&amp;rsquo;t be the case with Reddit&amp;rsquo;s modern algorithm; comments made late in the thread appear at the bottom, where they likely will not receive any upvotes (this led to a minor &amp;ldquo;&lt;a href=&#34;https://www.google.com/#q=site:reddit.com+%22late+to+this+thread%22&#34; target=&#34;_blank&#34;&gt;I know I&amp;rsquo;m late to this thread but&amp;hellip;&lt;/a&gt;&amp;rdquo; meme).&lt;/p&gt;
&lt;p&gt;I, of course, am not satisfied with anecdotes. A month ago, a Redditor asked &amp;ldquo;&lt;a href=&#34;https://www.reddit.com/r/TheoryOfReddit/comments/53d5ep/what_percentage_of_the_top_comment_in_threads/&#34; target=&#34;_blank&#34;&gt;What percentage of the top comment in threads were also the first comment?&lt;/a&gt;&amp;rdquo; Why not calculate it &lt;em&gt;exactly&lt;/em&gt; using big data?&lt;/p&gt;
&lt;h2 id=&#34;getting-the-reddit-data&#34;&gt;Getting the Reddit Data&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;You can view all the &lt;a href=&#34;https://www.r-project.org&#34; target=&#34;_blank&#34;&gt;R&lt;/a&gt; and &lt;a href=&#34;http://ggplot2.org&#34; target=&#34;_blank&#34;&gt;ggplot2&lt;/a&gt; code used to query, analyze, and visualize the Reddit data in &lt;a href=&#34;http://minimaxir.com/notebooks/first-comment/&#34; target=&#34;_blank&#34;&gt;this R Notebook&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In order to process a great amount of Reddit data, I turned to &lt;a href=&#34;https://cloud.google.com/bigquery/&#34; target=&#34;_blank&#34;&gt;BigQuery&lt;/a&gt;, which now has data for &lt;a href=&#34;https://www.reddit.com/r/datasets/comments/590re2/updated_reddit_comments_and_posts_updated_on/&#34; target=&#34;_blank&#34;&gt;all Reddit comments&lt;/a&gt; until September 2016.&lt;/p&gt;
&lt;p&gt;For this analysis, I will only look at the &lt;strong&gt;top-level comments&lt;/strong&gt; (i.e. comments which are not replies to other comments), since those are the ones most affected by the ordering and submission of new comments. Additionally I will only look at comments within Reddit threads with &lt;strong&gt;atleast 30 top-level comments&lt;/strong&gt; to ensure I only look at threads with sufficient discussion and where late posts are more likely to become hidden. It also mirrors the &amp;ldquo;late to this thread&amp;rdquo; meme: can posts be &lt;em&gt;too&lt;/em&gt; late?&lt;/p&gt;
&lt;p&gt;The queried data will be all comments posted from January 2015 to September 2016: this give a good balance of sample size and foundation around the modern comment ranking algorithms. The total number of Reddit comments analyzed, after filtering on threads with sufficient conversation and limiting the scope to the first 100 comments of a thread scoring within the Top 100, is &lt;strong&gt;n = 86,561,476&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;With clever use of BigQuery window functions, I obtained the aggregate data, counting the number of comments from the filtered Reddit threads at each voting rank and created rank.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/data.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;visualizing-the-discussion&#34;&gt;Visualizing the Discussion&lt;/h2&gt;
&lt;p&gt;Filtering on the top-voted comments (&lt;code&gt;score_rank = 1&lt;/code&gt;) only, &lt;em&gt;what percent of the top-voted comments in Reddit threads were also 1st Comment?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/reddit-first-4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The answer is &lt;strong&gt;17.24%&lt;/strong&gt; of all top-voted comments! That&amp;rsquo;s certainly more than what I expected! Additionally, 56% of the top-voted comments were posted within the first 5 comments, and 77% within the first 10 comments. The chart follows a &lt;a href=&#34;https://en.wikipedia.org/wiki/Power_law&#34; target=&#34;_blank&#34;&gt;power-law distribution&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s invert it: filtering on only the first comments (&lt;code&gt;created_rank = 1&lt;/code&gt;) made in comment threads, &lt;em&gt;what percentage of the 1st Comments in Reddit threads were also the top-voted comment?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/reddit-first-3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By construction, the answer is the same as before (17.24%), however the followup proportions are slightly different, with the first comment ranking within the Top 5 comments 46% of the time, and within the Top 10 comments 62% of the time.&lt;/p&gt;
&lt;p&gt;It may be worth it to visualize both dimensions at the same time using a heatmap, with the created rank on one axis, score rank on the other, and a z-axis representing the number of comments at each rank pairing. We can also add a faint contour line to help visualize clusters of the data. Putting it together:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/reddit-first-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Woah, most of the values are constrained between the semisquare constrained by the first 5 comments and the top 5 comments! But it&amp;rsquo;s harder to see trends, so let&amp;rsquo;s try applying a logarithmic base-10 scaling on the comment count:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/reddit-first-2a.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Much better! We can see a grouping of the 5x5 semisquare, but also smaller groupings of a 30x30 shape (this may possibly be due to the 30 comment filter threshold), a faint 60x60 shape, and &lt;em&gt;voids&lt;/em&gt; in the upper-left and lower-right corners.&lt;/p&gt;
&lt;p&gt;From the 2D heatmap, there appears to be a &lt;strong&gt;positive correlation&lt;/strong&gt; between the rank of the comment and the time it was submitted. Ideally, if Reddit&amp;rsquo;s algorithm correctly cycled posts so that each comment gets a fair chance at going viral, then there should be &lt;strong&gt;no correlation&lt;/strong&gt; between score rank and time posted.&lt;/p&gt;
&lt;h2 id=&#34;analysis-by-subreddit&#34;&gt;Analysis by Subreddit&lt;/h2&gt;
&lt;p&gt;When working with Reddit data, it is always important to facet the analysis by subreddit, as subreddits can have idiosyncratic behaviors which deviate from general Reddit behavior. As noted in the original Reddit thread with the initial question, it is possible that the percentage of first comments becoming top comment is &amp;ldquo;higher in lighter subs (funny, pics, videos) than more serious subs (askscience, history, etc).&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I tweaked the BigQuery above to retrieve the same data for each of the Top 100 subreddits (determined by unique commenter count over the same time period). Afterward, via scripting, I created a 1D proportion-of-first-comments-by-score-rank and 2D heatmaps for each subreddit. You can view and download the 1D charts &lt;a href=&#34;https://github.com/minimaxir/first-comment/tree/master/img-1d&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, and the 2D heatmaps &lt;a href=&#34;https://github.com/minimaxir/first-comment/tree/master/img-2d&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For example, here&amp;rsquo;s the chart of first-comment-rankings for &lt;a href=&#34;https://www.reddit.com/r/IAmA/&#34; target=&#34;_blank&#34;&gt;/r/IAmA&lt;/a&gt;, one of Reddit&amp;rsquo;s biggest subreddits where normal Redditors can ask celebrities any question they want.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/IAmA-1d.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unlike the all-Reddit chart, the distribution of first-comment proportions is more uniform instead of following a power law. It makes sense in theory; people would likely upvote top-level questions which the original poster replied to, so there should be less of a bias toward the first top-level comment.&lt;/p&gt;
&lt;p&gt;What does the 2D heatmap show?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/IAmA-2d.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Damn it.&lt;/p&gt;
&lt;p&gt;While the 1D behavior is different, the overall 2D behavior is the same albeit with larger voids (indeed, in the heatmap, you can see at &lt;code&gt;created_rank = 1&lt;/code&gt;, the vertical strip doesn&amp;rsquo;t fit the pattern).&lt;/p&gt;
&lt;p&gt;It turns out that most /r/IAmA threads have this comment:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/automoderator.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As it&amp;rsquo;s made by a robot, it&amp;rsquo;s always the first comment, and it gets ignored/downvoted in normal circumstances. Other subreddits with the same pattern of 1D irregularities, 2D regularities, and AutoModerator usage are &lt;a href=&#34;https://www.reddit.com/r/gameofthrones/&#34; target=&#34;_blank&#34;&gt;/r/gameofthrones&lt;/a&gt;, &lt;a href=&#34;https://www.reddit.com/r/photoshopbattles/&#34; target=&#34;_blank&#34;&gt;/r/photoshopbattles&lt;/a&gt;, and &lt;a href=&#34;https://www.reddit.com/r/WritingPrompts/&#34; target=&#34;_blank&#34;&gt;/r/WritingPrompts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Some subreddits have more uniformity than typical Reddit rank behavior. In &lt;a href=&#34;https://www.reddit.com/r/funny/&#34; target=&#34;_blank&#34;&gt;/r/funny&lt;/a&gt;, &lt;a href=&#34;https://www.reddit.com/r/leagueoflegends/&#34; target=&#34;_blank&#34;&gt;/r/leagueoflegends&lt;/a&gt;, &lt;a href=&#34;https://www.reddit.com/r/pics/&#34; target=&#34;_blank&#34;&gt;/r/pics&lt;/a&gt;, &lt;a href=&#34;https://www.reddit.com/r/todayilearned/&#34; target=&#34;_blank&#34;&gt;/r/todayilearned&lt;/a&gt;, and &lt;a href=&#34;https://www.reddit.com/r/video/&#34; target=&#34;_blank&#34;&gt;/r/videos&lt;/a&gt; (i.e. many default subreddits), there is no upper-left void (early comments can be poorly ranked) and the bottom-right void is minimized but still present.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/funny-2d.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/leagueoflegends-2d.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Inversely, there are subreddits where the correlation is obvious. &lt;a href=&#34;https://www.reddit.com/r/pcmasterrace/&#34; target=&#34;_blank&#34;&gt;/r/pcmasterrace&lt;/a&gt; and /r/gonewild both exhibit very straight lines, and are subreddits where the comments themselves are not very constructive, so whatever gets posted gets upvoted anyways.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/pcmasterrace-2d.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/first-comment/gonewild-2d.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Rushing to say &lt;strong&gt;FIRST!!1!11!&lt;/strong&gt; in a comments section of a blog post or forum thread is a meme that long predates Reddit. However, rushing to make the first comment in a Reddit thread may have strategic merit if you want to get your voice heard.&lt;/p&gt;
&lt;p&gt;Even in the most optimistic circumstances, comments that are late to a thread have a very, very low probability of becoming one of the top comments. In fairness, it&amp;rsquo;s hard to determine with public Reddit data if tweaking the ranking algorithm such that new comments will always rank at the top initially will actually improve the Reddit user experience as a whole. On the other hand, this behavior presents an opportunity: if there is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Long_tail&#34; target=&#34;_blank&#34;&gt;long tail&lt;/a&gt; of Reddit content that is unjustifiably being buried due to lack of attention, then perhaps there is a &lt;em&gt;business opportunity&lt;/em&gt; in creating a service to discover and resurface quality comments&amp;hellip;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;You can view all the &lt;a href=&#34;https://www.r-project.org&#34; target=&#34;_blank&#34;&gt;R&lt;/a&gt; and &lt;a href=&#34;http://ggplot2.org&#34; target=&#34;_blank&#34;&gt;ggplot2&lt;/a&gt; code used to query, analyze, and visualize the Reddit data in &lt;a href=&#34;http://minimaxir.com/notebooks/first-comment/&#34; target=&#34;_blank&#34;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&#34;https://github.com/minimaxir/first-comment&#34; target=&#34;_blank&#34;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Methods for Finding Related Reddit Subreddits with Simple Set Theory</title><link>/2016/06/reddit-related-subreddits/</link><pubDate>Mon, 20 Jun 2016 08:20:00 +0000</pubDate><guid>/2016/06/reddit-related-subreddits/</guid><description>
&lt;p&gt;I recently &lt;a href=&#34;http://minimaxir.com/2016/05/reddit-graph/&#34; target=&#34;_blank&#34;&gt;wrote a post&lt;/a&gt; on how to visualize &lt;a href=&#34;https://en.wikipedia.org/wiki/Graph_theory&#34; target=&#34;_blank&#34;&gt;network graphs&lt;/a&gt; of &lt;a href=&#34;https://www.reddit.com&#34; target=&#34;_blank&#34;&gt;Reddit&lt;/a&gt; subreddits.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One of the reasons I&amp;rsquo;ve been researching the topic is to find a good way to facilitate discovery of lesser-known subreddits, as Reddit is doing a terrible job at it (although they have been trying a &lt;a href=&#34;https://www.reddit.com/r/changelog/comments/4o4qjh/more_small_tests_to_improve_user_experience_live/d49leyu?context=2&#34; target=&#34;_blank&#34;&gt;few new experiments&lt;/a&gt; &lt;em&gt;very recently&lt;/em&gt;). As it turns out, invoking graph theory is overkill. Even fancy machine learning approaches like &lt;a href=&#34;https://en.wikipedia.org/wiki/Collaborative_filtering&#34; target=&#34;_blank&#34;&gt;collaborative filtering&lt;/a&gt;, while powerful, may not be required to help Redditors discover new things.&lt;/p&gt;
&lt;h2 id=&#34;finding-related-subreddits&#34;&gt;Finding Related Subreddits&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s say we have two sets: Set &lt;em&gt;A&lt;/em&gt;, where &lt;em&gt;A&lt;/em&gt; represents the number of active users in a given subreddit, and set &lt;em&gt;B&lt;/em&gt;, where &lt;em&gt;B&lt;/em&gt; is the set of active users in a subreddit. The intersection of Sets &lt;em&gt;A&lt;/em&gt; and &lt;em&gt;B&lt;/em&gt; (A ∩ B) represents users who are active in &lt;em&gt;both&lt;/em&gt; subreddits.&lt;/p&gt;
&lt;p&gt;Using &lt;a href=&#34;https://cloud.google.com/bigquery/&#34; target=&#34;_blank&#34;&gt;BigQuery&lt;/a&gt;, I can get the comment data from &lt;strong&gt;ALL&lt;/strong&gt; public Reddit subreddits, as otherwise this technique would not work well using any smaller subset. The network graph edgelist conveniently gives (A ∩ B), obtained &lt;a href=&#34;http://minimaxir.com/2016/05/reddit-graph/&#34; target=&#34;_blank&#34;&gt;as described in my previous post&lt;/a&gt;, which calculates the number of active users for all pairs of subreddits (defining &amp;ldquo;active users&amp;rdquo; as users who have made a comment in at least 5 unique threads in a given subreddit within the past 6 months).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/active-edge.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case, we can filter the edgelist to only allow intersections where there are at least 10 active users; this prevents including dead and personal subreddits.&lt;/p&gt;
&lt;p&gt;We can run another similar query to get the number of active users for each subreddit.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/active-users.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;After that, for a given subreddit &lt;em&gt;A&lt;/em&gt;, find:&lt;/p&gt;
&lt;p&gt;(A ∩ B) / (B)&lt;/p&gt;
&lt;p&gt;for all subreddits &lt;em&gt;B&lt;/em&gt; where (A ∩ B) &amp;gt; 0 (i.e. only neighbors of &lt;em&gt;A&lt;/em&gt;). This computation takes less than a second. Additionally, the output is always a percentage between 0% and 100%. For the visualizations, we plot the Top 15 subreddits with the highest overlap of the specified subreddit &lt;em&gt;A&lt;/em&gt; (and color the bars with a nice &lt;a href=&#34;https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html&#34; target=&#34;_blank&#34;&gt;viridis palette&lt;/a&gt; to provide another easy way to perceive relative magnitude of relatedness).&lt;/p&gt;
&lt;p&gt;The methodology may sound arbitrary, but the results are very interesting. Here&amp;rsquo;s a chart of the top related subreddits for &lt;a href=&#34;https://www.reddit.com/r/aww&#34; target=&#34;_blank&#34;&gt;/r/aww&lt;/a&gt;, one of the most popular places on the internet for cat pictures.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/aww-related.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I have honestly &lt;em&gt;never&lt;/em&gt; heard of any of these subreddits before. But yet, by analyzing public user activity alone, I found a few new places to get more cute pics.&lt;/p&gt;
&lt;p&gt;This methodology is excellent for finding subreddit-specific subsubreddits which may not be documented. The related subreddits for &lt;a href=&#34;https://www.reddit.com/r/buildapc&#34; target=&#34;_blank&#34;&gt;/r/buildapc&lt;/a&gt; offer more places to get PC building advice.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/buildapc-related.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Related subreddits for sport-specific subreddits, like &lt;a href=&#34;https://www.reddit.com/r/cfb&#34; target=&#34;_blank&#34;&gt;/r/cfb&lt;/a&gt; (college football) include the corresponding teams.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/cfb-related.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.reddit.com/r/food&#34; target=&#34;_blank&#34;&gt;/r/food&lt;/a&gt; related subreddits list a surprising number of subreddits dedicated to specific foods.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/food-related.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is a surprising amount of depth to the &lt;a href=&#34;https://www.reddit.com/r/me_irl&#34; target=&#34;_blank&#34;&gt;/r/me_irl&lt;/a&gt; network.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/me_irl-related.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The chart for &lt;a href=&#34;https://www.reddit.com/r/programming&#34; target=&#34;_blank&#34;&gt;/r/programming&lt;/a&gt; can tell you which subreddits exist for specific programming languages and technologies.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/programming-related.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The methodology can also reveal a &lt;em&gt;lack&lt;/em&gt; of related subreddits, by the large contrast between subreddits with high relatedness and low relatedness. For example, while /r/cfb may have large numbers of obviously-related subreddits as a sports subreddit, &lt;a href=&#34;https://www.reddit.com/r/golf&#34; target=&#34;_blank&#34;&gt;/r/golf&lt;/a&gt; has only 2.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/golf-related.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can view Related Subreddit charts for the Top 200 Subreddits &lt;a href=&#34;https://github.com/minimaxir/subreddit-related/tree/master/related&#34; target=&#34;_blank&#34;&gt;in this GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;finding-similar-subreddits&#34;&gt;Finding Similar Subreddits&lt;/h2&gt;
&lt;p&gt;Another method for finding related subreddits would be to find subreddits with similar communities. An academic approach to finding similarity between sets is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Jaccard_index&#34; target=&#34;_blank&#34;&gt;Jaccard Index&lt;/a&gt;. Using the same set A and set B definitions above, the formula now becomes:&lt;/p&gt;
&lt;p&gt;(A ∩ B) / [(A) + (B) - (A ∩ B)]&lt;/p&gt;
&lt;p&gt;which outputs the Jaccard Index, between 0 and 1. This formula only requires a few tweaks to the original code. The results from this computation tell a different story.&lt;/p&gt;
&lt;p&gt;Here are the most-similar subreddits to /r/aww:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/aww-jaccard-nondefault.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this implementation, the &lt;a href=&#34;https://www.reddit.com/r/defaults/comments/4l3svc/list_of_default_subreddits_usa_26_may_2016/&#34; target=&#34;_blank&#34;&gt;default Reddit subreddits&lt;/a&gt; must be removed from the results, as the communities of default subreddits are largely similar to most others by design. Even former defaults like &lt;a href=&#34;https://www.reddit.com/r/adviceanimals&#34; target=&#34;_blank&#34;&gt;/r/adviceanimals&lt;/a&gt; and &lt;a href=&#34;https://www.reddit.com/r/technology&#34; target=&#34;_blank&#34;&gt;/r/technology&lt;/a&gt; still have large amounts of holdout users which skew the results. As &lt;a href=&#34;https://www.reddit.com/r/aww&#34; target=&#34;_blank&#34;&gt;/r/aww&lt;/a&gt; is a mass-appeal subreddit, it makes sense that the communities are similar to other mass-appeal subreddits.&lt;/p&gt;
&lt;p&gt;The magnitude of the Jaccard Index measures the strength of the similarity. Most subreddit relationships have a low Jaccard Index, but the relative magnitude between all subreddit neighbors illustrate comparisons for potential related subreddits regardless (this is also the reason why the x-axis is not fixed across plots). The subreddit relationship with the highest absolute similarity is &lt;a href=&#34;https://www.reddit.com/r/arrow&#34; target=&#34;_blank&#34;&gt;/r/arrow&lt;/a&gt; and &lt;a href=&#34;https://www.reddit.com/r/flashtv&#34; target=&#34;_blank&#34;&gt;/r/flashtv&lt;/a&gt; at 0.345, which make sense given the massive overlap between the two CW television shows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/arrow-jaccard-nondefault.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The Jaccard Index is more useful for finding similar subreddits to niche subreddits. Let&amp;rsquo;s try a few of the subreddits mentioned previously and see how the results changed.&lt;/p&gt;
&lt;p&gt;/r/buildapc is a niche, and the output identifies well-established subreddits, unlike with the previous related-subreddit methodology.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/buildapc-jaccard-nondefault.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The subreddit most similar to /r/cfb (college football) is &lt;a href=&#34;https://www.reddit.com/r/collegebasketball&#34; target=&#34;_blank&#34;&gt;/r/collegebasketball&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/cfb-jaccard-nondefault.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The subreddit most similar to /r/food is &lt;a href=&#34;https://www.reddit.com/r/cooking&#34; target=&#34;_blank&#34;&gt;/r/cooking&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/food-jaccard-nondefault.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The subreddit most similar to /r/programming is &lt;a href=&#34;https://www.reddit.com/r/linux&#34; target=&#34;_blank&#34;&gt;/r/linux&lt;/a&gt;! (of course)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-related-subreddits/programming-jaccard-nondefault.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can view the Similar Subreddit charts for the Top 200 Subreddits &lt;a href=&#34;https://github.com/minimaxir/subreddit-related/tree/master/similar&#34; target=&#34;_blank&#34;&gt;in this GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Again, Reddit has significantly better internal data for identifying user activity between subreddits, such as voting patterns and clickthrough tracking. But the results shown using these two set methodologies are pretty good for using public data. In fact, these two set approaches can theoretically work with &lt;em&gt;any&lt;/em&gt; set of categorized, settable data, which may give me a few ideas for new blog posts in the future.&lt;/p&gt;
&lt;p&gt;And there&amp;rsquo;s still the fancy machine learning approaches to try.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;As always, the full code used to process the comment data and generate the visualizations is available in &lt;a href=&#34;https://github.com/minimaxir/subreddit-related/blob/master/find_related_subreddits.ipynb&#34; target=&#34;_blank&#34;&gt;this Jupyter notebook&lt;/a&gt;, open-sourced &lt;a href=&#34;https://github.com/minimaxir/subreddit-related&#34; target=&#34;_blank&#34;&gt;on GitHub&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you do find any other interesting trends in the related/similar charts of other subreddits and write about it, it would be greatly appreciated if proper attribution is given back to this post and/or myself. Thanks!&lt;/em&gt;&lt;/p&gt;</description></item><item><title>How to Create a Network Graph Visualization of Reddit Subreddits</title><link>/2016/05/reddit-graph/</link><pubDate>Fri, 27 May 2016 08:00:00 +0000</pubDate><guid>/2016/05/reddit-graph/</guid><description>
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Graph_theory&#34; target=&#34;_blank&#34;&gt;Network graphs&lt;/a&gt; are pretty data visualizations, and I like pretty data visualizations. Recently, &lt;a href=&#34;https://www.reddit.com&#34; target=&#34;_blank&#34;&gt;Reddit&lt;/a&gt; user CuriousGnu &lt;a href=&#34;http://www.curiousgnu.com/reddit-comments&#34; target=&#34;_blank&#34;&gt;posted a network graph&lt;/a&gt; of the comment patterns of the top 50 Reddit subreddits:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/rd_comments_net_hd.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.reddit.com/r/dataisbeautiful/comments/4fsrjd/oc_redditors_who_commented_in_rx_also_commented/&#34; target=&#34;_blank&#34;&gt;visualization&lt;/a&gt; was made with &lt;a href=&#34;https://gephi.org&#34; target=&#34;_blank&#34;&gt;Gephi&lt;/a&gt;, a very popular free and open-source network graph tool.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/gephi.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Gephi is &lt;em&gt;extremely&lt;/em&gt; difficult to use, and most blog posts about the software are in the form of Step 1: Gephi, Step 2: ???, Step 3: Profit. Even if you know &lt;em&gt;do&lt;/em&gt; how to use it, most of the network design customizations must be done manually, which is not helped by software slowness even on high-end machines. My own attempts to use Gephi for nice-looking networks have had &lt;a href=&#34;https://www.reddit.com/r/dataisbeautiful/comments/3z60z6/network_of_reddit_commenting_patterns_for_the_top/&#34; target=&#34;_blank&#34;&gt;mixed&lt;/a&gt; &lt;a href=&#34;https://www.reddit.com/r/magicTCG/comments/401hdq/graph_network_of_magic_the_gathering_creature/&#34; target=&#34;_blank&#34;&gt;results&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, there is very little discussion on how to gather the data for large-scale network graph visualizations, and how to make them in a &lt;em&gt;reproducible&lt;/em&gt; manner. It is time to fix that and create a Reddit network graph visualization with many more nodes, step by step.&lt;/p&gt;
&lt;h2 id=&#34;getting-reddit-edge-data&#34;&gt;Getting Reddit Edge Data&lt;/h2&gt;
&lt;p&gt;Network graphs are typically formed by getting the relationship data between two entities (the edges), then extrapolating the vertices of the graph (the nodes) from that data.&lt;/p&gt;
&lt;p&gt;There are two common data structures for representing edge data. One is an &lt;a href=&#34;https://en.wikipedia.org/wiki/Adjacency_matrix&#34; target=&#34;_blank&#34;&gt;adjacency matrix&lt;/a&gt;, which is a 2D matrix where the rows/columns represent the entities, and the value at the intersection between a row/column represents the &lt;em&gt;weight&lt;/em&gt; of the relationships. For the visualization above, CuriousGnu made an adjacency matrix by querying the relationships from &lt;a href=&#34;https://cloud.google.com/bigquery/&#34; target=&#34;_blank&#34;&gt;BigQuery&lt;/a&gt; for each subreddit manually. That requires adding a line of SQL for &lt;em&gt;each&lt;/em&gt; subreddit you want to plot, which is time-consuming and I am lazy.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s try option #2: an &lt;a href=&#34;https://reference.wolfram.com/language/ref/EdgeList.html&#34; target=&#34;_blank&#34;&gt;edge list&lt;/a&gt;, which is a tabular dataset where each row contains the two entities and a weight. With clever use of BigQuery, we can query the edges for &lt;em&gt;every single subreddit&lt;/em&gt; at the same time. And we can query on real-time Reddit data from approximately the past 6 months using Jason Baumgartner&amp;rsquo;s &lt;a href=&#34;https://pushshift.io/using-bigquery-with-reddit-data/&#34; target=&#34;_blank&#34;&gt;Reddit dataset&lt;/a&gt; on BigQuery.&lt;/p&gt;
&lt;p&gt;The process works like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Determine active users of a subreddit by identifying the subreddits where a user has &lt;strong&gt;commented&lt;/strong&gt; on at least &lt;strong&gt;5 different submissions&lt;/strong&gt; within the past 6 months.&lt;/li&gt;
&lt;li&gt;Perform a &lt;a href=&#34;http://stackoverflow.com/questions/3362038/what-is-self-join-and-when-would-you-use-it&#34; target=&#34;_blank&#34;&gt;self-join&lt;/a&gt; by joining the table on itself: this will create &lt;strong&gt;links&lt;/strong&gt; between all subreddits where a given user is active. (e.g. an active user of /r/askreddit, /r/pics, and /r/gifs will form 9 links: askreddit → askreddit, askreddit → pics, askreddit → gifs, pics → askreddit, etc.)&lt;/li&gt;
&lt;li&gt;Aggregate the counts of the number of links between two subreddits; this will become the edge &lt;strong&gt;Weight&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Filter the resulting dataset by removing self-loops and reverse-edges. (e.g. since we have askreddit → pics, remove pics → askreddit). Additionally, we should only retain edges with &lt;strong&gt;at least 200 active users&lt;/strong&gt; to keep the resulting dataset a manageable size for this analysis.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Putting it all together results in this query:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT a.l_subreddit as Source, b.l_subreddit as Target, COUNT(*) as Weight
FROM (
SELECT author, LOWER(subreddit) as l_subreddit, COUNT(DISTINCT(link_id)) as unique_threads
FROM [pushshift:rt_reddit.comments]
GROUP BY author, l_subreddit
HAVING unique_threads &amp;gt;= 5) a JOIN (
SELECT author, LOWER(subreddit) as l_subreddit, COUNT(DISTINCT(link_id)) as unique_threads
FROM [pushshift:rt_reddit.comments]
GROUP BY author, l_subreddit
HAVING unique_threads &amp;gt;= 5) b ON a.author = b.author
GROUP BY Source, Target
HAVING Source &amp;lt; Target AND Weight &amp;gt;= 200
ORDER BY Weight DESC
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Only 13 lines of code, with 3 of those lines repeated. Running the query only takes a few minutes. (which is actually &lt;em&gt;forever&lt;/em&gt; in BigQuery time: when people talk about &amp;ldquo;big data,&amp;rdquo; this is &lt;em&gt;actually big data&lt;/em&gt;!)&lt;/p&gt;
&lt;p&gt;That query (at the time of analysis) returns &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1MFHno-sYR3MkWgntnieWobWQ2e3x4CAcNUdVIFjmlQI/edit?usp=sharing&#34; target=&#34;_blank&#34;&gt;this dataset&lt;/a&gt; of 7,498 edges; more than enough. Now for the fun part.&lt;/p&gt;
&lt;h2 id=&#34;visualizing-the-reddit-data&#34;&gt;Visualizing the Reddit Data&lt;/h2&gt;
&lt;p&gt;The edge list linked above can actually be imported into Gephi as-is. &lt;strong&gt;Don&amp;rsquo;t&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Instead, let&amp;rsquo;s use R and my favorite data visualization tool &lt;code&gt;ggplot2&lt;/code&gt;, with a twist.&lt;/p&gt;
&lt;p&gt;First, we load the edge list into R, and create an undirected network graph using the &lt;code&gt;igraph&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;net &amp;lt;- graph.data.frame(df, directed=F)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/igraph.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The imported edge list results in a network with 1,131 nodes/subreddits. After pruning nodes with only a few neighbors and removing the subsequently-orphaned edges, we get a network of 517 nodes/subreddits with 6,732 edges.&lt;/p&gt;
&lt;p&gt;We can then add summary statistics for the nodes, such as the group/community each node belongs to, and the &lt;a href=&#34;https://en.wikipedia.org/wiki/Centrality&#34; target=&#34;_blank&#34;&gt;eigenvector centrality&lt;/a&gt; of the node.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;V(net)$group &amp;lt;- membership(cluster_walktrap(net, weights=E(net)$Weight))
V(net)$centrality &amp;lt;- eigen_centrality(net, weights=E(net)$Weight)$vector
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Convert the network to a dataframe suitable for plotting using the &lt;code&gt;ggnetwork&lt;/code&gt; library.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df_net &amp;lt;- ggnetwork(net, layout = &amp;quot;fruchtermanreingold&amp;quot;, weights=&amp;quot;Weight&amp;quot;, niter=50000)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now time for ggplot2/ggnetwork fun. In this case, we will color the nodes whether or not they are a default subreddit (orange if default, blue otherwise) and color the lines accordingly (orange if either end is a default subreddit, blue otherwise).&lt;/p&gt;
&lt;p&gt;Yes, writing and optimizing all of this code is &lt;em&gt;significantly&lt;/em&gt; easier than using Gephi, believe it or not.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;default_colors=c(&amp;quot;#3498db&amp;quot;, &amp;quot;#e67e22&amp;quot;)
default_labels=c(&amp;quot;Not Default&amp;quot;, &amp;quot;Default&amp;quot;)
ggplot(df_net, aes(x = x, y = y, xend = xend, yend = yend, size = centrality)) +
geom_edges(aes(color = connectDefault), size=0.05) +
geom_nodes(aes(fill = defaultnode), shape = 21, stroke=0.2, color=&amp;quot;black&amp;quot;) +
geom_nodelabel_repel(data=df_net, aes(color = defaultnode, label = vertex.names),
fontface = &amp;quot;bold&amp;quot;, size=0.5, box.padding = unit(0.05, &amp;quot;lines&amp;quot;),
label.padding= unit(0.1, &amp;quot;lines&amp;quot;), segment.size=0.1, label.size=0.2) +
scale_color_manual(values=default_colors, labels=default_labels, guide=F) +
scale_fill_manual(values=default_colors, labels=default_labels) +
ggtitle(&amp;quot;Network Graph of Reddit Subreddits (by @minimaxir)&amp;quot;) +
scale_size(range=c(0.1, 4)) +
theme_blank()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;object data=&#34;/img/reddit-graph/subreddit-1.pdf&#34; type=&#34;application/pdf&#34; width=&#34;100%&#34; height=&#34;400px&#34;&gt;&lt;/object&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;hidden-lg&#34;&gt;&lt;em&gt;If you are on a smartphone or tablet, tap &lt;a href=&#34;/img/reddit-graph/subreddit-1.pdf&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt; to view the network in a zoomable format.&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The large networks in the blog post are rendered as a PDF, which allows for easy pan/zooming at a very low file size (284KB!), while SVG/&lt;a href=&#34;https://d3js.org&#34; target=&#34;_blank&#34;&gt;d3&lt;/a&gt;/&lt;a href=&#34;http://sigmajs.org&#34; target=&#34;_blank&#34;&gt;sigma.js&lt;/a&gt; approaches have very poor performance at large numbers of nodes/edges.&lt;/p&gt;
&lt;p&gt;As we expect, the default subreddits are in the center of the network graph and have high centrality (although /r/art and /r/earthporn are oddly far separated from the other defaults). The large amounts of orange graph-wide illustrate the breadth of the defaults.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s color the nodes and edges by group, just as you saw in the introductory visualization:&lt;/p&gt;
&lt;p&gt;&lt;object data=&#34;/img/reddit-graph/subreddit-2.pdf&#34; type=&#34;application/pdf&#34; width=&#34;100%&#34; height=&#34;400px&#34;&gt;&lt;/object&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;hidden-lg&#34;&gt;&lt;em&gt;If you are on a smartphone or tablet, tap &lt;a href=&#34;/img/reddit-graph/subreddit-2.pdf&#34; target=&#34;_blank&#34;&gt;this link&lt;/a&gt; to view the network in a zoomable format.&lt;/em&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If an edge links to a node of the same group, the edge is colored that group. Otherwise, the edge is colored gray. (the code that implements this is not shown because it is somewhat convoluted). This color scheme helps gauge the overall impact of the communities on Reddit. But why not look at specific groups?&lt;/p&gt;
&lt;h2 id=&#34;subgraph-surprises&#34;&gt;Subgraph Surprises&lt;/h2&gt;
&lt;p&gt;As you can see plainly in the group-colored visualization, there is a giant green group at the center which includes the default subreddits. Analyzing that is not helpful. But we can filter the network on other specific groups and their subgraphs to see if we can define any Reddit subcultures. (note that the Group number is merely an ID; the value and order are not relevant).&lt;/p&gt;
&lt;p&gt;The most notable Reddit groups are gaming groups. We have two distinct groups of gamers:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-006.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-008.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Plus Nintendo gamers? With a little Vita on the side?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-010.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Subreddits related to sports and sporting teams form a nice cluster:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-001.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;PC-building has a distinct community:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-011.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The British make nice triangles!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-022.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Relationship and female-oriented subreddits have a relationship.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-007.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Lastly, DC Comics has their own sector, particularly with the corresponding CW television shows. (although some Marvel shows sneak in!)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-graph/group-003.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Of course, Reddit itself has better data for identifying relationships between subreddits, as they can track user activity more intimately. Meanwhile, the output for this post turned out better than expected and I hope to include similar visualizations in future blog posts. Hopefully, it dispelled some of the mystery behind pretty network graphs. (if you do use the code or data visualization designs from this post, it would be greatly appreciated if proper attribution is given back to this post and/or myself. Thanks!).&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;As always, the full code used to process the edge list and generate the visualizations is available in &lt;a href=&#34;https://github.com/minimaxir/reddit-graph/blob/master/subreddit_network_pdf.ipynb&#34; target=&#34;_blank&#34;&gt;this Jupyter notebook&lt;/a&gt;, open-sourced &lt;a href=&#34;https://github.com/minimaxir/reddit-graph&#34; target=&#34;_blank&#34;&gt;on GitHub&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additionally, thanks to Professor James P. Curley of Columbia University for providing &lt;a href=&#34;http://curleylab.psych.columbia.edu/netviz/netviz1.html#/&#34; target=&#34;_blank&#34;&gt;helpful slides&lt;/a&gt; which have good code samples for getting started with igraph/ggnetwork.&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Quantifying and Visualizing the Reddit Hivemind</title><link>/2015/10/reddit-topwords/</link><pubDate>Fri, 09 Oct 2015 08:00:00 +0000</pubDate><guid>/2015/10/reddit-topwords/</guid><description>
&lt;p&gt;In my &lt;a href=&#34;http://minimaxir.com/2015/10/reddit-bigquery/&#34; target=&#34;_blank&#34;&gt;last post on Reddit data&lt;/a&gt; (I strongly suggest you read that first if you haven&amp;rsquo;t already), I noted that analyzing the words used in Reddit submissions may be useful in quantifying the relationship of those keywords in the success of a Reddit submission. Indeed, if we can find out which topics Reddit users tend to upvote, we can identify what keywords are most attractive to the Reddit &amp;ldquo;hivemind.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;First, I gathered some preliminary statistics about all submissions to the top 500 subreddits on Reddit, again using the &lt;a href=&#34;https://cloud.google.com/bigquery/&#34; target=&#34;_blank&#34;&gt;BigQuery&lt;/a&gt; data dump compiled by Jason Baumgartner and Felipe Hoffa, in order to establish a good base for the analysis:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT subreddit,
COUNT(*) AS num_submissions,
ROUND(AVG(score), 1) as avg_score,
NTH(25, quantiles(score,1000)) AS lower_95,
NTH(500, quantiles(score,1000)) AS median,
NTH(975, quantiles(score,1000)) AS upper_95
FROM [fh-bigquery:reddit_posts.full_corpus_201509]
GROUP BY subreddit
ORDER BY num_submissions DESC
LIMIT 500
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which results in &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1lyEc7-5vkREKBV8fUreyOszICgyA0CqX2YHaK2-4ndo/edit?usp=sharing&#34; target=&#34;_blank&#34;&gt;this output&lt;/a&gt;. The &amp;ldquo;lower_95&amp;rdquo; and and the &amp;ldquo;upper_95&amp;rdquo; columns represent the 2.5% and the 97.5% percentile respectively, which could be used to form a 95% confidence interval around the median. For example, &lt;a href=&#34;http://reddit.com/r/funny&#34; target=&#34;_blank&#34;&gt;/r/funny&lt;/a&gt; has a 2.5% percentile of 0 points, a median of 1 point, and a 97.5% percentile of &lt;em&gt;875 points&lt;/em&gt;. However, from those values, it is clear the data is heavily skewed right, which makes running statistical tests more difficult.&lt;/p&gt;
&lt;p&gt;Now we can query the top keywords for each subreddit, whose presence in a submission is related to the highest average score within that subreddit. This requires a very intricate and optimized BigQuery. Specifically, we want the query to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get the Top 500 subreddits, by number of submissions (an abridged verson of query above).&lt;/li&gt;
&lt;li&gt;Get all submissions from these subreddits.&lt;/li&gt;
&lt;li&gt;Extract the keywords from all of these submissions, using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Regular_expression&#34; target=&#34;_blank&#34;&gt;regular expression&lt;/a&gt; to remove most punctuation (unfortunately, the regular expression will remove punctuation &lt;em&gt;within&lt;/em&gt; words as well, resulting in some odd &amp;ldquo;words&amp;rdquo; in the final results) and flattening the resulting tokens into separate rows for aggregation.&lt;/li&gt;
&lt;li&gt;Aggregate the keywords by both subreddit and the word itself, and obtain the # of distinct submissions the word is present in, the average score among all submissions, etc.&lt;/li&gt;
&lt;li&gt;Keep only words which occur in atleast 1,000 distinct submissions, which is important for getting a good average.&lt;/li&gt;
&lt;li&gt;For each subreddit, rank each remaining word by their average score, descending.&lt;/li&gt;
&lt;li&gt;Keep only the Top 20 words for each subreddit. 500 subreddits x 20 words = 10,000 rows maximum, which the limit BigQuery allows for web download, so that works out well.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM (
SELECT subreddit, word, num_words, avg_score, lower_95, median, upper_95, ROW_NUMBER() OVER (PARTITION BY subreddit ORDER BY avg_score DESC) score_rank
FROM (
SELECT subreddit, word, COUNT(DISTINCT(id)) AS num_words, ROUND(AVG(score), 3) AS avg_score, NTH(25, quantiles(score,1000)) AS lower_95, NTH(500, quantiles(score,1000)) AS median, NTH(975, quantiles(score,1000)) AS upper_95
FROM(FLATTEN((
SELECT SPLIT(LOWER(REGEXP_REPLACE(title, r&#39;[^\w\&#39;]&#39;, &#39; &#39;)), &#39; &#39;) word, subreddit, score, id
FROM [fh-bigquery:reddit_posts.full_corpus_201509]
WHERE subreddit IN (SELECT subreddit FROM (SELECT subreddit, COUNT(*) AS c FROM [fh-bigquery:reddit_posts.full_corpus_201509] GROUP BY subreddit ORDER BY c DESC LIMIT 500))
), word))
GROUP EACH BY subreddit, word
HAVING num_words &amp;gt;= 1000
))
WHERE score_rank &amp;lt;= 20
ORDER BY subreddit, avg_score DESC
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Phew! That query results in &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1MRfLR_TBO8zveKaifqVXTN0da7tf0FQOr5a2LVkZgkg/edit?usp=sharing&#34; target=&#34;_blank&#34;&gt;this output&lt;/a&gt;, which we can use to plot a bar chart for each subreddit.&lt;/p&gt;
&lt;h2 id=&#34;plotting-the-words&#34;&gt;Plotting the Words&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;The R code used to generate the charts is available in &lt;a href=&#34;https://github.com/minimaxir/reddit-subreddit-keywords/blob/master/reddit_subreddit_words.ipynb&#34; target=&#34;_blank&#34;&gt;this Jupyter notebook&lt;/a&gt;, open-sourced on GitHub. Additionally, all 500 charts with the keyword ranks for all 500 subreddits are available in &lt;a href=&#34;https://github.com/minimaxir/reddit-subreddit-keywords/tree/master/subreddit-mean&#34; target=&#34;_blank&#34;&gt;the parent repository&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;After a few R tricks, I managed to chart the Top 10 keywords for each of the Top 15 subreddits:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://i.imgur.com/dWdCnMI.png&#34; target=&#34;_blank&#34;&gt; &lt;img src=&#34;/img/reddit-topwords/subreddit-means-half.png&#34; alt=&#34;&#34; /&gt; &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(Click on image for full-resolution)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As noted in the subtitle, each word appears in atleast 1,000 submissions by subreddit (which absorbs any messy outliers), and vertical line represents the true average upvotes per subreddit. One might argue that the median would be a better statistic instead of the median, due to the high skewness of the data. Thanks to the power of BigQuery, I was able to calculate the &lt;a href=&#34;http://i.imgur.com/0PBolIq.png&#34; target=&#34;_blank&#34;&gt;top medians for each of the subreddits&lt;/a&gt; with a slightly-tweaked query, but the chart is not as helpful. There are still a few useful implications of the median, though, which I&amp;rsquo;ll show later. (No, I don&amp;rsquo;t need to normalize the data in the chart since I am not making an apples-to-apples comparison between the values of the words among subreddits, and no, I don&amp;rsquo;t need to remove stop words since this is visualizing an average, and not a count.)&lt;/p&gt;
&lt;p&gt;When the visualization was &lt;a href=&#34;https://www.reddit.com/r/dataisbeautiful/comments/3nz3zz/average_number_of_upvotes_for_reddit_submissions/&#34; target=&#34;_blank&#34;&gt;posted to Reddit&lt;/a&gt; in the &lt;a href=&#34;https://www.reddit.com/r/dataisbeautiful/&#34; target=&#34;_blank&#34;&gt;/r/dataisbeautiful&lt;/a&gt; subreddit, it received over 3,500 upvotes. As many commenters on that submission correctly note, there are a few especially interesting observations for the keywords in those 15 subreddits, and when looking at the remaining subreddits, many trends in their keywords are made apparent.&lt;/p&gt;
&lt;h2 id=&#34;politicalreddit&#34;&gt;Politicalreddit&lt;/h2&gt;
&lt;p&gt;The most notable trend with the Top 15 subreddits is in the &lt;a href=&#34;https://www.reddit.com/r/politics/&#34; target=&#34;_blank&#34;&gt;/r/politics&lt;/a&gt; subreddit, which tells users to &amp;ldquo;Vote based on quality, not opinion,&amp;rdquo; but has a high affiliation for submissions specifically involving Bernie Sanders and Elizabeth Warren.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-010-politics.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.reddit.com/r/technology/&#34; target=&#34;_blank&#34;&gt;/r/technology&lt;/a&gt;, intended to be about &amp;ldquo;a broad spectrum of conversation as to the innovations, aspirations, applications and machinations,&amp;rdquo; has a high affiliation for political issues such as the net neutrality controversy involving the FCC, ISPs, and Comcast, and little affiliation for actual &lt;em&gt;technology&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-018-technology.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Outside the Top 15 Subreddits, the political affiliations of subreddits such as &lt;a href=&#34;http://reddit.com/r/Libertarian&#34; target=&#34;_blank&#34;&gt;/r/Libertarian&lt;/a&gt; are less surprising and more funny as a result.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-103-Libertarian.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;storyreddit&#34;&gt;Storyreddit&lt;/h2&gt;
&lt;p&gt;One of the rising trends in the online publication landscape is that telling a story is more effective at generating attention. (thank BuzzFeed for that)&lt;/p&gt;
&lt;p&gt;The biggest offender is &lt;a href=&#34;https://www.reddit.com/r/aww/&#34; target=&#34;_blank&#34;&gt;/r/aww&lt;/a&gt;, a subreddit about animals, has a high affinity for words &lt;em&gt;that aren&amp;rsquo;t animals&lt;/em&gt;, with only two animal words appearing in the Top 20.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-011-aww.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The presence of story titles is also apparent in &lt;a href=&#34;https://www.reddit.com/r/Fitness/&#34; target=&#34;_blank&#34;&gt;/r/Fitness&lt;/a&gt;, which in fairness, the atmosphere of self-improvement lends itself more to stories.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-054-Fitness.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;metareddit&#34;&gt;Metareddit&lt;/h2&gt;
&lt;p&gt;The practice of upvoting submissions just because they mention a particular topic is colloquially known as &amp;ldquo;circlejerking.&amp;rdquo; &lt;a href=&#34;https://www.reddit.com/r/circlejerk/&#34; target=&#34;_blank&#34;&gt;/r/circlejerk&lt;/a&gt; fits that well, with titles designed to satirize clickbaity issues in order to receive upvotes ironically.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-025-circlejerk.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.reddit.com/r/Braveryjerk/&#34; target=&#34;_blank&#34;&gt;/r/Braveryjerk&lt;/a&gt;, however, takes this practice to its logical conclusion.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-486-Braveryjerk.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;esotericreddit&#34;&gt;Esotericreddit&lt;/h2&gt;
&lt;p&gt;Here are a few other infamous subreddits that people have requested.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.reddit.com/r/conspiracy/&#34; target=&#34;_blank&#34;&gt;/r/conspiracy&lt;/a&gt;, which apparently have frequent instances of &amp;ldquo;TIL&amp;rdquo; (Today, I Learned) in titles, are simultaneously very &lt;em&gt;suspicious&lt;/em&gt; of the actions in the &lt;a href=&#34;https://www.reddit.com/r/TIL/&#34; target=&#34;_blank&#34;&gt;/r/TIL&lt;/a&gt; subreddit.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-064-conspiracy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The keywords in &lt;a href=&#34;https://www.reddit.com/r/teenagers/&#34; target=&#34;_blank&#34;&gt;/r/teenagers&lt;/a&gt; captures the essence of modern social media.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-072-teenagers.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Some subreddits are just plain weird.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/mean-175-me_irl.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s &lt;a href=&#34;https://www.reddit.com/r/me_irl/&#34; target=&#34;_blank&#34;&gt;/r/me_irl&lt;/a&gt; for you.&lt;/p&gt;
&lt;h2 id=&#34;looking-at-the-medians&#34;&gt;Looking at the Medians&lt;/h2&gt;
&lt;p&gt;As shown in the linked median image earlier, the medians for most keywords are 1 or 2, which does not provide much visual information whether a keyword is more important than another.&lt;/p&gt;
&lt;p&gt;There are notable exceptions, however, such as with &lt;a href=&#34;https://www.reddit.com/r/Android/&#34; target=&#34;_blank&#34;&gt;/r/Android&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/median-059-Android.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That subreddit has official threads for events; it would make sense for users to upvote that whenever it appears as it&amp;rsquo;s &lt;em&gt;important&lt;/em&gt; that it&amp;rsquo;s visible, but not necessarily as an agreement of the topic. That&amp;rsquo;s why I believe looking at the medians is a different approach than looking at the means.&lt;/p&gt;
&lt;p&gt;Same thing with &lt;a href=&#34;https://www.reddit.com/r/relationships/&#34; target=&#34;_blank&#34;&gt;/r/relationships&lt;/a&gt;, where an &amp;ldquo;update&amp;rdquo; is important.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/reddit-topwords/median-057-relationships.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;All in all, this is still just a first step for analyzing the importance of keywords in Reddit submission, and the impact of Reddit&amp;rsquo;s hivemind. The next step would be NLP techniques such as POS tagging and TDF-IF, but those require very significant and very expensive computing power. At the least, the good results with these simple analyses validates the idea for further research.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Again the R code used to generate the charts is available in &lt;a href=&#34;https://github.com/minimaxir/reddit-subreddit-keywords/blob/master/reddit_subreddit_words.ipynb&#34; target=&#34;_blank&#34;&gt;this Jupyter notebook&lt;/a&gt;, open-sourced on GitHub. Additionally, all 500 charts with the keyword ranks for all 500 subreddits are available in &lt;a href=&#34;https://github.com/minimaxir/reddit-subreddit-keywords/tree/master/subreddit-mean&#34; target=&#34;_blank&#34;&gt;the parent repository&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>