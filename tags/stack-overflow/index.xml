<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Stack Overflow on Max Woolf&#39;s Blog</title><link>/tags/stack-overflow/</link><description>Recent content in Stack Overflow on Max Woolf&#39;s Blog</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Copyright Max Woolf &amp;copy; {year}</copyright><lastBuildDate>Fri, 09 Feb 2018 09:00:00 +0000</lastBuildDate><atom:link href="/tags/stack-overflow/index.xml" rel="self" type="application/rss+xml"/><item><title>A Visual Overview of Stack Overflow&#39;s Question Tags</title><link>/2018/02/stack-overflow-questions/</link><pubDate>Fri, 09 Feb 2018 09:00:00 +0000</pubDate><guid>/2018/02/stack-overflow-questions/</guid><description>
&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com&#34; target=&#34;_blank&#34;&gt;Stack Overflow&lt;/a&gt; is the most popular contemporary knowledge base for programming questions. But most interact with the site by Googling a programming question and getting a top result that links to SO. There isn&amp;rsquo;t as much discussion about actually &lt;em&gt;asking&lt;/em&gt; questions on the site.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/python_last_list.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I &lt;em&gt;could&lt;/em&gt; use &lt;a href=&#34;https://stackoverflow.com/users/9314418/minimaxir?tab=profile&#34; target=&#34;_blank&#34;&gt;my Stack Overflow account&lt;/a&gt; and test out the process of creating a question, but &lt;del&gt;I already know everything about programming&lt;/del&gt; there may be another way to learn how SO works. Stack Overflow &lt;a href=&#34;https://archive.org/details/stackexchange&#34; target=&#34;_blank&#34;&gt;releases an archive&lt;/a&gt; of all questions on the site every 3 months, and this archive is &lt;a href=&#34;https://cloud.google.com/bigquery/public-data/stackoverflow&#34; target=&#34;_blank&#34;&gt;syndicated to BigQuery&lt;/a&gt;, making it trivial to retrieve and analyze the millions of SO questions over the years. Even though (now-former) Stack Overflow data scientist &lt;a href=&#34;https://twitter.com/drob&#34; target=&#34;_blank&#34;&gt;David Robinson&lt;/a&gt; has written &lt;a href=&#34;https://stackoverflow.blog/2017/09/06/incredible-growth-python/&#34; target=&#34;_blank&#34;&gt;many&lt;/a&gt; &lt;a href=&#34;https://stackoverflow.blog/2017/04/19/programming-languages-used-late-night/&#34; target=&#34;_blank&#34;&gt;interesting&lt;/a&gt; blog posts for Stack Overflow with their data, I figured why not give it a try.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/python_last_list_answer.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Unlike social media sites like &lt;a href=&#34;https://twitter.com&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt; and &lt;a href=&#34;https://www.reddit.com&#34; target=&#34;_blank&#34;&gt;Reddit&lt;/a&gt; where the majority of traffic is driven within the first days after something is posted, posts on evergreen content sources like Stack Overflow are still relevant many years later. In fact, the traffic to Stack Overflow for most of 2017 (derived by finding the difference between question view counts from archive snapshots) is approximately uniform across question age, with a slight bias toward older content.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/so_overview.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In 2017, Stack Overflow received about 40k-50k new questions each week, an impressive feat:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/weekly_count.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the rest of this post, we&amp;rsquo;ll only look at questions made in 2017 (until December; about 2.3 million questions total) in order to get a sense of the current development landscape, and what&amp;rsquo;s to come in the future. But what types of questions are they?&lt;/p&gt;
&lt;h2 id=&#34;tag-breakdown&#34;&gt;Tag Breakdown&lt;/h2&gt;
&lt;p&gt;All questions on Stack Overflow are required to have atleast 1 tag indicating the programming language/technologies involved with the question, and can have up to 5 tags. In the example &amp;ldquo;how do you get the last element of a list in Python&amp;rdquo; &lt;a href=&#34;https://stackoverflow.com/questions/930397/getting-the-last-element-of-a-list-in-python&#34; target=&#34;_blank&#34;&gt;question&lt;/a&gt; above, the tags are &lt;code&gt;python&lt;/code&gt;, &lt;code&gt;list&lt;/code&gt;, and &lt;code&gt;indexing&lt;/code&gt;. In 2017, most of new questions had 2-3 tags. (i.e. people aren&amp;rsquo;t &lt;a href=&#34;http://minimaxir.com/2014/03/hashtag-tag/&#34; target=&#34;_blank&#34;&gt;tag spamming&lt;/a&gt; like on &lt;a href=&#34;https://www.instagram.com/?hl=en&#34; target=&#34;_blank&#34;&gt;Instagram&lt;/a&gt; for maximum exposure).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/so_tag_breakdown.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In theory, tag spamming might make a question more likely to be answered; however for all tag counts, the proportion of questions with accepted answer (the green checkmark) is &lt;strong&gt;36-39%&lt;/strong&gt;, so there&amp;rsquo;s not much practical benefit from minmaxing tag counts. Which types of tagged questions are most likely to be answered?&lt;/p&gt;
&lt;p&gt;First, here&amp;rsquo;s the breakdown of the top 40 tags on Stack Overflow, by the number of new questions containing that tag for each month throughout 2017. This can give a sense of each technology&amp;rsquo;s growth/decline throughout the year.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/monthly_count_tag.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both new web development technologies like &lt;code&gt;reactjs&lt;/code&gt; and &lt;code&gt;typescript&lt;/code&gt; and data science tools like &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;r&lt;/code&gt; are trending upward.&lt;/p&gt;
&lt;p&gt;For the Top 1,000 tags, here are the top 30 tags by the proportion of questions which received an acceptable answer:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/acceptable_answer_top_30.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In contrast, here are the bottom 30 out of the Top 1,000:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/acceptable_answer_bottom_30.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The top tags are newer, sexier technologies like &lt;code&gt;rust&lt;/code&gt; and &lt;code&gt;dart&lt;/code&gt;, with another strong hint of data science tooling with &lt;code&gt;dplyr&lt;/code&gt; (which I used to aggregate the data for this post!) and &lt;code&gt;data.table&lt;/code&gt;. In contrast, the bottom tags are less sexy and more corporate like &lt;code&gt;salesforce&lt;/code&gt;, &lt;code&gt;drupal&lt;/code&gt;, and &lt;code&gt;sharepoint-2013&lt;/code&gt; (that&amp;rsquo;s why consultants who specialize in these technologies can get paid very well!).&lt;/p&gt;
&lt;p&gt;It should be noted these two charts do not necessarily imply that one technology is &amp;ldquo;better&amp;rdquo; than another, and the difference in answer rates may be due to question difficulty and the number of people skilled in the tech available that can answer it effectively.&lt;/p&gt;
&lt;p&gt;The timing when questions are asked might vary by tag. Per &lt;a href=&#34;https://stackoverflow.blog/2017/04/19/programming-languages-used-late-night/&#34; target=&#34;_blank&#34;&gt;a Stack Overflow analysis&lt;/a&gt;, people typically ask questions during the 9 AM - 5 PM work hours (although in my case, I cannot easily adjust for the time zone of the asker). How does this data fare?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/monthly_count_hr_doy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This visualization is a bit weird. I adjusted the times to the Eastern time since internet activity for U.S.-based websites tends to revolve around that time zone. But for most technologies, the peak question-asking times are well before 9 AM to 5 PM: do those technologies correspond more to greater use in Europe and Asia? (In contrast, data-oriented technologies like &lt;code&gt;r&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;excel&lt;/code&gt; &lt;em&gt;do&lt;/em&gt; peak during the 9-5 block).&lt;/p&gt;
&lt;h2 id=&#34;how-easy-is-it-to-get-an-answer-by-tag&#34;&gt;How easy is it to get an answer by tag?&lt;/h2&gt;
&lt;p&gt;Stack Overflow caters the homepage toward the logged-in user&amp;rsquo;s recommended tags. Therefore, it&amp;rsquo;s not a surprise that the distribution of view counts on 2017 questions for each tag are very similar, although there is a slight edge toward the new &amp;ldquo;hip&amp;rdquo; technologies like &lt;code&gt;typescript&lt;/code&gt;, &lt;code&gt;spring&lt;/code&gt;, and &lt;code&gt;swift&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/views_boxplot_tag.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At the least, the distribution ensures that atleast 10 people see your question for these popular topics, which is nifty when you consider posts on Twitter and Reddit can die without any visibility at all. But will they provide an acceptable answer?&lt;/p&gt;
&lt;p&gt;The time it takes to get an acceptable answer also varies significantly by tag:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/acceptable_answer_density.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A median time of &lt;em&gt;15 minutes&lt;/em&gt; for tags like &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;arrays&lt;/code&gt; is pretty impressive! And even in the worst case scenario for these popular tags, the median is only a couple hours, much lower than I thought it would be.&lt;/p&gt;
&lt;h2 id=&#34;the-relationship-between-tags&#34;&gt;The Relationship Between Tags&lt;/h2&gt;
&lt;p&gt;As one would expect, the types of questions asked for each tag are much different. Here&amp;rsquo;s a wordcloud for each of the tags, quantifying the words most frequently used in the questions on those tags:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/so_tag_wordcloud.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notably, each word cloud is significantly different from reach other, even when technologies are related (also surprisingly true in the case of &lt;code&gt;angular&lt;/code&gt; and &lt;code&gt;angularjs&lt;/code&gt;!).&lt;/p&gt;
&lt;p&gt;How are the tags related anyways? We can calculate an &lt;a href=&#34;https://en.wikipedia.org/wiki/Adjacency_matrix&#34; target=&#34;_blank&#34;&gt;adjacency matrix&lt;/a&gt; of the tag pairs in the questions to see which tags are related:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/so_tag_adjacency.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looking down a given row/column, you can see which technologies have a lot of questions in common with another (for example, &lt;code&gt;javascript&lt;/code&gt; and &lt;code&gt;json&lt;/code&gt; are frequently asked in conjunction with other tags).&lt;/p&gt;
&lt;p&gt;Going back earlier to talking about tag abuse, do the presence of certain pairs of tags lead to notably different answer rates?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow-tags/so_tag_adjacency_percent.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Tag pairs which don&amp;rsquo;t make much sense (e.g. &lt;code&gt;ios&lt;/code&gt;+&lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;+&lt;code&gt;javascript&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;+&lt;code&gt;php&lt;/code&gt;) tend to have very low answer rates (20%-30%). But tags with already high answer rates like &lt;code&gt;regex&lt;/code&gt; don&amp;rsquo;t get much higher or much lower at a given pair.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There&amp;rsquo;s a lot more than can be done looking at question tags on Stack Overflow. I was surprised to see that all types of programming languages have quick answer times and a high probability of receiving an acceptable answer! I&amp;rsquo;ll definitely keep an eye on the SO archives as they are released, and I&amp;rsquo;m excited to see how trends change in the future.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;You can view the R and ggplot2 code used to create the data visualizations in &lt;a href=&#34;http://minimaxir.com/notebooks/stack-overflow-questions/&#34; target=&#34;_blank&#34;&gt;this R Notebook&lt;/a&gt;. You can also view the images/data used for this post in &lt;a href=&#34;https://github.com/minimaxir/stack-overflow-questions&#34; target=&#34;_blank&#34;&gt;this GitHub repository&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;You are free to use the data visualizations from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Visualizing How Developers Rate Their Own Programming Skills</title><link>/2016/07/stack-overflow/</link><pubDate>Thu, 21 Jul 2016 06:30:00 +0000</pubDate><guid>/2016/07/stack-overflow/</guid><description>
&lt;p&gt;&lt;a href=&#34;http://stackoverflow.com&#34; target=&#34;_blank&#34;&gt;Stack Overflow&lt;/a&gt;, the favorite destination for software developers when something breaks for no apparent reason, recently released their &lt;a href=&#34;http://stackoverflow.com/research/developer-survey-2016&#34; target=&#34;_blank&#34;&gt;2016 Stack Overflow Survey Results&lt;/a&gt; with responses to the questions of &amp;ldquo;where they work, what they build, and who they are.&amp;rdquo; You can download the released dataset containing all 56,030 cleaned responses &lt;a href=&#34;http://stackoverflow.com/research&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One variable present in the dataset but surprisingly unaddressed in the official Stack Overflow analysis is the &lt;code&gt;programming_ability&lt;/code&gt; field — &lt;em&gt;On a scale of 1-10, how would you rate your programming ability?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I took a look at the 46,982 users who identified their programming ability in the survey. On average, developers rate themselves 7.09 / 10. And like most 1-10 rating scales, the distribution of self-assessments is unimodal around 7 and 8, with relatively rare 9&amp;rsquo;s and 10&amp;rsquo;s.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow/so-programming-0.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can aggregate the programming ability data by other relevant metrics in the Stack Overflow dataset, such as experience and commit activity, and hopefully find interesting trends.&lt;/p&gt;
&lt;h2 id=&#34;sanity-checking&#34;&gt;Sanity Checking&lt;/h2&gt;
&lt;p&gt;I normally dislike working with survey data since there is a high possibility of &lt;a href=&#34;https://en.wikipedia.org/wiki/Selection_bias&#34; target=&#34;_blank&#34;&gt;selection bias&lt;/a&gt; among the respondents. In Stack Overflow&amp;rsquo;s case, their marketing of the survey on Facebook and Twitter may cause a high proportion of social-media savvy respondents and discount the insight of developers who are not likely to use those services. For this reason, I will show &lt;a href=&#34;https://en.wikipedia.org/wiki/Confidence_interval&#34; target=&#34;_blank&#34;&gt;confidence intervals&lt;/a&gt; whenever possible to reflect the proportionate uncertainty for groupings with insufficient data, and to also account for possibility that a minority of respondents may be dishonest and nudge their programming ability a few points higher than the truth.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s compare programming skill to the developer&amp;rsquo;s experience in the field. In the survey, the user could classify their IT / programming experience as a range, from &amp;ldquo;Less than 1 year&amp;rdquo;, &amp;ldquo;1 - 2 years&amp;rdquo;, &amp;ldquo;2 - 5 years&amp;rdquo;, &amp;ldquo;6 - 10 years&amp;rdquo;, and &amp;ldquo;11+ years.&amp;rdquo; Since we would expect a positive correlation between skill and experience, identifying such a positive correlation visually gives a quick indication that the analysis is on the right track.&lt;/p&gt;
&lt;p&gt;We can plot the average programming-ability rating for developers which fall into each of those five groups, and a confidence interval for that average. Additionally, we can make a &lt;a href=&#34;https://en.wikipedia.org/wiki/Violin_plot&#34; target=&#34;_blank&#34;&gt;violin plot&lt;/a&gt; of each group to give a sense of the underlying distribution of ratings.&lt;/p&gt;
&lt;p&gt;Putting it all together:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow/so-programming-5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The color dot for each group represents the average rating from the sample which the developers in the group give to themselves. The black error bars on the dot represent a 95% confidence interval for the true value of the average, obtained via &lt;a href=&#34;http://minimaxir.com/2015/09/bootstrap-resample/&#34; target=&#34;_blank&#34;&gt;percentile bootstrap&lt;/a&gt; with 10,000 resamples of the dataset with replacement (since there is a large amount of source data, the confidence intervals end up being very narrow in most cases; this is one legitimate advantage of big data).&lt;/p&gt;
&lt;p&gt;The violin plot for each group represents the normalized overall distribution of ratings. The narrowness of the per-value ratings reflect the amount of data available for that group: the more data available, the more narrow/precise the kernel smoothing is. Overall flat plots represent a wide selection of self-ratings, while an overall narrow plot represents a more-constrained selection (for the plot above, you can easily see the distribution shift to the right as the experience range increases).&lt;/p&gt;
&lt;p&gt;Also, keep in mind that these groupings alone do not imply a &lt;strong&gt;causal relationship&lt;/strong&gt; between the two variables. Employing traditional &lt;a href=&#34;https://en.wikipedia.org/wiki/Regression_analysis&#34; target=&#34;_blank&#34;&gt;regression analysis&lt;/a&gt; to build a model for predicting programming ability would be tricky: does having more experience cause programming skill to improve, or does having strong innate technical skill cause developers to remain in the industry and grow?&lt;/p&gt;
&lt;p&gt;Back to the plot at hand. We can easily confirm that a positive correlation exists between programming activity and experience, with newbie developers rating their skills 5.02 / 10 on average, and extremely experienced developers rating their skills three whole ranks higher at 8.13 / 10. What&amp;rsquo;s also notable is the range of values selected: for developers with &lt;strong&gt;less than 1 years&lt;/strong&gt; of experience, the distribution is almost completely flat between 1-7, showing that they are more honest with the self-assessment of their programming skills. Inversely, developers with &lt;strong&gt;11+ years&lt;/strong&gt; of experience select 9 and 10 ratings almost as much as 7 and 8 ratings.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s a good start. We can also compare developer skill to their age, which by construction (older developers have more experience) should have parallel behavior to experience levels.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow/so-programming-4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yes, the plot is indeed similar, with average ratings ranging from 6 to about 8. What&amp;rsquo;s interesting is the behavior for &lt;strong&gt;&amp;gt; 60&lt;/strong&gt; vs. &lt;strong&gt;50-59&lt;/strong&gt; is that the &amp;gt; 60 age programmers occasionally rate their skills at the low end of the scale, which is why the confidence interval is larger and the average is lower for that group.&lt;/p&gt;
&lt;p&gt;Lastly, we can look at the salary the developer is paid (in USD) as a validation of skill. This particular chart will only focus on developers in the United States (n = 13,539), so that the salary follows expected behavior with the specified currency and cost-of-living. In this case, there are many more groups, but that makes the distribution shift more apparent, and more interesting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow/so-programming-6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The large amount of &amp;gt;$100k earners in the dataset shows how the Stack Overflow demographic can skew toward Silicon Valley engineers. The $90k—$100k group serves as a convenient inflection point on how the distribution of self-ratings becomes a &lt;a href=&#34;http://tvtropes.org/pmwiki/pmwiki.php/Main/FourPointScale&#34; target=&#34;_blank&#34;&gt;Four Point Scale&lt;/a&gt; between 7 and 10 for those who earn more than $100k.&lt;/p&gt;
&lt;h2 id=&#34;do-better-developers-rate-themselves-better&#34;&gt;Do better developers rate themselves better?&lt;/h2&gt;
&lt;p&gt;So far, the data is internally consistent. There are a few other developer-relevant statistics are available in the dataset which can easily be aggregated. A good one is the &lt;em&gt;type&lt;/em&gt; of employment. For example, do &lt;strong&gt;freelance / contract&lt;/strong&gt; developers believe they are better programmers than &lt;strong&gt;full-time&lt;/strong&gt; developers?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow/so-programming-7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As it turns out, that guess is indeed the case, albeit it&amp;rsquo;s only a slight difference (7.53 / 10 for &lt;strong&gt;freelance / contract&lt;/strong&gt; vs. 7.29 / 10 for &lt;strong&gt;full-time&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;What about repository commit activity by developers? Are developers who commit more better? One could argue that a developer who commits code often is either vigilant with accounting for functional code changes, or polluting the codebase in an attempt to show productivity.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow/so-programming-8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yes, developers who commit lots of code rate themselves better.&lt;/p&gt;
&lt;p&gt;Lastly, let&amp;rsquo;s remember that the source of data is Stack Overflow. Are developers who use Stack Overflow as a resource better developers who know how to properly use external references in times of crisis, or are they developers who use it as a crutch to compensate for weak coding skills?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/stack-overflow/so-programming-9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As it turns out, there is &lt;strong&gt;no correlation between programming ability and and the frequency of Stack Overflow visits&lt;/strong&gt;, as the averages and distributions are virtually identical across all groups.&lt;/p&gt;
&lt;p&gt;There are many, many other answers available in the dataset; some allow multiple responses and are harder to parse, while others have zero correlation with programming ability as with the Stack Overflow visits, and therefore do not provide much additional insight. Although we cannot establish causal relationships with this methodology, there may be other important insights obtainable from aggregating programming ability data, but the charts presented in this post are a good start.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;As always, the full code used to process the comment data and generate the visualizations is available in &lt;a href=&#34;https://github.com/minimaxir/stack-overflow-survey/blob/master/stack_overflow_dev_survey.ipynb&#34; target=&#34;_blank&#34;&gt;this Jupyter notebook&lt;/a&gt;, open-sourced &lt;a href=&#34;https://github.com/minimaxir/stack-overflow-survey&#34; target=&#34;_blank&#34;&gt;on GitHub&lt;/a&gt;. The repository also contains a few unused bonus charts!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;You are free to use the charts from this article however you wish, but it would be greatly appreciated if proper attribution is given to this article and/or myself!&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>